{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-03T16:27:47.030196Z",
     "iopub.status.busy": "2024-11-03T16:27:47.029816Z",
     "iopub.status.idle": "2024-11-03T16:27:47.042838Z",
     "shell.execute_reply": "2024-11-03T16:27:47.041864Z",
     "shell.execute_reply.started": "2024-11-03T16:27:47.030142Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['creditcard.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "1fa9c421-e3e1-4a2c-978f-28f78e01ab34",
    "_uuid": "04bcbe2c5f6b3f74f6f8732c41e8e8e15654d311",
    "execution": {
     "iopub.execute_input": "2024-11-03T16:27:47.044468Z",
     "iopub.status.busy": "2024-11-03T16:27:47.044081Z",
     "iopub.status.idle": "2024-11-03T16:27:47.054590Z",
     "shell.execute_reply": "2024-11-03T16:27:47.053550Z",
     "shell.execute_reply.started": "2024-11-03T16:27:47.044379Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2024-11-03T16:27:47.096196Z",
     "iopub.status.busy": "2024-11-03T16:27:47.095722Z",
     "iopub.status.idle": "2024-11-03T16:27:50.496524Z",
     "shell.execute_reply": "2024-11-03T16:27:50.495438Z",
     "shell.execute_reply.started": "2024-11-03T16:27:47.096117Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "ad3d861f-12e4-49ca-a221-6d8bd6be6f8a",
    "_uuid": "24bc772bdd624e7d844b74020e273ffe3def4246",
    "execution": {
     "iopub.execute_input": "2024-11-03T16:27:50.498242Z",
     "iopub.status.busy": "2024-11-03T16:27:50.497934Z",
     "iopub.status.idle": "2024-11-03T16:27:50.539981Z",
     "shell.execute_reply": "2024-11-03T16:27:50.539131Z",
     "shell.execute_reply.started": "2024-11-03T16:27:50.498196Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "ac5f5f90-1607-4c5e-b0e7-845c724c7521",
    "_uuid": "7f9f454f8341834b0c6ab1a3de99b2577dcd7dd0",
    "execution": {
     "iopub.execute_input": "2024-11-03T16:27:50.541700Z",
     "iopub.status.busy": "2024-11-03T16:27:50.541368Z",
     "iopub.status.idle": "2024-11-03T16:27:51.331715Z",
     "shell.execute_reply": "2024-11-03T16:27:51.330755Z",
     "shell.execute_reply.started": "2024-11-03T16:27:50.541644Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.919560e-15  5.688174e-16 -8.769071e-15  2.782312e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552563e-15  2.010663e-15 -1.694249e-15 -1.927028e-16 -3.137024e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "           ...                 V21           V22           V23           V24  \\\n",
       "count      ...        2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean       ...        1.537294e-16  7.959909e-16  5.367590e-16  4.458112e-15   \n",
       "std        ...        7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min        ...       -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%        ...       -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%        ...       -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%        ...        1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max        ...        2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.453003e-15  1.699104e-15 -3.660161e-16 -1.206049e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "8f0c6894-0f3c-4f1a-9b2e-5155cc434ab8",
    "_uuid": "ae27e9aac252b8abebe73a7f152e8285f6ae6671",
    "execution": {
     "iopub.execute_input": "2024-11-03T16:27:51.333510Z",
     "iopub.status.busy": "2024-11-03T16:27:51.333181Z",
     "iopub.status.idle": "2024-11-03T16:27:51.495317Z",
     "shell.execute_reply": "2024-11-03T16:27:51.494415Z",
     "shell.execute_reply.started": "2024-11-03T16:27:51.333437Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "40293e6e-ec35-4847-90f1-1e6e89f70b91",
    "_uuid": "7ba46b55bc860137cbde1b97572a918dec5970d3",
    "execution": {
     "iopub.execute_input": "2024-11-03T16:27:51.496912Z",
     "iopub.status.busy": "2024-11-03T16:27:51.496619Z",
     "iopub.status.idle": "2024-11-03T16:27:52.209922Z",
     "shell.execute_reply": "2024-11-03T16:27:52.209083Z",
     "shell.execute_reply.started": "2024-11-03T16:27:51.496857Z"
    }
   },
   "outputs": [],
   "source": [
    "df.describe()\n",
    "df = df.drop('Time',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "25ea497f-93a3-4818-b1e5-a40c9ae9b81d",
    "_uuid": "8ab18d55eacc48d3f578c2c1977a789f9b95e03e",
    "execution": {
     "iopub.execute_input": "2024-11-03T16:27:52.211933Z",
     "iopub.status.busy": "2024-11-03T16:27:52.211536Z",
     "iopub.status.idle": "2024-11-03T16:27:52.277739Z",
     "shell.execute_reply": "2024-11-03T16:27:52.276697Z",
     "shell.execute_reply.started": "2024-11-03T16:27:52.211858Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df.drop('Class',axis=1).values \n",
    "y = df['Class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "c4737b0e-f780-45b4-b1cc-c0bd1d419b41",
    "_uuid": "4e153e0a8bbd54231af019089db7ceac7d4a3ab2",
    "execution": {
     "iopub.execute_input": "2024-11-03T16:27:52.279557Z",
     "iopub.status.busy": "2024-11-03T16:27:52.279219Z",
     "iopub.status.idle": "2024-11-03T16:27:52.293801Z",
     "shell.execute_reply": "2024-11-03T16:27:52.292817Z",
     "shell.execute_reply.started": "2024-11-03T16:27:52.279492Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 29)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "5788dbeb-8aa2-42a5-99af-b4e367de3808",
    "_uuid": "66ce9da4edfea3e8b6619d5f543b365899a59a5e",
    "execution": {
     "iopub.execute_input": "2024-11-03T16:27:52.295757Z",
     "iopub.status.busy": "2024-11-03T16:27:52.295244Z",
     "iopub.status.idle": "2024-11-03T16:27:52.337976Z",
     "shell.execute_reply": "2024-11-03T16:27:52.337047Z",
     "shell.execute_reply.started": "2024-11-03T16:27:52.295537Z"
    }
   },
   "outputs": [],
   "source": [
    "X -= X.min(axis=0)\n",
    "X /= X.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "57b2f8a6-9c45-4f60-a0ff-8aef07b2f484",
    "_uuid": "c36820c67500d54458d9b22ebc2293f2e8ccf99f",
    "execution": {
     "iopub.execute_input": "2024-11-03T16:27:52.339776Z",
     "iopub.status.busy": "2024-11-03T16:27:52.339425Z",
     "iopub.status.idle": "2024-11-03T16:27:52.352296Z",
     "shell.execute_reply": "2024-11-03T16:27:52.351430Z",
     "shell.execute_reply.started": "2024-11-03T16:27:52.339710Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5213456986251124"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "f79cfb3e-0a02-4052-b057-dfd6b96ac026",
    "_uuid": "91d77fc484400c0bc3ba4c3b16ebd9873d3da966",
    "execution": {
     "iopub.execute_input": "2024-11-03T16:27:52.354285Z",
     "iopub.status.busy": "2024-11-03T16:27:52.353984Z",
     "iopub.status.idle": "2024-11-03T16:27:52.360455Z",
     "shell.execute_reply": "2024-11-03T16:27:52.359542Z",
     "shell.execute_reply.started": "2024-11-03T16:27:52.354229Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 29)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "78e7cc64-e345-45c4-8c4e-52aa50cb9c21",
    "_uuid": "156872c244cdf82a28daa404fe1ebaaa96c52d0d",
    "execution": {
     "iopub.execute_input": "2024-11-03T16:27:52.362155Z",
     "iopub.status.busy": "2024-11-03T16:27:52.361830Z",
     "iopub.status.idle": "2024-11-03T16:27:52.617642Z",
     "shell.execute_reply": "2024-11-03T16:27:52.616451Z",
     "shell.execute_reply.started": "2024-11-03T16:27:52.362075Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train,y_test = train_test_split(X,y,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "572018d0-a703-43a9-aeee-4e1b655e350a",
    "_uuid": "1bf08d19c1f69f194b577e9ef1d652e1a7a24196",
    "execution": {
     "iopub.execute_input": "2024-11-03T16:27:52.619550Z",
     "iopub.status.busy": "2024-11-03T16:27:52.619214Z",
     "iopub.status.idle": "2024-11-03T16:27:52.660560Z",
     "shell.execute_reply": "2024-11-03T16:27:52.659669Z",
     "shell.execute_reply.started": "2024-11-03T16:27:52.619473Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import Input, Embedding, multiply, BatchNormalization\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.core import Reshape, Dense, Dropout, Flatten\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import Conv2D, UpSampling2D\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras import initializers\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "# Deterministic output.\n",
    "# Tired of seeing the same results every time? Remove the line below.\n",
    "np.random.seed(1000)\n",
    "\n",
    "# The results are a little better when the dimensionality of the random vector is only 10.\n",
    "# The dimensionality has been left at 100 for consistency with other GAN implementations.\n",
    "randomDim = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "0e0dc6cbb6ba7841c404ad1722a1bf957b9c0c71",
    "execution": {
     "iopub.execute_input": "2024-11-03T16:27:52.662372Z",
     "iopub.status.busy": "2024-11-03T16:27:52.662056Z",
     "iopub.status.idle": "2024-11-03T16:27:52.692713Z",
     "shell.execute_reply": "2024-11-03T16:27:52.691495Z",
     "shell.execute_reply.started": "2024-11-03T16:27:52.662314Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_generator(latent_dim,data_dim):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(16, input_dim=latent_dim))\n",
    "    \n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(32, input_dim=latent_dim))\n",
    "    \n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(data_dim,activation='tanh'))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "dff92e28df4d9b059f7e302aff0d4d374f4380bc",
    "execution": {
     "iopub.execute_input": "2024-11-03T16:27:52.695113Z",
     "iopub.status.busy": "2024-11-03T16:27:52.694724Z",
     "iopub.status.idle": "2024-11-03T16:27:53.104191Z",
     "shell.execute_reply": "2024-11-03T16:27:53.102964Z",
     "shell.execute_reply.started": "2024-11-03T16:27:52.695048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                176       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 29)                957       \n",
      "=================================================================\n",
      "Total params: 1,869\n",
      "Trainable params: 1,773\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = build_generator(latent_dim=10,data_dim=29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "52ff75e25d1db36679536594e80073f1e98a8205",
    "execution": {
     "iopub.execute_input": "2024-11-03T16:27:53.105944Z",
     "iopub.status.busy": "2024-11-03T16:27:53.105605Z",
     "iopub.status.idle": "2024-11-03T16:27:53.131219Z",
     "shell.execute_reply": "2024-11-03T16:27:53.130188Z",
     "shell.execute_reply.started": "2024-11-03T16:27:53.105881Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_discriminator(data_dim,num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(31,input_dim=data_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(16,input_dim=data_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model.summary()\n",
    "    img = Input(shape=(data_dim,))\n",
    "    features = model(img)\n",
    "    valid = Dense(1, activation=\"sigmoid\")(features)\n",
    "    label = Dense(num_classes+1, activation=\"softmax\")(features)\n",
    "    return Model(img, [valid, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "c4497a47e1f8d9218ea5463f9476a7c3c7592369",
    "execution": {
     "iopub.execute_input": "2024-11-03T16:27:53.133127Z",
     "iopub.status.busy": "2024-11-03T16:27:53.132710Z",
     "iopub.status.idle": "2024-11-03T16:27:53.421065Z",
     "shell.execute_reply": "2024-11-03T16:27:53.420041Z",
     "shell.execute_reply.started": "2024-11-03T16:27:53.133057Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 31)                930       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 31)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 31)                124       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 31)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 16)                0         \n",
      "=================================================================\n",
      "Total params: 1,566\n",
      "Trainable params: 1,504\n",
      "Non-trainable params: 62\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = build_discriminator(data_dim=29,num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "c29a35e4e0a2e9d0b349373c24ab0fae1bdf85f3",
    "execution": {
     "iopub.execute_input": "2024-11-03T16:27:53.422680Z",
     "iopub.status.busy": "2024-11-03T16:27:53.422343Z",
     "iopub.status.idle": "2024-11-03T16:27:53.491646Z",
     "shell.execute_reply": "2024-11-03T16:27:53.490787Z",
     "shell.execute_reply.started": "2024-11-03T16:27:53.422609Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(0.0002, 0.5)\n",
    "discriminator.compile(loss=['binary_crossentropy', 'categorical_crossentropy'],\n",
    "    loss_weights=[0.5, 0.5],\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "868d72058acc8074c6144032890def6deb200def",
    "execution": {
     "iopub.execute_input": "2024-11-03T16:27:53.493257Z",
     "iopub.status.busy": "2024-11-03T16:27:53.492997Z",
     "iopub.status.idle": "2024-11-03T16:27:53.799364Z",
     "shell.execute_reply": "2024-11-03T16:27:53.798333Z",
     "shell.execute_reply.started": "2024-11-03T16:27:53.493212Z"
    }
   },
   "outputs": [],
   "source": [
    "noise = Input(shape=(10,))\n",
    "img = generator(noise)\n",
    "discriminator.trainable = False\n",
    "valid,_ = discriminator(img)\n",
    "combined = Model(noise , valid)\n",
    "combined.compile(loss=['binary_crossentropy'],\n",
    "    optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "52864000452f21f43505dd97ca414deb508e839f",
    "execution": {
     "iopub.execute_input": "2024-11-03T16:27:53.801020Z",
     "iopub.status.busy": "2024-11-03T16:27:53.800739Z",
     "iopub.status.idle": "2024-11-03T16:27:53.806666Z",
     "shell.execute_reply": "2024-11-03T16:27:53.805713Z",
     "shell.execute_reply.started": "2024-11-03T16:27:53.800973Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256326, 29)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "b85ecac37805e937412c02f47461c0c59a2f3a0d",
    "execution": {
     "iopub.execute_input": "2024-11-03T16:27:53.808338Z",
     "iopub.status.busy": "2024-11-03T16:27:53.808040Z",
     "iopub.status.idle": "2024-11-03T16:27:53.820138Z",
     "shell.execute_reply": "2024-11-03T16:27:53.819233Z",
     "shell.execute_reply.started": "2024-11-03T16:27:53.808280Z"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "e6a1493cf4397402463a18b85a2ae24d7ed93639",
    "execution": {
     "iopub.execute_input": "2024-11-03T16:27:53.821789Z",
     "iopub.status.busy": "2024-11-03T16:27:53.821474Z",
     "iopub.status.idle": "2024-11-03T16:27:53.834333Z",
     "shell.execute_reply": "2024-11-03T16:27:53.833411Z",
     "shell.execute_reply.started": "2024-11-03T16:27:53.821740Z"
    }
   },
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "faf05a4ef5cded3a5e21681d0956cebfbf9c2efb",
    "execution": {
     "iopub.execute_input": "2024-11-03T16:27:53.836005Z",
     "iopub.status.busy": "2024-11-03T16:27:53.835702Z",
     "iopub.status.idle": "2024-11-03T16:27:54.149658Z",
     "shell.execute_reply": "2024-11-03T16:27:54.148702Z",
     "shell.execute_reply.started": "2024-11-03T16:27:53.835941Z"
    }
   },
   "outputs": [],
   "source": [
    "X_res, y_res = rus.fit_sample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "6d1c4f982b9a649a1191ebe975c2a9a26a6f4a3e",
    "execution": {
     "iopub.execute_input": "2024-11-03T16:27:54.151356Z",
     "iopub.status.busy": "2024-11-03T16:27:54.151042Z",
     "iopub.status.idle": "2024-11-03T16:27:54.157256Z",
     "shell.execute_reply": "2024-11-03T16:27:54.156326Z",
     "shell.execute_reply.started": "2024-11-03T16:27:54.151293Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(984, 29)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "3ee6d6276b542dbb9484e14dbd75156ba8e16efb",
    "execution": {
     "iopub.execute_input": "2024-11-03T16:27:54.158967Z",
     "iopub.status.busy": "2024-11-03T16:27:54.158651Z",
     "iopub.status.idle": "2024-11-03T16:27:54.170411Z",
     "shell.execute_reply": "2024-11-03T16:27:54.169496Z",
     "shell.execute_reply.started": "2024-11-03T16:27:54.158908Z"
    }
   },
   "outputs": [],
   "source": [
    "X_res -= X_res.min()\n",
    "X_res /= X_res.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "f906b0eb02f40139ed4ee9adde6e0175358d8cc4",
    "execution": {
     "iopub.execute_input": "2024-11-03T16:27:54.172036Z",
     "iopub.status.busy": "2024-11-03T16:27:54.171747Z",
     "iopub.status.idle": "2024-11-03T16:27:54.187545Z",
     "shell.execute_reply": "2024-11-03T16:27:54.186525Z",
     "shell.execute_reply.started": "2024-11-03T16:27:54.171988Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test -= X_test.min()\n",
    "X_test /= X_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "b85f188577271c544c6b82a133f70380a1ba303f",
    "execution": {
     "iopub.execute_input": "2024-11-03T16:27:54.189444Z",
     "iopub.status.busy": "2024-11-03T16:27:54.189038Z",
     "iopub.status.idle": "2024-11-03T16:27:54.226841Z",
     "shell.execute_reply": "2024-11-03T16:27:54.225789Z",
     "shell.execute_reply.started": "2024-11-03T16:27:54.189386Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test_res, y_test_res = rus.fit_sample(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "d0ed0b90189d4ae0ffad536db958905c0270d0b4",
    "execution": {
     "iopub.execute_input": "2024-11-03T16:27:54.228431Z",
     "iopub.status.busy": "2024-11-03T16:27:54.228172Z",
     "iopub.status.idle": "2024-11-03T16:27:54.233259Z",
     "shell.execute_reply": "2024-11-03T16:27:54.232354Z",
     "shell.execute_reply.started": "2024-11-03T16:27:54.228393Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "f1c158a5e790d62752767226791a34b8583dae8f",
    "execution": {
     "iopub.execute_input": "2024-11-03T16:27:54.235432Z",
     "iopub.status.busy": "2024-11-03T16:27:54.235108Z",
     "iopub.status.idle": "2024-11-03T16:27:54.248980Z",
     "shell.execute_reply": "2024-11-03T16:27:54.248006Z",
     "shell.execute_reply.started": "2024-11-03T16:27:54.235367Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(984,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "68eee475d3fa477523453ff78aeef868f36f6079",
    "execution": {
     "iopub.execute_input": "2024-11-03T16:27:54.250966Z",
     "iopub.status.busy": "2024-11-03T16:27:54.250631Z",
     "iopub.status.idle": "2024-11-03T16:27:54.535132Z",
     "shell.execute_reply": "2024-11-03T16:27:54.534084Z",
     "shell.execute_reply.started": "2024-11-03T16:27:54.250910Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(X_train,y_train,\n",
    "          X_test,y_test,\n",
    "          generator,discriminator,\n",
    "          combined,\n",
    "          num_classes,\n",
    "          epochs, \n",
    "          batch_size=128):\n",
    "    \n",
    "    f1_progress = []\n",
    "    d_loss_progress = []\n",
    "    half_batch = int(batch_size / 2)\n",
    "\n",
    "    noise_until = epochs\n",
    "\n",
    "    # Class weights:\n",
    "    # To balance the difference in occurences of digit class labels.\n",
    "    # 50% of labels that the discriminator trains on are 'fake'.\n",
    "    # Weight = 1 / frequency\n",
    "    cw1 = {0: 1, 1: 1}\n",
    "    cw2 = {i: num_classes / half_batch for i in range(num_classes)}\n",
    "    cw2[num_classes] = 1 / half_batch \n",
    "    d_loss_sum = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        # Select a random half batch of images\n",
    "        idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "        imgs = X_train[idx]\n",
    "\n",
    "        # Sample noise and generate a half batch of new images\n",
    "        noise = np.random.normal(0, 1, (half_batch, 10))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "\n",
    "        valid = np.ones((half_batch, 1))\n",
    "        fake = np.zeros((half_batch, 1))\n",
    "\n",
    "        labels = to_categorical(y_train[idx], num_classes=num_classes+1)\n",
    "        fake_labels = to_categorical(np.full((half_batch, 1), num_classes), num_classes=num_classes+1)\n",
    "\n",
    "        # Train the discriminator\n",
    "        d_loss_real = discriminator.train_on_batch(imgs, [valid, labels], class_weight=[cw1, cw2])\n",
    "        d_loss_fake = discriminator.train_on_batch(gen_imgs, [fake, fake_labels], class_weight=[cw1, cw2])\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Generator\n",
    "        # ---------------------\n",
    "\n",
    "        noise = np.random.normal(0, 1, (batch_size, 10))\n",
    "        validity = np.ones((batch_size, 1))\n",
    "\n",
    "        # Train the generator\n",
    "        g_loss = combined.train_on_batch(noise, validity, class_weight=[cw1, cw2])\n",
    "\n",
    "        # Plot the progress\n",
    "        print (\"%d [D loss: %f, acc: %.2f%%, op_acc: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[3], 100*d_loss[4], g_loss))\n",
    "        d_loss_sum += 100*d_loss[3]\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            _,y_pred = discriminator.predict(X_test,batch_size=batch_size)\n",
    "            #print(y_pred.shape)\n",
    "            y_pred = np.argmax(y_pred[:,:-1],axis=1)\n",
    "            \n",
    "            f1 = f1_score(y_test,y_pred)\n",
    "            print('Epoch: {}, F1: {:.5f}, F1P: {}'.format(epoch,f1,len(f1_progress)))\n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "            print(cm)\n",
    "            print(d_loss_sum/10)\n",
    "            d_loss_progress.append(d_loss_sum/10)\n",
    "            f1_progress.append(f1)\n",
    "            d_loss_sum = 0\n",
    "    \n",
    "    return f1_progress, d_loss_progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "bf5e4c217d9b0036e859b818561a9274d32027ce",
    "execution": {
     "iopub.execute_input": "2024-11-03T16:27:54.537169Z",
     "iopub.status.busy": "2024-11-03T16:27:54.536774Z",
     "iopub.status.idle": "2024-11-03T16:29:26.252053Z",
     "shell.execute_reply": "2024-11-03T16:29:26.251044Z",
     "shell.execute_reply.started": "2024-11-03T16:27:54.537100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/Keras-2.1.5-py3.6.egg/keras/engine/training.py:973: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.439273, acc: 46.09%, op_acc: 25.78%] [G loss: 1.320194]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, F1: 0.00000, F1P: 0\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "4.609375\n",
      "1 [D loss: 0.458723, acc: 42.97%, op_acc: 32.81%] [G loss: 1.346049]\n",
      "2 [D loss: 0.432519, acc: 45.31%, op_acc: 32.03%] [G loss: 1.374250]\n",
      "3 [D loss: 0.414698, acc: 51.56%, op_acc: 27.34%] [G loss: 1.258614]\n",
      "4 [D loss: 0.414755, acc: 49.22%, op_acc: 24.22%] [G loss: 1.313936]\n",
      "5 [D loss: 0.432729, acc: 45.31%, op_acc: 35.16%] [G loss: 1.282988]\n",
      "6 [D loss: 0.419263, acc: 52.34%, op_acc: 27.34%] [G loss: 1.280510]\n",
      "7 [D loss: 0.410565, acc: 50.00%, op_acc: 35.16%] [G loss: 1.297639]\n",
      "8 [D loss: 0.428291, acc: 44.53%, op_acc: 28.12%] [G loss: 1.289013]\n",
      "9 [D loss: 0.425672, acc: 40.62%, op_acc: 35.16%] [G loss: 1.253543]\n",
      "10 [D loss: 0.411603, acc: 46.88%, op_acc: 28.91%] [G loss: 1.252488]\n",
      "Epoch: 10, F1: 0.00000, F1P: 1\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "46.875\n",
      "11 [D loss: 0.389918, acc: 52.34%, op_acc: 26.56%] [G loss: 1.352849]\n",
      "12 [D loss: 0.428216, acc: 46.88%, op_acc: 29.69%] [G loss: 1.221812]\n",
      "13 [D loss: 0.424134, acc: 50.78%, op_acc: 28.91%] [G loss: 1.305849]\n",
      "14 [D loss: 0.416417, acc: 46.88%, op_acc: 25.78%] [G loss: 1.270907]\n",
      "15 [D loss: 0.413430, acc: 48.44%, op_acc: 25.00%] [G loss: 1.271910]\n",
      "16 [D loss: 0.376513, acc: 50.00%, op_acc: 33.59%] [G loss: 1.264418]\n",
      "17 [D loss: 0.408051, acc: 48.44%, op_acc: 32.03%] [G loss: 1.271192]\n",
      "18 [D loss: 0.409853, acc: 50.00%, op_acc: 25.78%] [G loss: 1.191409]\n",
      "19 [D loss: 0.380465, acc: 52.34%, op_acc: 33.59%] [G loss: 1.248409]\n",
      "20 [D loss: 0.393493, acc: 42.97%, op_acc: 39.84%] [G loss: 1.214552]\n",
      "Epoch: 20, F1: 0.00000, F1P: 2\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "48.90625\n",
      "21 [D loss: 0.397022, acc: 43.75%, op_acc: 32.81%] [G loss: 1.222677]\n",
      "22 [D loss: 0.410299, acc: 50.78%, op_acc: 27.34%] [G loss: 1.274032]\n",
      "23 [D loss: 0.418684, acc: 48.44%, op_acc: 28.12%] [G loss: 1.197091]\n",
      "24 [D loss: 0.372247, acc: 53.91%, op_acc: 33.59%] [G loss: 1.265886]\n",
      "25 [D loss: 0.388233, acc: 50.00%, op_acc: 30.47%] [G loss: 1.167375]\n",
      "26 [D loss: 0.405662, acc: 50.00%, op_acc: 28.12%] [G loss: 1.233422]\n",
      "27 [D loss: 0.391177, acc: 53.12%, op_acc: 35.94%] [G loss: 1.223800]\n",
      "28 [D loss: 0.395498, acc: 52.34%, op_acc: 35.16%] [G loss: 1.246624]\n",
      "29 [D loss: 0.380133, acc: 47.66%, op_acc: 35.16%] [G loss: 1.199056]\n",
      "30 [D loss: 0.386857, acc: 53.12%, op_acc: 32.81%] [G loss: 1.170648]\n",
      "Epoch: 30, F1: 0.00000, F1P: 3\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "50.3125\n",
      "31 [D loss: 0.367787, acc: 53.12%, op_acc: 28.91%] [G loss: 1.189102]\n",
      "32 [D loss: 0.404717, acc: 51.56%, op_acc: 32.81%] [G loss: 1.142187]\n",
      "33 [D loss: 0.392447, acc: 48.44%, op_acc: 37.50%] [G loss: 1.205830]\n",
      "34 [D loss: 0.382520, acc: 50.00%, op_acc: 35.94%] [G loss: 1.125480]\n",
      "35 [D loss: 0.359614, acc: 57.81%, op_acc: 39.06%] [G loss: 1.219737]\n",
      "36 [D loss: 0.406981, acc: 45.31%, op_acc: 32.81%] [G loss: 1.216573]\n",
      "37 [D loss: 0.379307, acc: 52.34%, op_acc: 32.03%] [G loss: 1.220271]\n",
      "38 [D loss: 0.384862, acc: 47.66%, op_acc: 27.34%] [G loss: 1.162119]\n",
      "39 [D loss: 0.381476, acc: 53.12%, op_acc: 35.16%] [G loss: 1.163964]\n",
      "40 [D loss: 0.389256, acc: 47.66%, op_acc: 26.56%] [G loss: 1.188694]\n",
      "Epoch: 40, F1: 0.00000, F1P: 4\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "50.703125\n",
      "41 [D loss: 0.366050, acc: 54.69%, op_acc: 32.03%] [G loss: 1.139604]\n",
      "42 [D loss: 0.343765, acc: 53.91%, op_acc: 35.16%] [G loss: 1.242343]\n",
      "43 [D loss: 0.363970, acc: 55.47%, op_acc: 37.50%] [G loss: 1.197338]\n",
      "44 [D loss: 0.383881, acc: 51.56%, op_acc: 32.81%] [G loss: 1.153362]\n",
      "45 [D loss: 0.364713, acc: 52.34%, op_acc: 36.72%] [G loss: 1.070711]\n",
      "46 [D loss: 0.372451, acc: 56.25%, op_acc: 29.69%] [G loss: 1.166938]\n",
      "47 [D loss: 0.359575, acc: 51.56%, op_acc: 36.72%] [G loss: 1.170983]\n",
      "48 [D loss: 0.386638, acc: 50.00%, op_acc: 31.25%] [G loss: 1.206532]\n",
      "49 [D loss: 0.370876, acc: 48.44%, op_acc: 40.62%] [G loss: 1.217037]\n",
      "50 [D loss: 0.362943, acc: 58.59%, op_acc: 33.59%] [G loss: 1.124843]\n",
      "Epoch: 50, F1: 0.00000, F1P: 5\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "53.28125\n",
      "51 [D loss: 0.378674, acc: 49.22%, op_acc: 29.69%] [G loss: 1.172283]\n",
      "52 [D loss: 0.344351, acc: 58.59%, op_acc: 32.03%] [G loss: 1.170742]\n",
      "53 [D loss: 0.367705, acc: 53.12%, op_acc: 31.25%] [G loss: 1.159080]\n",
      "54 [D loss: 0.362405, acc: 54.69%, op_acc: 38.28%] [G loss: 1.182551]\n",
      "55 [D loss: 0.369253, acc: 52.34%, op_acc: 34.38%] [G loss: 1.123727]\n",
      "56 [D loss: 0.381329, acc: 50.00%, op_acc: 31.25%] [G loss: 1.172068]\n",
      "57 [D loss: 0.360242, acc: 57.03%, op_acc: 39.84%] [G loss: 1.100094]\n",
      "58 [D loss: 0.359750, acc: 56.25%, op_acc: 30.47%] [G loss: 1.136177]\n",
      "59 [D loss: 0.365798, acc: 53.12%, op_acc: 28.91%] [G loss: 1.152305]\n",
      "60 [D loss: 0.373084, acc: 52.34%, op_acc: 32.81%] [G loss: 1.214938]\n",
      "Epoch: 60, F1: 0.00000, F1P: 6\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "53.671875\n",
      "61 [D loss: 0.368175, acc: 55.47%, op_acc: 32.03%] [G loss: 1.184312]\n",
      "62 [D loss: 0.343727, acc: 53.91%, op_acc: 35.16%] [G loss: 1.161420]\n",
      "63 [D loss: 0.377139, acc: 50.00%, op_acc: 33.59%] [G loss: 1.181957]\n",
      "64 [D loss: 0.361642, acc: 53.12%, op_acc: 36.72%] [G loss: 1.124700]\n",
      "65 [D loss: 0.361792, acc: 53.91%, op_acc: 33.59%] [G loss: 1.133302]\n",
      "66 [D loss: 0.362208, acc: 51.56%, op_acc: 43.75%] [G loss: 1.148321]\n",
      "67 [D loss: 0.370167, acc: 54.69%, op_acc: 25.78%] [G loss: 1.123388]\n",
      "68 [D loss: 0.380702, acc: 49.22%, op_acc: 36.72%] [G loss: 1.117530]\n",
      "69 [D loss: 0.369237, acc: 55.47%, op_acc: 35.94%] [G loss: 1.077353]\n",
      "70 [D loss: 0.367145, acc: 53.91%, op_acc: 25.00%] [G loss: 1.066442]\n",
      "Epoch: 70, F1: 0.00000, F1P: 7\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "53.125\n",
      "71 [D loss: 0.379094, acc: 50.00%, op_acc: 34.38%] [G loss: 1.120298]\n",
      "72 [D loss: 0.355923, acc: 56.25%, op_acc: 36.72%] [G loss: 1.084132]\n",
      "73 [D loss: 0.356734, acc: 58.59%, op_acc: 34.38%] [G loss: 1.165336]\n",
      "74 [D loss: 0.347280, acc: 56.25%, op_acc: 35.94%] [G loss: 1.159348]\n",
      "75 [D loss: 0.368898, acc: 46.09%, op_acc: 35.94%] [G loss: 1.112139]\n",
      "76 [D loss: 0.381711, acc: 50.78%, op_acc: 37.50%] [G loss: 1.123975]\n",
      "77 [D loss: 0.359631, acc: 51.56%, op_acc: 38.28%] [G loss: 1.151641]\n",
      "78 [D loss: 0.355552, acc: 53.91%, op_acc: 28.91%] [G loss: 1.069556]\n",
      "79 [D loss: 0.367388, acc: 50.00%, op_acc: 34.38%] [G loss: 1.107242]\n",
      "80 [D loss: 0.333603, acc: 59.38%, op_acc: 30.47%] [G loss: 1.152106]\n",
      "Epoch: 80, F1: 0.00000, F1P: 8\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "53.28125\n",
      "81 [D loss: 0.348161, acc: 59.38%, op_acc: 33.59%] [G loss: 1.124879]\n",
      "82 [D loss: 0.365789, acc: 54.69%, op_acc: 37.50%] [G loss: 1.173993]\n",
      "83 [D loss: 0.351393, acc: 57.81%, op_acc: 37.50%] [G loss: 1.088366]\n",
      "84 [D loss: 0.359275, acc: 54.69%, op_acc: 44.53%] [G loss: 1.147916]\n",
      "85 [D loss: 0.365957, acc: 53.91%, op_acc: 34.38%] [G loss: 1.099043]\n",
      "86 [D loss: 0.364990, acc: 55.47%, op_acc: 30.47%] [G loss: 1.129952]\n",
      "87 [D loss: 0.345397, acc: 60.94%, op_acc: 43.75%] [G loss: 1.080883]\n",
      "88 [D loss: 0.349085, acc: 60.94%, op_acc: 38.28%] [G loss: 1.104197]\n",
      "89 [D loss: 0.355502, acc: 57.03%, op_acc: 34.38%] [G loss: 1.014031]\n",
      "90 [D loss: 0.350206, acc: 62.50%, op_acc: 32.81%] [G loss: 1.085476]\n",
      "Epoch: 90, F1: 0.00000, F1P: 9\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "57.734375\n",
      "91 [D loss: 0.350726, acc: 53.91%, op_acc: 42.19%] [G loss: 1.158997]\n",
      "92 [D loss: 0.356020, acc: 51.56%, op_acc: 39.06%] [G loss: 1.135341]\n",
      "93 [D loss: 0.328625, acc: 66.41%, op_acc: 35.16%] [G loss: 1.077945]\n",
      "94 [D loss: 0.340486, acc: 56.25%, op_acc: 39.84%] [G loss: 1.178728]\n",
      "95 [D loss: 0.320301, acc: 64.06%, op_acc: 35.16%] [G loss: 1.118239]\n",
      "96 [D loss: 0.341314, acc: 59.38%, op_acc: 35.94%] [G loss: 1.132962]\n",
      "97 [D loss: 0.333002, acc: 61.72%, op_acc: 38.28%] [G loss: 1.131365]\n",
      "98 [D loss: 0.342215, acc: 61.72%, op_acc: 42.19%] [G loss: 1.155204]\n",
      "99 [D loss: 0.334315, acc: 65.62%, op_acc: 37.50%] [G loss: 1.143989]\n",
      "100 [D loss: 0.341328, acc: 64.06%, op_acc: 34.38%] [G loss: 1.089395]\n",
      "Epoch: 100, F1: 0.00000, F1P: 10\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "60.46875\n",
      "101 [D loss: 0.342630, acc: 56.25%, op_acc: 36.72%] [G loss: 1.095309]\n",
      "102 [D loss: 0.330465, acc: 60.94%, op_acc: 33.59%] [G loss: 1.076778]\n",
      "103 [D loss: 0.341871, acc: 60.16%, op_acc: 34.38%] [G loss: 1.097399]\n",
      "104 [D loss: 0.338802, acc: 58.59%, op_acc: 37.50%] [G loss: 1.147779]\n",
      "105 [D loss: 0.343605, acc: 56.25%, op_acc: 38.28%] [G loss: 1.081372]\n",
      "106 [D loss: 0.328360, acc: 64.84%, op_acc: 36.72%] [G loss: 1.101461]\n",
      "107 [D loss: 0.318391, acc: 70.31%, op_acc: 37.50%] [G loss: 1.097827]\n",
      "108 [D loss: 0.309759, acc: 66.41%, op_acc: 43.75%] [G loss: 1.116200]\n",
      "109 [D loss: 0.332115, acc: 60.16%, op_acc: 39.06%] [G loss: 1.078827]\n",
      "110 [D loss: 0.349865, acc: 60.16%, op_acc: 39.06%] [G loss: 1.078679]\n",
      "Epoch: 110, F1: 0.00000, F1P: 11\n",
      "[[28431     1]\n",
      " [   49     0]]\n",
      "61.40625\n",
      "111 [D loss: 0.330617, acc: 62.50%, op_acc: 36.72%] [G loss: 0.986141]\n",
      "112 [D loss: 0.326038, acc: 67.19%, op_acc: 37.50%] [G loss: 1.098546]\n",
      "113 [D loss: 0.339364, acc: 57.81%, op_acc: 41.41%] [G loss: 1.167402]\n",
      "114 [D loss: 0.333632, acc: 63.28%, op_acc: 34.38%] [G loss: 1.069698]\n",
      "115 [D loss: 0.337575, acc: 58.59%, op_acc: 43.75%] [G loss: 1.096579]\n",
      "116 [D loss: 0.327922, acc: 61.72%, op_acc: 39.84%] [G loss: 1.131656]\n",
      "117 [D loss: 0.330173, acc: 65.62%, op_acc: 42.19%] [G loss: 1.073798]\n",
      "118 [D loss: 0.327327, acc: 64.06%, op_acc: 39.06%] [G loss: 1.101611]\n",
      "119 [D loss: 0.345850, acc: 61.72%, op_acc: 41.41%] [G loss: 1.043871]\n",
      "120 [D loss: 0.320419, acc: 69.53%, op_acc: 38.28%] [G loss: 1.059297]\n",
      "Epoch: 120, F1: 0.00000, F1P: 12\n",
      "[[28430     2]\n",
      " [   49     0]]\n",
      "63.203125\n",
      "121 [D loss: 0.335575, acc: 60.94%, op_acc: 38.28%] [G loss: 1.030326]\n",
      "122 [D loss: 0.344610, acc: 60.16%, op_acc: 39.06%] [G loss: 1.018990]\n",
      "123 [D loss: 0.324387, acc: 63.28%, op_acc: 41.41%] [G loss: 1.098415]\n",
      "124 [D loss: 0.326736, acc: 67.97%, op_acc: 39.84%] [G loss: 1.081349]\n",
      "125 [D loss: 0.340505, acc: 60.16%, op_acc: 39.06%] [G loss: 1.078258]\n",
      "126 [D loss: 0.325944, acc: 66.41%, op_acc: 39.84%] [G loss: 1.086303]\n",
      "127 [D loss: 0.332467, acc: 57.03%, op_acc: 42.19%] [G loss: 1.059302]\n",
      "128 [D loss: 0.314608, acc: 71.88%, op_acc: 42.97%] [G loss: 1.054730]\n",
      "129 [D loss: 0.323330, acc: 62.50%, op_acc: 40.62%] [G loss: 1.056850]\n",
      "130 [D loss: 0.317219, acc: 67.19%, op_acc: 40.62%] [G loss: 1.069209]\n",
      "Epoch: 130, F1: 0.00000, F1P: 13\n",
      "[[28430     2]\n",
      " [   49     0]]\n",
      "63.75\n",
      "131 [D loss: 0.313477, acc: 66.41%, op_acc: 35.94%] [G loss: 1.106170]\n",
      "132 [D loss: 0.342706, acc: 64.06%, op_acc: 35.94%] [G loss: 1.094429]\n",
      "133 [D loss: 0.318466, acc: 71.09%, op_acc: 35.94%] [G loss: 1.038216]\n",
      "134 [D loss: 0.335110, acc: 65.62%, op_acc: 42.97%] [G loss: 1.103682]\n",
      "135 [D loss: 0.319899, acc: 65.62%, op_acc: 36.72%] [G loss: 1.054675]\n",
      "136 [D loss: 0.302737, acc: 66.41%, op_acc: 41.41%] [G loss: 1.083852]\n",
      "137 [D loss: 0.328440, acc: 70.31%, op_acc: 39.84%] [G loss: 1.070771]\n",
      "138 [D loss: 0.322616, acc: 65.62%, op_acc: 43.75%] [G loss: 1.036989]\n",
      "139 [D loss: 0.327353, acc: 66.41%, op_acc: 42.97%] [G loss: 1.030173]\n",
      "140 [D loss: 0.344494, acc: 63.28%, op_acc: 38.28%] [G loss: 1.034223]\n",
      "Epoch: 140, F1: 0.00000, F1P: 14\n",
      "[[28430     2]\n",
      " [   49     0]]\n",
      "66.484375\n",
      "141 [D loss: 0.330693, acc: 64.06%, op_acc: 42.19%] [G loss: 1.171725]\n",
      "142 [D loss: 0.347275, acc: 61.72%, op_acc: 36.72%] [G loss: 1.032373]\n",
      "143 [D loss: 0.321887, acc: 69.53%, op_acc: 44.53%] [G loss: 1.064088]\n",
      "144 [D loss: 0.329308, acc: 68.75%, op_acc: 44.53%] [G loss: 1.069698]\n",
      "145 [D loss: 0.325022, acc: 71.09%, op_acc: 35.16%] [G loss: 1.038486]\n",
      "146 [D loss: 0.324683, acc: 68.75%, op_acc: 42.19%] [G loss: 1.056216]\n",
      "147 [D loss: 0.321449, acc: 65.62%, op_acc: 35.16%] [G loss: 1.075450]\n",
      "148 [D loss: 0.330357, acc: 65.62%, op_acc: 44.53%] [G loss: 1.111469]\n",
      "149 [D loss: 0.309622, acc: 69.53%, op_acc: 35.94%] [G loss: 1.070059]\n",
      "150 [D loss: 0.331465, acc: 61.72%, op_acc: 42.97%] [G loss: 1.055362]\n",
      "Epoch: 150, F1: 0.00000, F1P: 15\n",
      "[[28430     2]\n",
      " [   49     0]]\n",
      "66.640625\n",
      "151 [D loss: 0.326464, acc: 64.84%, op_acc: 36.72%] [G loss: 1.045549]\n",
      "152 [D loss: 0.335074, acc: 58.59%, op_acc: 37.50%] [G loss: 1.081180]\n",
      "153 [D loss: 0.313580, acc: 65.62%, op_acc: 39.06%] [G loss: 1.064145]\n",
      "154 [D loss: 0.315524, acc: 71.88%, op_acc: 42.19%] [G loss: 1.068413]\n",
      "155 [D loss: 0.328364, acc: 72.66%, op_acc: 40.62%] [G loss: 1.089229]\n",
      "156 [D loss: 0.327467, acc: 66.41%, op_acc: 35.94%] [G loss: 1.069546]\n",
      "157 [D loss: 0.309036, acc: 67.97%, op_acc: 39.84%] [G loss: 1.060457]\n",
      "158 [D loss: 0.312092, acc: 71.88%, op_acc: 45.31%] [G loss: 1.068516]\n",
      "159 [D loss: 0.317108, acc: 66.41%, op_acc: 43.75%] [G loss: 1.061469]\n",
      "160 [D loss: 0.313428, acc: 71.88%, op_acc: 45.31%] [G loss: 1.006907]\n",
      "Epoch: 160, F1: 0.00000, F1P: 16\n",
      "[[28430     2]\n",
      " [   49     0]]\n",
      "67.8125\n",
      "161 [D loss: 0.321067, acc: 71.09%, op_acc: 42.97%] [G loss: 1.128364]\n",
      "162 [D loss: 0.321136, acc: 70.31%, op_acc: 39.06%] [G loss: 1.053797]\n",
      "163 [D loss: 0.325738, acc: 67.19%, op_acc: 39.84%] [G loss: 1.166648]\n",
      "164 [D loss: 0.323251, acc: 67.19%, op_acc: 38.28%] [G loss: 1.046805]\n",
      "165 [D loss: 0.327642, acc: 70.31%, op_acc: 36.72%] [G loss: 1.016877]\n",
      "166 [D loss: 0.301774, acc: 69.53%, op_acc: 42.97%] [G loss: 1.166129]\n",
      "167 [D loss: 0.315113, acc: 67.19%, op_acc: 42.19%] [G loss: 1.091355]\n",
      "168 [D loss: 0.320868, acc: 70.31%, op_acc: 42.19%] [G loss: 1.077995]\n",
      "169 [D loss: 0.313434, acc: 75.78%, op_acc: 39.84%] [G loss: 1.040176]\n",
      "170 [D loss: 0.313306, acc: 77.34%, op_acc: 48.44%] [G loss: 1.077125]\n",
      "Epoch: 170, F1: 0.00000, F1P: 17\n",
      "[[28430     2]\n",
      " [   49     0]]\n",
      "70.625\n",
      "171 [D loss: 0.302639, acc: 73.44%, op_acc: 41.41%] [G loss: 1.094306]\n",
      "172 [D loss: 0.324611, acc: 64.06%, op_acc: 45.31%] [G loss: 1.053925]\n",
      "173 [D loss: 0.305652, acc: 74.22%, op_acc: 42.97%] [G loss: 1.040210]\n",
      "174 [D loss: 0.306098, acc: 72.66%, op_acc: 37.50%] [G loss: 1.062704]\n",
      "175 [D loss: 0.306947, acc: 68.75%, op_acc: 43.75%] [G loss: 1.051961]\n",
      "176 [D loss: 0.304973, acc: 74.22%, op_acc: 39.84%] [G loss: 1.087554]\n",
      "177 [D loss: 0.293427, acc: 75.00%, op_acc: 42.19%] [G loss: 1.051859]\n",
      "178 [D loss: 0.323555, acc: 67.97%, op_acc: 49.22%] [G loss: 1.052030]\n",
      "179 [D loss: 0.305890, acc: 67.97%, op_acc: 42.19%] [G loss: 1.074568]\n",
      "180 [D loss: 0.317420, acc: 71.09%, op_acc: 41.41%] [G loss: 1.148004]\n",
      "Epoch: 180, F1: 0.00000, F1P: 18\n",
      "[[28430     2]\n",
      " [   49     0]]\n",
      "70.9375\n",
      "181 [D loss: 0.306980, acc: 74.22%, op_acc: 46.09%] [G loss: 1.042901]\n",
      "182 [D loss: 0.316241, acc: 63.28%, op_acc: 43.75%] [G loss: 1.008052]\n",
      "183 [D loss: 0.299142, acc: 75.78%, op_acc: 42.19%] [G loss: 1.090313]\n",
      "184 [D loss: 0.326754, acc: 67.19%, op_acc: 38.28%] [G loss: 1.115747]\n",
      "185 [D loss: 0.309637, acc: 74.22%, op_acc: 43.75%] [G loss: 1.026594]\n",
      "186 [D loss: 0.311446, acc: 72.66%, op_acc: 44.53%] [G loss: 1.104303]\n",
      "187 [D loss: 0.321375, acc: 64.84%, op_acc: 38.28%] [G loss: 1.042395]\n",
      "188 [D loss: 0.312592, acc: 72.66%, op_acc: 43.75%] [G loss: 1.076839]\n",
      "189 [D loss: 0.287353, acc: 76.56%, op_acc: 45.31%] [G loss: 1.085985]\n",
      "190 [D loss: 0.318171, acc: 67.19%, op_acc: 40.62%] [G loss: 1.102480]\n",
      "Epoch: 190, F1: 0.00000, F1P: 19\n",
      "[[28430     2]\n",
      " [   49     0]]\n",
      "70.859375\n",
      "191 [D loss: 0.287807, acc: 72.66%, op_acc: 33.59%] [G loss: 1.009864]\n",
      "192 [D loss: 0.299142, acc: 74.22%, op_acc: 35.94%] [G loss: 0.999926]\n",
      "193 [D loss: 0.299029, acc: 73.44%, op_acc: 50.78%] [G loss: 1.033181]\n",
      "194 [D loss: 0.299660, acc: 72.66%, op_acc: 39.84%] [G loss: 1.017392]\n",
      "195 [D loss: 0.299674, acc: 72.66%, op_acc: 43.75%] [G loss: 1.012088]\n",
      "196 [D loss: 0.296673, acc: 72.66%, op_acc: 39.84%] [G loss: 1.084815]\n",
      "197 [D loss: 0.307531, acc: 75.00%, op_acc: 38.28%] [G loss: 1.033438]\n",
      "198 [D loss: 0.317277, acc: 70.31%, op_acc: 46.09%] [G loss: 1.019937]\n",
      "199 [D loss: 0.305856, acc: 72.66%, op_acc: 48.44%] [G loss: 1.042290]\n",
      "200 [D loss: 0.344911, acc: 69.53%, op_acc: 41.41%] [G loss: 1.034585]\n",
      "Epoch: 200, F1: 0.00000, F1P: 20\n",
      "[[28430     2]\n",
      " [   49     0]]\n",
      "72.578125\n",
      "201 [D loss: 0.303101, acc: 71.88%, op_acc: 48.44%] [G loss: 1.077633]\n",
      "202 [D loss: 0.331410, acc: 71.09%, op_acc: 42.97%] [G loss: 1.073937]\n",
      "203 [D loss: 0.313311, acc: 71.09%, op_acc: 43.75%] [G loss: 1.055629]\n",
      "204 [D loss: 0.310415, acc: 67.97%, op_acc: 47.66%] [G loss: 1.052723]\n",
      "205 [D loss: 0.300609, acc: 77.34%, op_acc: 45.31%] [G loss: 1.092613]\n",
      "206 [D loss: 0.307944, acc: 75.00%, op_acc: 41.41%] [G loss: 1.036653]\n",
      "207 [D loss: 0.298108, acc: 74.22%, op_acc: 41.41%] [G loss: 1.076483]\n",
      "208 [D loss: 0.293311, acc: 75.78%, op_acc: 41.41%] [G loss: 1.012813]\n",
      "209 [D loss: 0.285044, acc: 81.25%, op_acc: 50.00%] [G loss: 1.120323]\n",
      "210 [D loss: 0.296022, acc: 74.22%, op_acc: 41.41%] [G loss: 1.006379]\n",
      "Epoch: 210, F1: 0.00000, F1P: 21\n",
      "[[28429     3]\n",
      " [   49     0]]\n",
      "73.984375\n",
      "211 [D loss: 0.299133, acc: 75.78%, op_acc: 48.44%] [G loss: 1.135028]\n",
      "212 [D loss: 0.306946, acc: 74.22%, op_acc: 44.53%] [G loss: 1.070114]\n",
      "213 [D loss: 0.307134, acc: 72.66%, op_acc: 37.50%] [G loss: 1.022904]\n",
      "214 [D loss: 0.292120, acc: 75.78%, op_acc: 39.84%] [G loss: 1.108855]\n",
      "215 [D loss: 0.295791, acc: 75.00%, op_acc: 42.97%] [G loss: 1.081371]\n",
      "216 [D loss: 0.298438, acc: 77.34%, op_acc: 49.22%] [G loss: 1.039620]\n",
      "217 [D loss: 0.315475, acc: 75.00%, op_acc: 43.75%] [G loss: 1.092414]\n",
      "218 [D loss: 0.300974, acc: 75.78%, op_acc: 51.56%] [G loss: 1.110738]\n",
      "219 [D loss: 0.301086, acc: 71.88%, op_acc: 47.66%] [G loss: 1.051970]\n",
      "220 [D loss: 0.300857, acc: 71.88%, op_acc: 42.97%] [G loss: 1.094559]\n",
      "Epoch: 220, F1: 0.00000, F1P: 22\n",
      "[[28429     3]\n",
      " [   49     0]]\n",
      "74.53125\n",
      "221 [D loss: 0.313024, acc: 70.31%, op_acc: 41.41%] [G loss: 1.113880]\n",
      "222 [D loss: 0.310125, acc: 69.53%, op_acc: 45.31%] [G loss: 1.119472]\n",
      "223 [D loss: 0.283736, acc: 81.25%, op_acc: 48.44%] [G loss: 1.037263]\n",
      "224 [D loss: 0.303820, acc: 72.66%, op_acc: 45.31%] [G loss: 1.069299]\n",
      "225 [D loss: 0.318595, acc: 72.66%, op_acc: 39.84%] [G loss: 1.078164]\n",
      "226 [D loss: 0.287366, acc: 79.69%, op_acc: 42.19%] [G loss: 0.991122]\n",
      "227 [D loss: 0.313027, acc: 68.75%, op_acc: 42.97%] [G loss: 1.016950]\n",
      "228 [D loss: 0.296739, acc: 78.12%, op_acc: 50.00%] [G loss: 1.012493]\n",
      "229 [D loss: 0.316743, acc: 67.19%, op_acc: 39.84%] [G loss: 1.064115]\n",
      "230 [D loss: 0.292322, acc: 78.91%, op_acc: 44.53%] [G loss: 1.056528]\n",
      "Epoch: 230, F1: 0.00000, F1P: 23\n",
      "[[28428     4]\n",
      " [   49     0]]\n",
      "73.90625\n",
      "231 [D loss: 0.316052, acc: 68.75%, op_acc: 40.62%] [G loss: 1.008793]\n",
      "232 [D loss: 0.314139, acc: 69.53%, op_acc: 45.31%] [G loss: 0.959397]\n",
      "233 [D loss: 0.285890, acc: 78.91%, op_acc: 51.56%] [G loss: 1.087099]\n",
      "234 [D loss: 0.284334, acc: 75.78%, op_acc: 40.62%] [G loss: 1.022306]\n",
      "235 [D loss: 0.303028, acc: 77.34%, op_acc: 45.31%] [G loss: 1.104272]\n",
      "236 [D loss: 0.290060, acc: 77.34%, op_acc: 48.44%] [G loss: 1.040865]\n",
      "237 [D loss: 0.295690, acc: 78.12%, op_acc: 39.84%] [G loss: 0.989168]\n",
      "238 [D loss: 0.287467, acc: 78.91%, op_acc: 48.44%] [G loss: 1.036538]\n",
      "239 [D loss: 0.301636, acc: 77.34%, op_acc: 36.72%] [G loss: 1.010173]\n",
      "240 [D loss: 0.291267, acc: 75.00%, op_acc: 49.22%] [G loss: 1.019391]\n",
      "Epoch: 240, F1: 0.00000, F1P: 24\n",
      "[[28428     4]\n",
      " [   49     0]]\n",
      "75.703125\n",
      "241 [D loss: 0.305122, acc: 75.00%, op_acc: 43.75%] [G loss: 1.005698]\n",
      "242 [D loss: 0.294105, acc: 75.00%, op_acc: 44.53%] [G loss: 1.082733]\n",
      "243 [D loss: 0.288119, acc: 75.00%, op_acc: 44.53%] [G loss: 1.004730]\n",
      "244 [D loss: 0.306259, acc: 75.78%, op_acc: 45.31%] [G loss: 1.077973]\n",
      "245 [D loss: 0.304997, acc: 75.00%, op_acc: 42.97%] [G loss: 1.038407]\n",
      "246 [D loss: 0.282989, acc: 78.12%, op_acc: 46.88%] [G loss: 0.976691]\n",
      "247 [D loss: 0.308091, acc: 68.75%, op_acc: 44.53%] [G loss: 1.001576]\n",
      "248 [D loss: 0.291681, acc: 74.22%, op_acc: 43.75%] [G loss: 1.079229]\n",
      "249 [D loss: 0.285699, acc: 80.47%, op_acc: 43.75%] [G loss: 1.058598]\n",
      "250 [D loss: 0.304020, acc: 78.12%, op_acc: 46.88%] [G loss: 0.997330]\n",
      "Epoch: 250, F1: 0.00000, F1P: 25\n",
      "[[28428     4]\n",
      " [   49     0]]\n",
      "75.546875\n",
      "251 [D loss: 0.304296, acc: 72.66%, op_acc: 43.75%] [G loss: 1.072890]\n",
      "252 [D loss: 0.295102, acc: 75.78%, op_acc: 47.66%] [G loss: 1.080564]\n",
      "253 [D loss: 0.294059, acc: 79.69%, op_acc: 51.56%] [G loss: 1.055815]\n",
      "254 [D loss: 0.290536, acc: 77.34%, op_acc: 44.53%] [G loss: 1.067594]\n",
      "255 [D loss: 0.298990, acc: 73.44%, op_acc: 44.53%] [G loss: 1.091273]\n",
      "256 [D loss: 0.268693, acc: 84.38%, op_acc: 49.22%] [G loss: 1.037931]\n",
      "257 [D loss: 0.285301, acc: 75.78%, op_acc: 45.31%] [G loss: 1.004798]\n",
      "258 [D loss: 0.278790, acc: 82.03%, op_acc: 48.44%] [G loss: 1.010465]\n",
      "259 [D loss: 0.301579, acc: 72.66%, op_acc: 44.53%] [G loss: 1.023505]\n",
      "260 [D loss: 0.310232, acc: 74.22%, op_acc: 49.22%] [G loss: 1.080249]\n",
      "Epoch: 260, F1: 0.00000, F1P: 26\n",
      "[[28425     7]\n",
      " [   49     0]]\n",
      "76.796875\n",
      "261 [D loss: 0.290130, acc: 78.91%, op_acc: 45.31%] [G loss: 1.044744]\n",
      "262 [D loss: 0.284116, acc: 77.34%, op_acc: 45.31%] [G loss: 1.064598]\n",
      "263 [D loss: 0.294493, acc: 75.78%, op_acc: 42.97%] [G loss: 1.065311]\n",
      "264 [D loss: 0.289808, acc: 74.22%, op_acc: 49.22%] [G loss: 1.091248]\n",
      "265 [D loss: 0.293065, acc: 73.44%, op_acc: 46.88%] [G loss: 1.053088]\n",
      "266 [D loss: 0.283464, acc: 81.25%, op_acc: 45.31%] [G loss: 1.029728]\n",
      "267 [D loss: 0.277919, acc: 80.47%, op_acc: 49.22%] [G loss: 1.020392]\n",
      "268 [D loss: 0.295940, acc: 75.00%, op_acc: 43.75%] [G loss: 1.067377]\n",
      "269 [D loss: 0.289280, acc: 75.78%, op_acc: 41.41%] [G loss: 1.001013]\n",
      "270 [D loss: 0.288021, acc: 75.78%, op_acc: 52.34%] [G loss: 1.083887]\n",
      "Epoch: 270, F1: 0.00000, F1P: 27\n",
      "[[28424     8]\n",
      " [   49     0]]\n",
      "76.796875\n",
      "271 [D loss: 0.281361, acc: 81.25%, op_acc: 43.75%] [G loss: 1.045328]\n",
      "272 [D loss: 0.281226, acc: 81.25%, op_acc: 46.09%] [G loss: 1.066437]\n",
      "273 [D loss: 0.282955, acc: 78.91%, op_acc: 48.44%] [G loss: 1.099796]\n",
      "274 [D loss: 0.277263, acc: 81.25%, op_acc: 46.88%] [G loss: 1.090819]\n",
      "275 [D loss: 0.289890, acc: 76.56%, op_acc: 43.75%] [G loss: 1.107677]\n",
      "276 [D loss: 0.296111, acc: 76.56%, op_acc: 42.19%] [G loss: 1.013802]\n",
      "277 [D loss: 0.294316, acc: 76.56%, op_acc: 43.75%] [G loss: 1.068015]\n",
      "278 [D loss: 0.279267, acc: 80.47%, op_acc: 47.66%] [G loss: 1.037515]\n",
      "279 [D loss: 0.275471, acc: 85.16%, op_acc: 46.88%] [G loss: 1.052112]\n",
      "280 [D loss: 0.309816, acc: 70.31%, op_acc: 42.97%] [G loss: 1.073649]\n",
      "Epoch: 280, F1: 0.00000, F1P: 28\n",
      "[[28408    24]\n",
      " [   49     0]]\n",
      "78.828125\n",
      "281 [D loss: 0.273593, acc: 81.25%, op_acc: 42.19%] [G loss: 1.024380]\n",
      "282 [D loss: 0.288832, acc: 74.22%, op_acc: 47.66%] [G loss: 1.045947]\n",
      "283 [D loss: 0.286555, acc: 79.69%, op_acc: 49.22%] [G loss: 1.081957]\n",
      "284 [D loss: 0.287487, acc: 78.12%, op_acc: 46.09%] [G loss: 1.085070]\n",
      "285 [D loss: 0.286034, acc: 84.38%, op_acc: 52.34%] [G loss: 1.074963]\n",
      "286 [D loss: 0.280611, acc: 80.47%, op_acc: 47.66%] [G loss: 1.002218]\n",
      "287 [D loss: 0.277060, acc: 78.91%, op_acc: 47.66%] [G loss: 1.020250]\n",
      "288 [D loss: 0.281106, acc: 74.22%, op_acc: 46.88%] [G loss: 1.066789]\n",
      "289 [D loss: 0.302738, acc: 74.22%, op_acc: 42.97%] [G loss: 1.038122]\n",
      "290 [D loss: 0.277014, acc: 78.91%, op_acc: 53.12%] [G loss: 1.011070]\n",
      "Epoch: 290, F1: 0.01980, F1P: 29\n",
      "[[28381    51]\n",
      " [   48     1]]\n",
      "78.4375\n",
      "291 [D loss: 0.280095, acc: 80.47%, op_acc: 50.78%] [G loss: 1.019758]\n",
      "292 [D loss: 0.285217, acc: 78.12%, op_acc: 52.34%] [G loss: 1.020959]\n",
      "293 [D loss: 0.283837, acc: 75.78%, op_acc: 46.09%] [G loss: 1.025867]\n",
      "294 [D loss: 0.280689, acc: 76.56%, op_acc: 47.66%] [G loss: 1.067795]\n",
      "295 [D loss: 0.289849, acc: 75.00%, op_acc: 44.53%] [G loss: 1.086949]\n",
      "296 [D loss: 0.285443, acc: 80.47%, op_acc: 49.22%] [G loss: 1.049690]\n",
      "297 [D loss: 0.278552, acc: 80.47%, op_acc: 47.66%] [G loss: 1.012771]\n",
      "298 [D loss: 0.283572, acc: 77.34%, op_acc: 45.31%] [G loss: 1.042909]\n",
      "299 [D loss: 0.290257, acc: 75.00%, op_acc: 46.88%] [G loss: 1.014365]\n",
      "300 [D loss: 0.287472, acc: 73.44%, op_acc: 45.31%] [G loss: 1.051807]\n",
      "Epoch: 300, F1: 0.05970, F1P: 30\n",
      "[[28286   146]\n",
      " [   43     6]]\n",
      "77.265625\n",
      "301 [D loss: 0.301393, acc: 74.22%, op_acc: 41.41%] [G loss: 1.048114]\n",
      "302 [D loss: 0.275262, acc: 82.81%, op_acc: 46.09%] [G loss: 1.000828]\n",
      "303 [D loss: 0.307046, acc: 72.66%, op_acc: 48.44%] [G loss: 0.968331]\n",
      "304 [D loss: 0.301723, acc: 78.91%, op_acc: 50.78%] [G loss: 1.045845]\n",
      "305 [D loss: 0.280182, acc: 80.47%, op_acc: 47.66%] [G loss: 1.052490]\n",
      "306 [D loss: 0.290207, acc: 76.56%, op_acc: 42.19%] [G loss: 1.025624]\n",
      "307 [D loss: 0.270293, acc: 85.16%, op_acc: 45.31%] [G loss: 1.035074]\n",
      "308 [D loss: 0.283214, acc: 76.56%, op_acc: 49.22%] [G loss: 1.059183]\n",
      "309 [D loss: 0.284806, acc: 77.34%, op_acc: 44.53%] [G loss: 1.020229]\n",
      "310 [D loss: 0.291551, acc: 81.25%, op_acc: 50.00%] [G loss: 0.969244]\n",
      "Epoch: 310, F1: 0.07123, F1P: 31\n",
      "[[28129   303]\n",
      " [   36    13]]\n",
      "78.59375\n",
      "311 [D loss: 0.286284, acc: 76.56%, op_acc: 46.88%] [G loss: 1.006774]\n",
      "312 [D loss: 0.299883, acc: 71.09%, op_acc: 37.50%] [G loss: 1.003373]\n",
      "313 [D loss: 0.291915, acc: 75.00%, op_acc: 49.22%] [G loss: 0.980857]\n",
      "314 [D loss: 0.284890, acc: 76.56%, op_acc: 42.97%] [G loss: 1.051688]\n",
      "315 [D loss: 0.309636, acc: 75.78%, op_acc: 50.00%] [G loss: 1.021963]\n",
      "316 [D loss: 0.311158, acc: 72.66%, op_acc: 41.41%] [G loss: 0.997996]\n",
      "317 [D loss: 0.277988, acc: 79.69%, op_acc: 48.44%] [G loss: 1.062764]\n",
      "318 [D loss: 0.279585, acc: 78.91%, op_acc: 51.56%] [G loss: 1.011647]\n",
      "319 [D loss: 0.282850, acc: 80.47%, op_acc: 57.03%] [G loss: 0.953582]\n",
      "320 [D loss: 0.283444, acc: 78.12%, op_acc: 45.31%] [G loss: 1.072127]\n",
      "Epoch: 320, F1: 0.08264, F1P: 32\n",
      "[[28133   299]\n",
      " [   34    15]]\n",
      "76.484375\n",
      "321 [D loss: 0.286368, acc: 78.91%, op_acc: 41.41%] [G loss: 1.041117]\n",
      "322 [D loss: 0.289203, acc: 77.34%, op_acc: 47.66%] [G loss: 1.015426]\n",
      "323 [D loss: 0.293727, acc: 75.00%, op_acc: 55.47%] [G loss: 0.958968]\n",
      "324 [D loss: 0.294844, acc: 80.47%, op_acc: 46.88%] [G loss: 1.053059]\n",
      "325 [D loss: 0.297885, acc: 73.44%, op_acc: 46.09%] [G loss: 1.011864]\n",
      "326 [D loss: 0.294555, acc: 73.44%, op_acc: 47.66%] [G loss: 1.048580]\n",
      "327 [D loss: 0.298797, acc: 75.00%, op_acc: 42.97%] [G loss: 1.023083]\n",
      "328 [D loss: 0.288994, acc: 76.56%, op_acc: 50.78%] [G loss: 0.993977]\n",
      "329 [D loss: 0.296159, acc: 75.78%, op_acc: 46.88%] [G loss: 1.017270]\n",
      "330 [D loss: 0.286817, acc: 78.91%, op_acc: 53.12%] [G loss: 1.083147]\n",
      "Epoch: 330, F1: 0.08995, F1P: 33\n",
      "[[28120   312]\n",
      " [   32    17]]\n",
      "76.484375\n",
      "331 [D loss: 0.290729, acc: 77.34%, op_acc: 50.00%] [G loss: 1.040942]\n",
      "332 [D loss: 0.296973, acc: 75.78%, op_acc: 46.88%] [G loss: 0.975163]\n",
      "333 [D loss: 0.288507, acc: 78.91%, op_acc: 50.78%] [G loss: 1.075896]\n",
      "334 [D loss: 0.280947, acc: 79.69%, op_acc: 50.00%] [G loss: 1.045978]\n",
      "335 [D loss: 0.289675, acc: 78.91%, op_acc: 45.31%] [G loss: 1.018751]\n",
      "336 [D loss: 0.303020, acc: 70.31%, op_acc: 46.88%] [G loss: 1.066928]\n",
      "337 [D loss: 0.285167, acc: 75.78%, op_acc: 46.09%] [G loss: 0.957095]\n",
      "338 [D loss: 0.305244, acc: 78.12%, op_acc: 53.91%] [G loss: 0.974367]\n",
      "339 [D loss: 0.295113, acc: 78.12%, op_acc: 46.09%] [G loss: 1.038385]\n",
      "340 [D loss: 0.292873, acc: 74.22%, op_acc: 52.34%] [G loss: 0.950842]\n",
      "Epoch: 340, F1: 0.09547, F1P: 34\n",
      "[[28082   350]\n",
      " [   29    20]]\n",
      "76.71875\n",
      "341 [D loss: 0.291207, acc: 73.44%, op_acc: 46.09%] [G loss: 1.042613]\n",
      "342 [D loss: 0.303585, acc: 75.00%, op_acc: 49.22%] [G loss: 1.003062]\n",
      "343 [D loss: 0.284193, acc: 79.69%, op_acc: 54.69%] [G loss: 0.976946]\n",
      "344 [D loss: 0.289677, acc: 73.44%, op_acc: 51.56%] [G loss: 0.952752]\n",
      "345 [D loss: 0.296271, acc: 76.56%, op_acc: 52.34%] [G loss: 0.999908]\n",
      "346 [D loss: 0.299818, acc: 70.31%, op_acc: 45.31%] [G loss: 1.035942]\n",
      "347 [D loss: 0.306903, acc: 71.09%, op_acc: 50.00%] [G loss: 1.028342]\n",
      "348 [D loss: 0.272044, acc: 78.12%, op_acc: 47.66%] [G loss: 1.063901]\n",
      "349 [D loss: 0.288321, acc: 75.78%, op_acc: 49.22%] [G loss: 0.945530]\n",
      "350 [D loss: 0.288307, acc: 75.00%, op_acc: 50.78%] [G loss: 1.024634]\n",
      "Epoch: 350, F1: 0.13125, F1P: 35\n",
      "[[28182   250]\n",
      " [   28    21]]\n",
      "74.84375\n",
      "351 [D loss: 0.291460, acc: 73.44%, op_acc: 42.19%] [G loss: 1.030784]\n",
      "352 [D loss: 0.287901, acc: 76.56%, op_acc: 52.34%] [G loss: 0.992791]\n",
      "353 [D loss: 0.300219, acc: 74.22%, op_acc: 50.00%] [G loss: 0.984996]\n",
      "354 [D loss: 0.291248, acc: 78.91%, op_acc: 49.22%] [G loss: 1.034039]\n",
      "355 [D loss: 0.303116, acc: 71.88%, op_acc: 50.78%] [G loss: 1.083676]\n",
      "356 [D loss: 0.295813, acc: 73.44%, op_acc: 52.34%] [G loss: 0.982689]\n",
      "357 [D loss: 0.297192, acc: 75.78%, op_acc: 49.22%] [G loss: 0.923642]\n",
      "358 [D loss: 0.285048, acc: 75.00%, op_acc: 52.34%] [G loss: 1.026580]\n",
      "359 [D loss: 0.298502, acc: 76.56%, op_acc: 51.56%] [G loss: 1.006142]\n",
      "360 [D loss: 0.287253, acc: 75.78%, op_acc: 44.53%] [G loss: 0.968596]\n",
      "Epoch: 360, F1: 0.18884, F1P: 36\n",
      "[[28270   162]\n",
      " [   27    22]]\n",
      "75.15625\n",
      "361 [D loss: 0.303285, acc: 73.44%, op_acc: 50.00%] [G loss: 1.026785]\n",
      "362 [D loss: 0.298370, acc: 73.44%, op_acc: 57.81%] [G loss: 1.006139]\n",
      "363 [D loss: 0.307880, acc: 73.44%, op_acc: 50.78%] [G loss: 0.980509]\n",
      "364 [D loss: 0.292524, acc: 74.22%, op_acc: 52.34%] [G loss: 0.981441]\n",
      "365 [D loss: 0.309266, acc: 67.19%, op_acc: 49.22%] [G loss: 0.909140]\n",
      "366 [D loss: 0.296987, acc: 78.91%, op_acc: 49.22%] [G loss: 1.001556]\n",
      "367 [D loss: 0.293911, acc: 73.44%, op_acc: 49.22%] [G loss: 0.970414]\n",
      "368 [D loss: 0.295149, acc: 72.66%, op_acc: 50.78%] [G loss: 0.961527]\n",
      "369 [D loss: 0.300781, acc: 72.66%, op_acc: 50.00%] [G loss: 0.966180]\n",
      "370 [D loss: 0.299571, acc: 71.88%, op_acc: 46.09%] [G loss: 0.991883]\n",
      "Epoch: 370, F1: 0.23280, F1P: 37\n",
      "[[28314   118]\n",
      " [   27    22]]\n",
      "73.125\n",
      "371 [D loss: 0.299368, acc: 73.44%, op_acc: 47.66%] [G loss: 1.041228]\n",
      "372 [D loss: 0.298557, acc: 76.56%, op_acc: 48.44%] [G loss: 0.943053]\n",
      "373 [D loss: 0.290978, acc: 73.44%, op_acc: 50.00%] [G loss: 0.986521]\n",
      "374 [D loss: 0.287319, acc: 74.22%, op_acc: 50.78%] [G loss: 0.991748]\n",
      "375 [D loss: 0.302056, acc: 72.66%, op_acc: 53.12%] [G loss: 0.986428]\n",
      "376 [D loss: 0.293287, acc: 76.56%, op_acc: 51.56%] [G loss: 1.047361]\n",
      "377 [D loss: 0.295731, acc: 72.66%, op_acc: 53.12%] [G loss: 1.008415]\n",
      "378 [D loss: 0.301219, acc: 73.44%, op_acc: 46.09%] [G loss: 0.907567]\n",
      "379 [D loss: 0.295597, acc: 77.34%, op_acc: 50.00%] [G loss: 1.009135]\n",
      "380 [D loss: 0.289985, acc: 78.12%, op_acc: 48.44%] [G loss: 0.930856]\n",
      "Epoch: 380, F1: 0.25698, F1P: 38\n",
      "[[28325   107]\n",
      " [   26    23]]\n",
      "74.84375\n",
      "381 [D loss: 0.290143, acc: 76.56%, op_acc: 57.03%] [G loss: 0.984347]\n",
      "382 [D loss: 0.292000, acc: 71.09%, op_acc: 50.78%] [G loss: 1.057750]\n",
      "383 [D loss: 0.292556, acc: 79.69%, op_acc: 46.09%] [G loss: 1.048715]\n",
      "384 [D loss: 0.282357, acc: 74.22%, op_acc: 50.00%] [G loss: 1.025331]\n",
      "385 [D loss: 0.295493, acc: 78.12%, op_acc: 46.88%] [G loss: 1.005355]\n",
      "386 [D loss: 0.303251, acc: 76.56%, op_acc: 54.69%] [G loss: 1.055915]\n",
      "387 [D loss: 0.268881, acc: 84.38%, op_acc: 60.94%] [G loss: 1.005992]\n",
      "388 [D loss: 0.298724, acc: 73.44%, op_acc: 53.91%] [G loss: 0.977168]\n",
      "389 [D loss: 0.298824, acc: 78.12%, op_acc: 54.69%] [G loss: 0.981523]\n",
      "390 [D loss: 0.293739, acc: 72.66%, op_acc: 55.47%] [G loss: 0.971310]\n",
      "Epoch: 390, F1: 0.41739, F1P: 39\n",
      "[[28390    42]\n",
      " [   25    24]]\n",
      "76.484375\n",
      "391 [D loss: 0.288794, acc: 77.34%, op_acc: 55.47%] [G loss: 1.062617]\n",
      "392 [D loss: 0.284732, acc: 75.78%, op_acc: 55.47%] [G loss: 1.020045]\n",
      "393 [D loss: 0.289758, acc: 72.66%, op_acc: 50.00%] [G loss: 1.062219]\n",
      "394 [D loss: 0.305565, acc: 71.88%, op_acc: 57.03%] [G loss: 0.996900]\n",
      "395 [D loss: 0.304962, acc: 71.09%, op_acc: 50.78%] [G loss: 0.965722]\n",
      "396 [D loss: 0.292008, acc: 78.12%, op_acc: 51.56%] [G loss: 0.960257]\n",
      "397 [D loss: 0.313895, acc: 69.53%, op_acc: 47.66%] [G loss: 0.988696]\n",
      "398 [D loss: 0.288558, acc: 75.00%, op_acc: 50.00%] [G loss: 0.971609]\n",
      "399 [D loss: 0.296299, acc: 78.91%, op_acc: 53.12%] [G loss: 0.961278]\n",
      "400 [D loss: 0.298345, acc: 77.34%, op_acc: 56.25%] [G loss: 0.982306]\n",
      "Epoch: 400, F1: 0.56311, F1P: 40\n",
      "[[28407    25]\n",
      " [   20    29]]\n",
      "74.765625\n",
      "401 [D loss: 0.280656, acc: 82.81%, op_acc: 55.47%] [G loss: 1.010085]\n",
      "402 [D loss: 0.296068, acc: 78.91%, op_acc: 53.12%] [G loss: 1.020093]\n",
      "403 [D loss: 0.283392, acc: 81.25%, op_acc: 51.56%] [G loss: 1.014885]\n",
      "404 [D loss: 0.303131, acc: 73.44%, op_acc: 52.34%] [G loss: 0.992198]\n",
      "405 [D loss: 0.289969, acc: 74.22%, op_acc: 55.47%] [G loss: 1.020675]\n",
      "406 [D loss: 0.281509, acc: 78.91%, op_acc: 48.44%] [G loss: 0.933514]\n",
      "407 [D loss: 0.278416, acc: 81.25%, op_acc: 48.44%] [G loss: 0.991604]\n",
      "408 [D loss: 0.281816, acc: 76.56%, op_acc: 57.81%] [G loss: 1.010670]\n",
      "409 [D loss: 0.306490, acc: 75.78%, op_acc: 53.91%] [G loss: 1.014069]\n",
      "410 [D loss: 0.290666, acc: 77.34%, op_acc: 60.16%] [G loss: 0.991337]\n",
      "Epoch: 410, F1: 0.62222, F1P: 41\n",
      "[[28419    13]\n",
      " [   21    28]]\n",
      "78.046875\n",
      "411 [D loss: 0.314026, acc: 65.62%, op_acc: 50.00%] [G loss: 1.010410]\n",
      "412 [D loss: 0.279691, acc: 79.69%, op_acc: 57.03%] [G loss: 1.048103]\n",
      "413 [D loss: 0.300718, acc: 73.44%, op_acc: 50.00%] [G loss: 1.001776]\n",
      "414 [D loss: 0.280021, acc: 78.12%, op_acc: 50.00%] [G loss: 0.948231]\n",
      "415 [D loss: 0.303950, acc: 76.56%, op_acc: 53.12%] [G loss: 1.023891]\n",
      "416 [D loss: 0.311165, acc: 68.75%, op_acc: 52.34%] [G loss: 1.016261]\n",
      "417 [D loss: 0.302778, acc: 72.66%, op_acc: 43.75%] [G loss: 0.968107]\n",
      "418 [D loss: 0.292817, acc: 71.88%, op_acc: 54.69%] [G loss: 1.002460]\n",
      "419 [D loss: 0.292666, acc: 75.78%, op_acc: 53.12%] [G loss: 0.964506]\n",
      "420 [D loss: 0.287095, acc: 71.09%, op_acc: 53.12%] [G loss: 0.925919]\n",
      "Epoch: 420, F1: 0.65116, F1P: 42\n",
      "[[28423     9]\n",
      " [   21    28]]\n",
      "73.359375\n",
      "421 [D loss: 0.291955, acc: 74.22%, op_acc: 53.12%] [G loss: 1.035968]\n",
      "422 [D loss: 0.289932, acc: 78.91%, op_acc: 53.12%] [G loss: 1.041205]\n",
      "423 [D loss: 0.316615, acc: 73.44%, op_acc: 53.91%] [G loss: 0.987315]\n",
      "424 [D loss: 0.275500, acc: 81.25%, op_acc: 56.25%] [G loss: 0.958500]\n",
      "425 [D loss: 0.300451, acc: 75.00%, op_acc: 56.25%] [G loss: 1.029680]\n",
      "426 [D loss: 0.310272, acc: 68.75%, op_acc: 50.00%] [G loss: 1.049735]\n",
      "427 [D loss: 0.292587, acc: 69.53%, op_acc: 49.22%] [G loss: 0.993559]\n",
      "428 [D loss: 0.283436, acc: 78.12%, op_acc: 52.34%] [G loss: 1.002590]\n",
      "429 [D loss: 0.288207, acc: 75.78%, op_acc: 49.22%] [G loss: 1.075027]\n",
      "430 [D loss: 0.281591, acc: 80.47%, op_acc: 55.47%] [G loss: 1.009786]\n",
      "Epoch: 430, F1: 0.65882, F1P: 43\n",
      "[[28424     8]\n",
      " [   21    28]]\n",
      "75.546875\n",
      "431 [D loss: 0.297529, acc: 78.91%, op_acc: 53.91%] [G loss: 0.988562]\n",
      "432 [D loss: 0.258268, acc: 85.16%, op_acc: 52.34%] [G loss: 1.011167]\n",
      "433 [D loss: 0.308744, acc: 69.53%, op_acc: 56.25%] [G loss: 1.044721]\n",
      "434 [D loss: 0.307931, acc: 70.31%, op_acc: 52.34%] [G loss: 0.979864]\n",
      "435 [D loss: 0.295942, acc: 73.44%, op_acc: 57.81%] [G loss: 1.072181]\n",
      "436 [D loss: 0.287606, acc: 80.47%, op_acc: 53.12%] [G loss: 0.988133]\n",
      "437 [D loss: 0.279478, acc: 81.25%, op_acc: 52.34%] [G loss: 1.059627]\n",
      "438 [D loss: 0.292216, acc: 77.34%, op_acc: 53.91%] [G loss: 0.972643]\n",
      "439 [D loss: 0.311804, acc: 66.41%, op_acc: 48.44%] [G loss: 1.018391]\n",
      "440 [D loss: 0.290799, acc: 75.78%, op_acc: 54.69%] [G loss: 1.027212]\n",
      "Epoch: 440, F1: 0.64286, F1P: 44\n",
      "[[28424     8]\n",
      " [   22    27]]\n",
      "75.859375\n",
      "441 [D loss: 0.280683, acc: 82.03%, op_acc: 57.03%] [G loss: 1.059005]\n",
      "442 [D loss: 0.293717, acc: 75.78%, op_acc: 54.69%] [G loss: 1.026249]\n",
      "443 [D loss: 0.289594, acc: 78.91%, op_acc: 54.69%] [G loss: 1.050648]\n",
      "444 [D loss: 0.286693, acc: 75.78%, op_acc: 53.12%] [G loss: 0.991909]\n",
      "445 [D loss: 0.307842, acc: 73.44%, op_acc: 49.22%] [G loss: 0.971252]\n",
      "446 [D loss: 0.289465, acc: 78.12%, op_acc: 49.22%] [G loss: 1.011866]\n",
      "447 [D loss: 0.287932, acc: 75.78%, op_acc: 51.56%] [G loss: 1.060142]\n",
      "448 [D loss: 0.290697, acc: 78.12%, op_acc: 48.44%] [G loss: 1.041558]\n",
      "449 [D loss: 0.295330, acc: 74.22%, op_acc: 54.69%] [G loss: 1.055032]\n",
      "450 [D loss: 0.287655, acc: 80.47%, op_acc: 51.56%] [G loss: 1.022224]\n",
      "Epoch: 450, F1: 0.65060, F1P: 45\n",
      "[[28425     7]\n",
      " [   22    27]]\n",
      "77.265625\n",
      "451 [D loss: 0.293900, acc: 78.12%, op_acc: 46.88%] [G loss: 1.031482]\n",
      "452 [D loss: 0.303807, acc: 75.00%, op_acc: 50.00%] [G loss: 0.998710]\n",
      "453 [D loss: 0.286672, acc: 78.91%, op_acc: 55.47%] [G loss: 0.973376]\n",
      "454 [D loss: 0.293925, acc: 73.44%, op_acc: 49.22%] [G loss: 1.038896]\n",
      "455 [D loss: 0.291511, acc: 75.00%, op_acc: 53.12%] [G loss: 0.998450]\n",
      "456 [D loss: 0.275959, acc: 78.91%, op_acc: 55.47%] [G loss: 1.033513]\n",
      "457 [D loss: 0.287291, acc: 77.34%, op_acc: 58.59%] [G loss: 1.036133]\n",
      "458 [D loss: 0.295226, acc: 70.31%, op_acc: 57.03%] [G loss: 1.031487]\n",
      "459 [D loss: 0.287854, acc: 77.34%, op_acc: 52.34%] [G loss: 0.997117]\n",
      "460 [D loss: 0.298761, acc: 67.97%, op_acc: 50.00%] [G loss: 1.017127]\n",
      "Epoch: 460, F1: 0.66667, F1P: 46\n",
      "[[28425     7]\n",
      " [   21    28]]\n",
      "75.234375\n",
      "461 [D loss: 0.299235, acc: 72.66%, op_acc: 52.34%] [G loss: 1.040827]\n",
      "462 [D loss: 0.282525, acc: 76.56%, op_acc: 51.56%] [G loss: 1.037455]\n",
      "463 [D loss: 0.275144, acc: 77.34%, op_acc: 53.91%] [G loss: 1.023897]\n",
      "464 [D loss: 0.284822, acc: 78.12%, op_acc: 53.12%] [G loss: 1.008131]\n",
      "465 [D loss: 0.296659, acc: 75.78%, op_acc: 53.12%] [G loss: 1.028241]\n",
      "466 [D loss: 0.286190, acc: 81.25%, op_acc: 55.47%] [G loss: 1.085860]\n",
      "467 [D loss: 0.297685, acc: 75.78%, op_acc: 55.47%] [G loss: 1.091600]\n",
      "468 [D loss: 0.307578, acc: 67.97%, op_acc: 53.12%] [G loss: 1.068062]\n",
      "469 [D loss: 0.283846, acc: 77.34%, op_acc: 54.69%] [G loss: 1.047270]\n",
      "470 [D loss: 0.286383, acc: 81.25%, op_acc: 57.03%] [G loss: 1.062545]\n",
      "Epoch: 470, F1: 0.66667, F1P: 47\n",
      "[[28425     7]\n",
      " [   21    28]]\n",
      "76.40625\n",
      "471 [D loss: 0.283042, acc: 77.34%, op_acc: 53.91%] [G loss: 1.013862]\n",
      "472 [D loss: 0.295808, acc: 77.34%, op_acc: 56.25%] [G loss: 1.019492]\n",
      "473 [D loss: 0.289387, acc: 78.91%, op_acc: 54.69%] [G loss: 1.084313]\n",
      "474 [D loss: 0.278647, acc: 81.25%, op_acc: 58.59%] [G loss: 1.098395]\n",
      "475 [D loss: 0.296953, acc: 75.78%, op_acc: 58.59%] [G loss: 1.019640]\n",
      "476 [D loss: 0.293707, acc: 78.91%, op_acc: 57.81%] [G loss: 1.029496]\n",
      "477 [D loss: 0.296947, acc: 76.56%, op_acc: 57.81%] [G loss: 1.054845]\n",
      "478 [D loss: 0.294315, acc: 71.09%, op_acc: 50.00%] [G loss: 1.102671]\n",
      "479 [D loss: 0.292122, acc: 80.47%, op_acc: 62.50%] [G loss: 1.025114]\n",
      "480 [D loss: 0.284134, acc: 74.22%, op_acc: 58.59%] [G loss: 1.058438]\n",
      "Epoch: 480, F1: 0.60759, F1P: 48\n",
      "[[28426     6]\n",
      " [   25    24]]\n",
      "77.1875\n",
      "481 [D loss: 0.300539, acc: 72.66%, op_acc: 57.03%] [G loss: 1.060193]\n",
      "482 [D loss: 0.283285, acc: 73.44%, op_acc: 52.34%] [G loss: 1.071488]\n",
      "483 [D loss: 0.281323, acc: 77.34%, op_acc: 59.38%] [G loss: 1.055604]\n",
      "484 [D loss: 0.287164, acc: 78.91%, op_acc: 52.34%] [G loss: 1.117940]\n",
      "485 [D loss: 0.294013, acc: 70.31%, op_acc: 52.34%] [G loss: 1.018615]\n",
      "486 [D loss: 0.286780, acc: 73.44%, op_acc: 51.56%] [G loss: 1.060774]\n",
      "487 [D loss: 0.292935, acc: 75.78%, op_acc: 52.34%] [G loss: 1.043222]\n",
      "488 [D loss: 0.295803, acc: 73.44%, op_acc: 53.91%] [G loss: 1.034995]\n",
      "489 [D loss: 0.274864, acc: 79.69%, op_acc: 51.56%] [G loss: 1.058513]\n",
      "490 [D loss: 0.298300, acc: 74.22%, op_acc: 61.72%] [G loss: 1.012089]\n",
      "Epoch: 490, F1: 0.64198, F1P: 49\n",
      "[[28426     6]\n",
      " [   23    26]]\n",
      "74.921875\n",
      "491 [D loss: 0.280543, acc: 78.91%, op_acc: 59.38%] [G loss: 1.125766]\n",
      "492 [D loss: 0.301364, acc: 74.22%, op_acc: 55.47%] [G loss: 0.997802]\n",
      "493 [D loss: 0.289748, acc: 75.78%, op_acc: 55.47%] [G loss: 1.057350]\n",
      "494 [D loss: 0.286949, acc: 78.91%, op_acc: 46.88%] [G loss: 1.070195]\n",
      "495 [D loss: 0.292292, acc: 78.91%, op_acc: 51.56%] [G loss: 1.029669]\n",
      "496 [D loss: 0.287511, acc: 77.34%, op_acc: 54.69%] [G loss: 1.040069]\n",
      "497 [D loss: 0.297121, acc: 74.22%, op_acc: 46.09%] [G loss: 1.042091]\n",
      "498 [D loss: 0.294951, acc: 75.00%, op_acc: 54.69%] [G loss: 1.077680]\n",
      "499 [D loss: 0.292466, acc: 75.78%, op_acc: 55.47%] [G loss: 1.044230]\n",
      "500 [D loss: 0.262769, acc: 85.16%, op_acc: 59.38%] [G loss: 1.043435]\n",
      "Epoch: 500, F1: 0.64198, F1P: 50\n",
      "[[28426     6]\n",
      " [   23    26]]\n",
      "77.421875\n",
      "501 [D loss: 0.292626, acc: 76.56%, op_acc: 50.00%] [G loss: 1.105295]\n",
      "502 [D loss: 0.288295, acc: 71.88%, op_acc: 50.00%] [G loss: 1.059654]\n",
      "503 [D loss: 0.283303, acc: 74.22%, op_acc: 54.69%] [G loss: 1.067840]\n",
      "504 [D loss: 0.285282, acc: 72.66%, op_acc: 51.56%] [G loss: 1.081671]\n",
      "505 [D loss: 0.279359, acc: 81.25%, op_acc: 57.81%] [G loss: 1.020452]\n",
      "506 [D loss: 0.285597, acc: 75.78%, op_acc: 56.25%] [G loss: 1.090634]\n",
      "507 [D loss: 0.291558, acc: 72.66%, op_acc: 56.25%] [G loss: 1.077865]\n",
      "508 [D loss: 0.290399, acc: 75.00%, op_acc: 54.69%] [G loss: 1.055304]\n",
      "509 [D loss: 0.292225, acc: 75.00%, op_acc: 48.44%] [G loss: 1.132422]\n",
      "510 [D loss: 0.296231, acc: 74.22%, op_acc: 52.34%] [G loss: 1.000869]\n",
      "Epoch: 510, F1: 0.62500, F1P: 51\n",
      "[[28426     6]\n",
      " [   24    25]]\n",
      "74.921875\n",
      "511 [D loss: 0.288884, acc: 77.34%, op_acc: 55.47%] [G loss: 1.044045]\n",
      "512 [D loss: 0.302770, acc: 75.78%, op_acc: 50.00%] [G loss: 1.050611]\n",
      "513 [D loss: 0.278120, acc: 82.03%, op_acc: 64.06%] [G loss: 1.046414]\n",
      "514 [D loss: 0.293609, acc: 71.09%, op_acc: 53.91%] [G loss: 1.054620]\n",
      "515 [D loss: 0.278514, acc: 80.47%, op_acc: 56.25%] [G loss: 1.030333]\n",
      "516 [D loss: 0.279872, acc: 75.78%, op_acc: 57.03%] [G loss: 1.156390]\n",
      "517 [D loss: 0.305378, acc: 71.09%, op_acc: 56.25%] [G loss: 1.061177]\n",
      "518 [D loss: 0.290743, acc: 78.12%, op_acc: 57.81%] [G loss: 1.080538]\n",
      "519 [D loss: 0.282928, acc: 78.91%, op_acc: 60.16%] [G loss: 1.097923]\n",
      "520 [D loss: 0.276894, acc: 76.56%, op_acc: 57.03%] [G loss: 1.134296]\n",
      "Epoch: 520, F1: 0.62500, F1P: 52\n",
      "[[28426     6]\n",
      " [   24    25]]\n",
      "76.71875\n",
      "521 [D loss: 0.268488, acc: 80.47%, op_acc: 57.03%] [G loss: 1.055973]\n",
      "522 [D loss: 0.282122, acc: 80.47%, op_acc: 55.47%] [G loss: 1.123981]\n",
      "523 [D loss: 0.291209, acc: 72.66%, op_acc: 53.91%] [G loss: 1.077134]\n",
      "524 [D loss: 0.299531, acc: 74.22%, op_acc: 59.38%] [G loss: 1.039729]\n",
      "525 [D loss: 0.278573, acc: 79.69%, op_acc: 57.81%] [G loss: 1.056368]\n",
      "526 [D loss: 0.280515, acc: 78.91%, op_acc: 59.38%] [G loss: 1.015707]\n",
      "527 [D loss: 0.285920, acc: 80.47%, op_acc: 56.25%] [G loss: 1.040802]\n",
      "528 [D loss: 0.283495, acc: 71.88%, op_acc: 53.91%] [G loss: 1.165697]\n",
      "529 [D loss: 0.286647, acc: 72.66%, op_acc: 53.12%] [G loss: 1.081387]\n",
      "530 [D loss: 0.290331, acc: 75.78%, op_acc: 55.47%] [G loss: 1.036320]\n",
      "Epoch: 530, F1: 0.62500, F1P: 53\n",
      "[[28426     6]\n",
      " [   24    25]]\n",
      "76.71875\n",
      "531 [D loss: 0.279763, acc: 75.78%, op_acc: 57.03%] [G loss: 1.098764]\n",
      "532 [D loss: 0.295669, acc: 73.44%, op_acc: 50.78%] [G loss: 1.111433]\n",
      "533 [D loss: 0.286946, acc: 75.00%, op_acc: 56.25%] [G loss: 1.028539]\n",
      "534 [D loss: 0.288847, acc: 78.12%, op_acc: 55.47%] [G loss: 1.031302]\n",
      "535 [D loss: 0.290291, acc: 80.47%, op_acc: 55.47%] [G loss: 1.069734]\n",
      "536 [D loss: 0.302520, acc: 71.09%, op_acc: 51.56%] [G loss: 1.047173]\n",
      "537 [D loss: 0.278001, acc: 78.91%, op_acc: 55.47%] [G loss: 1.090484]\n",
      "538 [D loss: 0.281838, acc: 78.91%, op_acc: 55.47%] [G loss: 1.089130]\n",
      "539 [D loss: 0.286418, acc: 71.88%, op_acc: 51.56%] [G loss: 1.044073]\n",
      "540 [D loss: 0.305813, acc: 71.09%, op_acc: 51.56%] [G loss: 1.107545]\n",
      "Epoch: 540, F1: 0.62500, F1P: 54\n",
      "[[28426     6]\n",
      " [   24    25]]\n",
      "75.46875\n",
      "541 [D loss: 0.276833, acc: 78.91%, op_acc: 54.69%] [G loss: 1.089451]\n",
      "542 [D loss: 0.292994, acc: 71.88%, op_acc: 53.91%] [G loss: 1.079299]\n",
      "543 [D loss: 0.287574, acc: 75.78%, op_acc: 53.12%] [G loss: 1.078656]\n",
      "544 [D loss: 0.282312, acc: 76.56%, op_acc: 53.91%] [G loss: 1.077051]\n",
      "545 [D loss: 0.269445, acc: 85.94%, op_acc: 57.03%] [G loss: 1.066749]\n",
      "546 [D loss: 0.285823, acc: 78.91%, op_acc: 51.56%] [G loss: 1.108803]\n",
      "547 [D loss: 0.293522, acc: 73.44%, op_acc: 56.25%] [G loss: 1.063130]\n",
      "548 [D loss: 0.299941, acc: 71.09%, op_acc: 52.34%] [G loss: 1.085335]\n",
      "549 [D loss: 0.287870, acc: 78.12%, op_acc: 55.47%] [G loss: 1.065506]\n",
      "550 [D loss: 0.284256, acc: 77.34%, op_acc: 54.69%] [G loss: 1.140201]\n",
      "Epoch: 550, F1: 0.61728, F1P: 55\n",
      "[[28425     7]\n",
      " [   24    25]]\n",
      "76.796875\n",
      "551 [D loss: 0.268580, acc: 77.34%, op_acc: 53.91%] [G loss: 1.101021]\n",
      "552 [D loss: 0.269321, acc: 80.47%, op_acc: 52.34%] [G loss: 1.075649]\n",
      "553 [D loss: 0.285566, acc: 74.22%, op_acc: 53.12%] [G loss: 1.118392]\n",
      "554 [D loss: 0.276623, acc: 80.47%, op_acc: 51.56%] [G loss: 1.065365]\n",
      "555 [D loss: 0.283601, acc: 76.56%, op_acc: 58.59%] [G loss: 1.150687]\n",
      "556 [D loss: 0.282807, acc: 79.69%, op_acc: 53.12%] [G loss: 1.033717]\n",
      "557 [D loss: 0.292418, acc: 76.56%, op_acc: 51.56%] [G loss: 1.133136]\n",
      "558 [D loss: 0.287122, acc: 79.69%, op_acc: 56.25%] [G loss: 1.141726]\n",
      "559 [D loss: 0.291610, acc: 75.00%, op_acc: 49.22%] [G loss: 1.049029]\n",
      "560 [D loss: 0.263269, acc: 81.25%, op_acc: 55.47%] [G loss: 1.080349]\n",
      "Epoch: 560, F1: 0.63415, F1P: 56\n",
      "[[28425     7]\n",
      " [   23    26]]\n",
      "78.125\n",
      "561 [D loss: 0.290778, acc: 73.44%, op_acc: 50.00%] [G loss: 1.036432]\n",
      "562 [D loss: 0.294579, acc: 74.22%, op_acc: 57.03%] [G loss: 1.094736]\n",
      "563 [D loss: 0.284560, acc: 77.34%, op_acc: 51.56%] [G loss: 1.110320]\n",
      "564 [D loss: 0.281568, acc: 76.56%, op_acc: 50.78%] [G loss: 1.083467]\n",
      "565 [D loss: 0.302931, acc: 72.66%, op_acc: 53.12%] [G loss: 1.082123]\n",
      "566 [D loss: 0.291566, acc: 74.22%, op_acc: 49.22%] [G loss: 1.135440]\n",
      "567 [D loss: 0.275702, acc: 79.69%, op_acc: 53.91%] [G loss: 1.038281]\n",
      "568 [D loss: 0.283107, acc: 71.88%, op_acc: 56.25%] [G loss: 1.074949]\n",
      "569 [D loss: 0.296442, acc: 72.66%, op_acc: 50.00%] [G loss: 1.078721]\n",
      "570 [D loss: 0.285441, acc: 77.34%, op_acc: 54.69%] [G loss: 1.102019]\n",
      "Epoch: 570, F1: 0.62500, F1P: 57\n",
      "[[28426     6]\n",
      " [   24    25]]\n",
      "75.0\n",
      "571 [D loss: 0.268443, acc: 79.69%, op_acc: 55.47%] [G loss: 1.068028]\n",
      "572 [D loss: 0.284194, acc: 81.25%, op_acc: 56.25%] [G loss: 1.070407]\n",
      "573 [D loss: 0.281712, acc: 81.25%, op_acc: 57.81%] [G loss: 1.096945]\n",
      "574 [D loss: 0.288891, acc: 75.78%, op_acc: 51.56%] [G loss: 1.105436]\n",
      "575 [D loss: 0.276329, acc: 77.34%, op_acc: 50.78%] [G loss: 1.083192]\n",
      "576 [D loss: 0.277862, acc: 82.03%, op_acc: 61.72%] [G loss: 1.073458]\n",
      "577 [D loss: 0.285250, acc: 78.12%, op_acc: 60.94%] [G loss: 1.101709]\n",
      "578 [D loss: 0.277115, acc: 82.03%, op_acc: 57.81%] [G loss: 1.100867]\n",
      "579 [D loss: 0.289638, acc: 71.88%, op_acc: 58.59%] [G loss: 1.123386]\n",
      "580 [D loss: 0.292266, acc: 71.88%, op_acc: 53.91%] [G loss: 1.083200]\n",
      "Epoch: 580, F1: 0.62500, F1P: 58\n",
      "[[28426     6]\n",
      " [   24    25]]\n",
      "78.125\n",
      "581 [D loss: 0.292456, acc: 75.78%, op_acc: 50.78%] [G loss: 1.107895]\n",
      "582 [D loss: 0.268108, acc: 80.47%, op_acc: 55.47%] [G loss: 1.100685]\n",
      "583 [D loss: 0.290143, acc: 78.12%, op_acc: 54.69%] [G loss: 1.099072]\n",
      "584 [D loss: 0.281910, acc: 79.69%, op_acc: 53.91%] [G loss: 1.171122]\n",
      "585 [D loss: 0.289384, acc: 81.25%, op_acc: 54.69%] [G loss: 1.048768]\n",
      "586 [D loss: 0.281561, acc: 75.78%, op_acc: 56.25%] [G loss: 1.107361]\n",
      "587 [D loss: 0.280774, acc: 78.12%, op_acc: 52.34%] [G loss: 1.070926]\n",
      "588 [D loss: 0.281054, acc: 77.34%, op_acc: 53.91%] [G loss: 1.079842]\n",
      "589 [D loss: 0.278866, acc: 78.12%, op_acc: 50.78%] [G loss: 1.114379]\n",
      "590 [D loss: 0.284557, acc: 76.56%, op_acc: 53.91%] [G loss: 1.110326]\n",
      "Epoch: 590, F1: 0.62500, F1P: 59\n",
      "[[28426     6]\n",
      " [   24    25]]\n",
      "78.125\n",
      "591 [D loss: 0.268626, acc: 85.16%, op_acc: 60.16%] [G loss: 1.109869]\n",
      "592 [D loss: 0.280822, acc: 82.03%, op_acc: 57.81%] [G loss: 1.079187]\n",
      "593 [D loss: 0.295867, acc: 73.44%, op_acc: 51.56%] [G loss: 1.055879]\n",
      "594 [D loss: 0.278888, acc: 80.47%, op_acc: 53.91%] [G loss: 1.118667]\n",
      "595 [D loss: 0.273177, acc: 78.91%, op_acc: 53.91%] [G loss: 1.090789]\n",
      "596 [D loss: 0.264906, acc: 82.03%, op_acc: 50.78%] [G loss: 1.087232]\n",
      "597 [D loss: 0.286725, acc: 75.78%, op_acc: 48.44%] [G loss: 1.073044]\n",
      "598 [D loss: 0.273423, acc: 79.69%, op_acc: 52.34%] [G loss: 1.045701]\n",
      "599 [D loss: 0.266667, acc: 81.25%, op_acc: 56.25%] [G loss: 1.070878]\n",
      "600 [D loss: 0.277283, acc: 81.25%, op_acc: 58.59%] [G loss: 1.126588]\n",
      "Epoch: 600, F1: 0.64198, F1P: 60\n",
      "[[28426     6]\n",
      " [   23    26]]\n",
      "80.0\n",
      "601 [D loss: 0.280638, acc: 80.47%, op_acc: 59.38%] [G loss: 1.098081]\n",
      "602 [D loss: 0.284466, acc: 77.34%, op_acc: 53.12%] [G loss: 1.119514]\n",
      "603 [D loss: 0.270662, acc: 81.25%, op_acc: 57.81%] [G loss: 1.035296]\n",
      "604 [D loss: 0.285437, acc: 76.56%, op_acc: 54.69%] [G loss: 1.096174]\n",
      "605 [D loss: 0.260583, acc: 86.72%, op_acc: 54.69%] [G loss: 1.082619]\n",
      "606 [D loss: 0.276587, acc: 78.91%, op_acc: 52.34%] [G loss: 1.131576]\n",
      "607 [D loss: 0.275362, acc: 80.47%, op_acc: 59.38%] [G loss: 1.157585]\n",
      "608 [D loss: 0.271890, acc: 78.91%, op_acc: 60.94%] [G loss: 1.080267]\n",
      "609 [D loss: 0.274835, acc: 77.34%, op_acc: 54.69%] [G loss: 1.110433]\n",
      "610 [D loss: 0.269937, acc: 76.56%, op_acc: 54.69%] [G loss: 1.090493]\n",
      "Epoch: 610, F1: 0.65060, F1P: 61\n",
      "[[28425     7]\n",
      " [   22    27]]\n",
      "79.453125\n",
      "611 [D loss: 0.275516, acc: 84.38%, op_acc: 51.56%] [G loss: 1.059906]\n",
      "612 [D loss: 0.276919, acc: 77.34%, op_acc: 57.03%] [G loss: 1.155417]\n",
      "613 [D loss: 0.286202, acc: 72.66%, op_acc: 57.03%] [G loss: 1.115581]\n",
      "614 [D loss: 0.273125, acc: 82.03%, op_acc: 55.47%] [G loss: 1.087159]\n",
      "615 [D loss: 0.280249, acc: 75.00%, op_acc: 52.34%] [G loss: 1.176962]\n",
      "616 [D loss: 0.278998, acc: 73.44%, op_acc: 54.69%] [G loss: 1.164910]\n",
      "617 [D loss: 0.286411, acc: 77.34%, op_acc: 53.12%] [G loss: 1.137815]\n",
      "618 [D loss: 0.267650, acc: 75.78%, op_acc: 53.91%] [G loss: 1.107503]\n",
      "619 [D loss: 0.278699, acc: 78.91%, op_acc: 53.91%] [G loss: 1.134209]\n",
      "620 [D loss: 0.270305, acc: 79.69%, op_acc: 55.47%] [G loss: 1.085081]\n",
      "Epoch: 620, F1: 0.65060, F1P: 62\n",
      "[[28425     7]\n",
      " [   22    27]]\n",
      "77.65625\n",
      "621 [D loss: 0.279456, acc: 78.91%, op_acc: 52.34%] [G loss: 1.091952]\n",
      "622 [D loss: 0.271945, acc: 78.12%, op_acc: 54.69%] [G loss: 1.128660]\n",
      "623 [D loss: 0.269755, acc: 76.56%, op_acc: 56.25%] [G loss: 1.121609]\n",
      "624 [D loss: 0.276880, acc: 79.69%, op_acc: 55.47%] [G loss: 1.130044]\n",
      "625 [D loss: 0.273115, acc: 80.47%, op_acc: 55.47%] [G loss: 1.115034]\n",
      "626 [D loss: 0.277944, acc: 78.12%, op_acc: 53.12%] [G loss: 1.123617]\n",
      "627 [D loss: 0.254994, acc: 86.72%, op_acc: 60.16%] [G loss: 1.105811]\n",
      "628 [D loss: 0.284410, acc: 75.00%, op_acc: 56.25%] [G loss: 1.043542]\n",
      "629 [D loss: 0.278463, acc: 77.34%, op_acc: 55.47%] [G loss: 1.157793]\n",
      "630 [D loss: 0.270128, acc: 81.25%, op_acc: 57.03%] [G loss: 1.112147]\n",
      "Epoch: 630, F1: 0.66667, F1P: 63\n",
      "[[28425     7]\n",
      " [   21    28]]\n",
      "79.21875\n",
      "631 [D loss: 0.274300, acc: 78.12%, op_acc: 51.56%] [G loss: 1.130870]\n",
      "632 [D loss: 0.277619, acc: 76.56%, op_acc: 50.00%] [G loss: 1.100921]\n",
      "633 [D loss: 0.285954, acc: 78.91%, op_acc: 47.66%] [G loss: 1.075504]\n",
      "634 [D loss: 0.268779, acc: 84.38%, op_acc: 62.50%] [G loss: 1.056961]\n",
      "635 [D loss: 0.275892, acc: 75.78%, op_acc: 55.47%] [G loss: 1.162723]\n",
      "636 [D loss: 0.270237, acc: 81.25%, op_acc: 53.91%] [G loss: 1.138279]\n",
      "637 [D loss: 0.262267, acc: 82.03%, op_acc: 56.25%] [G loss: 1.089797]\n",
      "638 [D loss: 0.279923, acc: 83.59%, op_acc: 53.12%] [G loss: 1.167686]\n",
      "639 [D loss: 0.282939, acc: 78.12%, op_acc: 53.12%] [G loss: 1.170212]\n",
      "640 [D loss: 0.285451, acc: 75.00%, op_acc: 55.47%] [G loss: 1.136502]\n",
      "Epoch: 640, F1: 0.65116, F1P: 64\n",
      "[[28423     9]\n",
      " [   21    28]]\n",
      "79.375\n",
      "641 [D loss: 0.271838, acc: 81.25%, op_acc: 52.34%] [G loss: 1.202608]\n",
      "642 [D loss: 0.268828, acc: 82.03%, op_acc: 54.69%] [G loss: 1.136572]\n",
      "643 [D loss: 0.273459, acc: 81.25%, op_acc: 56.25%] [G loss: 1.125316]\n",
      "644 [D loss: 0.265251, acc: 82.81%, op_acc: 56.25%] [G loss: 1.091647]\n",
      "645 [D loss: 0.262043, acc: 84.38%, op_acc: 61.72%] [G loss: 1.182395]\n",
      "646 [D loss: 0.276434, acc: 83.59%, op_acc: 57.81%] [G loss: 1.154023]\n",
      "647 [D loss: 0.262120, acc: 82.03%, op_acc: 53.91%] [G loss: 1.181357]\n",
      "648 [D loss: 0.248318, acc: 86.72%, op_acc: 59.38%] [G loss: 1.203437]\n",
      "649 [D loss: 0.272156, acc: 81.25%, op_acc: 51.56%] [G loss: 1.112076]\n",
      "650 [D loss: 0.267954, acc: 84.38%, op_acc: 57.81%] [G loss: 1.138054]\n",
      "Epoch: 650, F1: 0.65116, F1P: 65\n",
      "[[28423     9]\n",
      " [   21    28]]\n",
      "82.96875\n",
      "651 [D loss: 0.265403, acc: 80.47%, op_acc: 57.03%] [G loss: 1.130160]\n",
      "652 [D loss: 0.284512, acc: 76.56%, op_acc: 60.16%] [G loss: 1.173052]\n",
      "653 [D loss: 0.261560, acc: 85.16%, op_acc: 60.16%] [G loss: 1.121406]\n",
      "654 [D loss: 0.256301, acc: 83.59%, op_acc: 57.81%] [G loss: 1.138369]\n",
      "655 [D loss: 0.274454, acc: 79.69%, op_acc: 54.69%] [G loss: 1.132924]\n",
      "656 [D loss: 0.271037, acc: 78.91%, op_acc: 53.12%] [G loss: 1.135640]\n",
      "657 [D loss: 0.260953, acc: 83.59%, op_acc: 54.69%] [G loss: 1.113157]\n",
      "658 [D loss: 0.254286, acc: 84.38%, op_acc: 59.38%] [G loss: 1.158788]\n",
      "659 [D loss: 0.267183, acc: 83.59%, op_acc: 56.25%] [G loss: 1.162083]\n",
      "660 [D loss: 0.266813, acc: 81.25%, op_acc: 56.25%] [G loss: 1.105649]\n",
      "Epoch: 660, F1: 0.65116, F1P: 66\n",
      "[[28423     9]\n",
      " [   21    28]]\n",
      "81.71875\n",
      "661 [D loss: 0.261747, acc: 81.25%, op_acc: 58.59%] [G loss: 1.164678]\n",
      "662 [D loss: 0.272176, acc: 84.38%, op_acc: 56.25%] [G loss: 1.181567]\n",
      "663 [D loss: 0.265889, acc: 82.03%, op_acc: 53.12%] [G loss: 1.128627]\n",
      "664 [D loss: 0.271921, acc: 80.47%, op_acc: 50.00%] [G loss: 1.155387]\n",
      "665 [D loss: 0.276272, acc: 81.25%, op_acc: 57.81%] [G loss: 1.069360]\n",
      "666 [D loss: 0.282384, acc: 76.56%, op_acc: 57.81%] [G loss: 1.128361]\n",
      "667 [D loss: 0.271952, acc: 77.34%, op_acc: 60.94%] [G loss: 1.168049]\n",
      "668 [D loss: 0.248730, acc: 84.38%, op_acc: 60.94%] [G loss: 1.128551]\n",
      "669 [D loss: 0.273990, acc: 79.69%, op_acc: 53.91%] [G loss: 1.158656]\n",
      "670 [D loss: 0.280578, acc: 78.12%, op_acc: 44.53%] [G loss: 1.148795]\n",
      "Epoch: 670, F1: 0.68182, F1P: 67\n",
      "[[28423     9]\n",
      " [   19    30]]\n",
      "80.546875\n",
      "671 [D loss: 0.260432, acc: 81.25%, op_acc: 57.03%] [G loss: 1.177816]\n",
      "672 [D loss: 0.269199, acc: 83.59%, op_acc: 49.22%] [G loss: 1.132890]\n",
      "673 [D loss: 0.259525, acc: 84.38%, op_acc: 50.78%] [G loss: 1.155206]\n",
      "674 [D loss: 0.271045, acc: 77.34%, op_acc: 48.44%] [G loss: 1.176467]\n",
      "675 [D loss: 0.274224, acc: 82.03%, op_acc: 50.78%] [G loss: 1.144229]\n",
      "676 [D loss: 0.253582, acc: 87.50%, op_acc: 58.59%] [G loss: 1.167299]\n",
      "677 [D loss: 0.270788, acc: 82.03%, op_acc: 49.22%] [G loss: 1.168869]\n",
      "678 [D loss: 0.269863, acc: 83.59%, op_acc: 57.03%] [G loss: 1.220643]\n",
      "679 [D loss: 0.257337, acc: 85.94%, op_acc: 54.69%] [G loss: 1.167490]\n",
      "680 [D loss: 0.262107, acc: 82.81%, op_acc: 54.69%] [G loss: 1.171422]\n",
      "Epoch: 680, F1: 0.65957, F1P: 68\n",
      "[[28418    14]\n",
      " [   18    31]]\n",
      "83.046875\n",
      "681 [D loss: 0.254756, acc: 84.38%, op_acc: 57.03%] [G loss: 1.127477]\n",
      "682 [D loss: 0.249637, acc: 89.84%, op_acc: 60.16%] [G loss: 1.201467]\n",
      "683 [D loss: 0.268061, acc: 81.25%, op_acc: 62.50%] [G loss: 1.190204]\n",
      "684 [D loss: 0.277530, acc: 78.91%, op_acc: 56.25%] [G loss: 1.221824]\n",
      "685 [D loss: 0.254094, acc: 84.38%, op_acc: 53.91%] [G loss: 1.193822]\n",
      "686 [D loss: 0.269294, acc: 75.00%, op_acc: 58.59%] [G loss: 1.197098]\n",
      "687 [D loss: 0.250511, acc: 89.06%, op_acc: 56.25%] [G loss: 1.148218]\n",
      "688 [D loss: 0.253309, acc: 87.50%, op_acc: 53.12%] [G loss: 1.159551]\n",
      "689 [D loss: 0.264580, acc: 81.25%, op_acc: 60.94%] [G loss: 1.222592]\n",
      "690 [D loss: 0.270103, acc: 82.03%, op_acc: 51.56%] [G loss: 1.216004]\n",
      "Epoch: 690, F1: 0.66667, F1P: 69\n",
      "[[28415    17]\n",
      " [   16    33]]\n",
      "83.359375\n",
      "691 [D loss: 0.249454, acc: 85.94%, op_acc: 59.38%] [G loss: 1.196699]\n",
      "692 [D loss: 0.278525, acc: 79.69%, op_acc: 57.81%] [G loss: 1.178878]\n",
      "693 [D loss: 0.269842, acc: 81.25%, op_acc: 54.69%] [G loss: 1.194484]\n",
      "694 [D loss: 0.261726, acc: 82.03%, op_acc: 57.03%] [G loss: 1.153159]\n",
      "695 [D loss: 0.268287, acc: 83.59%, op_acc: 53.91%] [G loss: 1.158974]\n",
      "696 [D loss: 0.252673, acc: 82.03%, op_acc: 55.47%] [G loss: 1.195924]\n",
      "697 [D loss: 0.267050, acc: 82.03%, op_acc: 52.34%] [G loss: 1.199954]\n",
      "698 [D loss: 0.277941, acc: 79.69%, op_acc: 53.12%] [G loss: 1.208403]\n",
      "699 [D loss: 0.260088, acc: 82.03%, op_acc: 52.34%] [G loss: 1.205646]\n",
      "700 [D loss: 0.258835, acc: 80.47%, op_acc: 53.91%] [G loss: 1.193899]\n",
      "Epoch: 700, F1: 0.65385, F1P: 70\n",
      "[[28411    21]\n",
      " [   15    34]]\n",
      "81.875\n",
      "701 [D loss: 0.273501, acc: 76.56%, op_acc: 50.00%] [G loss: 1.210731]\n",
      "702 [D loss: 0.258644, acc: 82.03%, op_acc: 60.94%] [G loss: 1.235071]\n",
      "703 [D loss: 0.259727, acc: 81.25%, op_acc: 53.12%] [G loss: 1.168875]\n",
      "704 [D loss: 0.245227, acc: 88.28%, op_acc: 53.91%] [G loss: 1.171869]\n",
      "705 [D loss: 0.267818, acc: 82.81%, op_acc: 53.91%] [G loss: 1.213142]\n",
      "706 [D loss: 0.246786, acc: 89.06%, op_acc: 60.16%] [G loss: 1.164166]\n",
      "707 [D loss: 0.265434, acc: 75.78%, op_acc: 50.78%] [G loss: 1.148249]\n",
      "708 [D loss: 0.253852, acc: 83.59%, op_acc: 53.91%] [G loss: 1.263716]\n",
      "709 [D loss: 0.258071, acc: 83.59%, op_acc: 57.81%] [G loss: 1.137750]\n",
      "710 [D loss: 0.264461, acc: 85.16%, op_acc: 52.34%] [G loss: 1.234116]\n",
      "Epoch: 710, F1: 0.64220, F1P: 71\n",
      "[[28407    25]\n",
      " [   14    35]]\n",
      "82.8125\n",
      "711 [D loss: 0.246173, acc: 88.28%, op_acc: 56.25%] [G loss: 1.169404]\n",
      "712 [D loss: 0.265386, acc: 79.69%, op_acc: 59.38%] [G loss: 1.247939]\n",
      "713 [D loss: 0.264056, acc: 82.81%, op_acc: 46.88%] [G loss: 1.183797]\n",
      "714 [D loss: 0.251424, acc: 85.16%, op_acc: 60.16%] [G loss: 1.165546]\n",
      "715 [D loss: 0.262938, acc: 82.81%, op_acc: 53.91%] [G loss: 1.298113]\n",
      "716 [D loss: 0.258842, acc: 83.59%, op_acc: 55.47%] [G loss: 1.159040]\n",
      "717 [D loss: 0.256315, acc: 85.94%, op_acc: 52.34%] [G loss: 1.259783]\n",
      "718 [D loss: 0.259130, acc: 81.25%, op_acc: 50.78%] [G loss: 1.224286]\n",
      "719 [D loss: 0.243749, acc: 90.62%, op_acc: 60.16%] [G loss: 1.152715]\n",
      "720 [D loss: 0.265000, acc: 81.25%, op_acc: 56.25%] [G loss: 1.227658]\n",
      "Epoch: 720, F1: 0.64815, F1P: 72\n",
      "[[28408    24]\n",
      " [   14    35]]\n",
      "84.140625\n",
      "721 [D loss: 0.247159, acc: 83.59%, op_acc: 50.78%] [G loss: 1.178007]\n",
      "722 [D loss: 0.271094, acc: 76.56%, op_acc: 47.66%] [G loss: 1.197247]\n",
      "723 [D loss: 0.261543, acc: 85.94%, op_acc: 52.34%] [G loss: 1.137800]\n",
      "724 [D loss: 0.260251, acc: 85.16%, op_acc: 55.47%] [G loss: 1.211524]\n",
      "725 [D loss: 0.271371, acc: 76.56%, op_acc: 51.56%] [G loss: 1.187166]\n",
      "726 [D loss: 0.256580, acc: 81.25%, op_acc: 53.12%] [G loss: 1.220544]\n",
      "727 [D loss: 0.264379, acc: 86.72%, op_acc: 53.91%] [G loss: 1.195537]\n",
      "728 [D loss: 0.263862, acc: 82.81%, op_acc: 57.03%] [G loss: 1.192181]\n",
      "729 [D loss: 0.257563, acc: 79.69%, op_acc: 59.38%] [G loss: 1.165143]\n",
      "730 [D loss: 0.264570, acc: 82.81%, op_acc: 53.91%] [G loss: 1.175091]\n",
      "Epoch: 730, F1: 0.64220, F1P: 73\n",
      "[[28407    25]\n",
      " [   14    35]]\n",
      "82.109375\n",
      "731 [D loss: 0.259244, acc: 79.69%, op_acc: 55.47%] [G loss: 1.257357]\n",
      "732 [D loss: 0.263068, acc: 81.25%, op_acc: 55.47%] [G loss: 1.266144]\n",
      "733 [D loss: 0.272539, acc: 74.22%, op_acc: 50.78%] [G loss: 1.156842]\n",
      "734 [D loss: 0.252013, acc: 85.94%, op_acc: 53.91%] [G loss: 1.140968]\n",
      "735 [D loss: 0.255627, acc: 82.03%, op_acc: 52.34%] [G loss: 1.257377]\n",
      "736 [D loss: 0.252899, acc: 82.03%, op_acc: 57.03%] [G loss: 1.204253]\n",
      "737 [D loss: 0.264272, acc: 82.03%, op_acc: 60.16%] [G loss: 1.245665]\n",
      "738 [D loss: 0.248485, acc: 85.94%, op_acc: 55.47%] [G loss: 1.262108]\n",
      "739 [D loss: 0.252127, acc: 84.38%, op_acc: 57.81%] [G loss: 1.241762]\n",
      "740 [D loss: 0.259705, acc: 82.03%, op_acc: 52.34%] [G loss: 1.223014]\n",
      "Epoch: 740, F1: 0.60870, F1P: 74\n",
      "[[28401    31]\n",
      " [   14    35]]\n",
      "81.953125\n",
      "741 [D loss: 0.258006, acc: 82.03%, op_acc: 49.22%] [G loss: 1.172959]\n",
      "742 [D loss: 0.257815, acc: 83.59%, op_acc: 56.25%] [G loss: 1.233095]\n",
      "743 [D loss: 0.244569, acc: 85.94%, op_acc: 57.03%] [G loss: 1.165321]\n",
      "744 [D loss: 0.266458, acc: 78.91%, op_acc: 54.69%] [G loss: 1.232403]\n",
      "745 [D loss: 0.256368, acc: 78.91%, op_acc: 59.38%] [G loss: 1.282817]\n",
      "746 [D loss: 0.257362, acc: 82.03%, op_acc: 59.38%] [G loss: 1.243146]\n",
      "747 [D loss: 0.258717, acc: 85.94%, op_acc: 54.69%] [G loss: 1.249099]\n",
      "748 [D loss: 0.252175, acc: 85.16%, op_acc: 54.69%] [G loss: 1.224396]\n",
      "749 [D loss: 0.255626, acc: 83.59%, op_acc: 56.25%] [G loss: 1.188162]\n",
      "750 [D loss: 0.265275, acc: 80.47%, op_acc: 57.03%] [G loss: 1.248230]\n",
      "Epoch: 750, F1: 0.60000, F1P: 75\n",
      "[[28397    35]\n",
      " [   13    36]]\n",
      "82.65625\n",
      "751 [D loss: 0.270710, acc: 78.12%, op_acc: 57.03%] [G loss: 1.214171]\n",
      "752 [D loss: 0.247600, acc: 85.16%, op_acc: 58.59%] [G loss: 1.239662]\n",
      "753 [D loss: 0.250642, acc: 88.28%, op_acc: 47.66%] [G loss: 1.202797]\n",
      "754 [D loss: 0.249939, acc: 88.28%, op_acc: 55.47%] [G loss: 1.259718]\n",
      "755 [D loss: 0.252967, acc: 84.38%, op_acc: 64.84%] [G loss: 1.248006]\n",
      "756 [D loss: 0.244888, acc: 88.28%, op_acc: 54.69%] [G loss: 1.180107]\n",
      "757 [D loss: 0.256706, acc: 84.38%, op_acc: 58.59%] [G loss: 1.285807]\n",
      "758 [D loss: 0.257623, acc: 80.47%, op_acc: 54.69%] [G loss: 1.266907]\n",
      "759 [D loss: 0.243877, acc: 87.50%, op_acc: 55.47%] [G loss: 1.274325]\n",
      "760 [D loss: 0.256439, acc: 82.03%, op_acc: 53.12%] [G loss: 1.259834]\n",
      "Epoch: 760, F1: 0.58537, F1P: 76\n",
      "[[28394    38]\n",
      " [   13    36]]\n",
      "84.6875\n",
      "761 [D loss: 0.228776, acc: 88.28%, op_acc: 57.03%] [G loss: 1.238319]\n",
      "762 [D loss: 0.249506, acc: 86.72%, op_acc: 44.53%] [G loss: 1.285978]\n",
      "763 [D loss: 0.249144, acc: 86.72%, op_acc: 56.25%] [G loss: 1.202800]\n",
      "764 [D loss: 0.244017, acc: 88.28%, op_acc: 56.25%] [G loss: 1.284829]\n",
      "765 [D loss: 0.237837, acc: 90.62%, op_acc: 60.16%] [G loss: 1.292376]\n",
      "766 [D loss: 0.251314, acc: 84.38%, op_acc: 55.47%] [G loss: 1.267854]\n",
      "767 [D loss: 0.249629, acc: 89.06%, op_acc: 61.72%] [G loss: 1.229607]\n",
      "768 [D loss: 0.233511, acc: 87.50%, op_acc: 51.56%] [G loss: 1.215064]\n",
      "769 [D loss: 0.238007, acc: 87.50%, op_acc: 55.47%] [G loss: 1.259061]\n",
      "770 [D loss: 0.254368, acc: 82.03%, op_acc: 58.59%] [G loss: 1.283207]\n",
      "Epoch: 770, F1: 0.59016, F1P: 77\n",
      "[[28395    37]\n",
      " [   13    36]]\n",
      "87.109375\n",
      "771 [D loss: 0.252152, acc: 85.16%, op_acc: 55.47%] [G loss: 1.279183]\n",
      "772 [D loss: 0.243344, acc: 86.72%, op_acc: 52.34%] [G loss: 1.275803]\n",
      "773 [D loss: 0.246346, acc: 85.94%, op_acc: 56.25%] [G loss: 1.218763]\n",
      "774 [D loss: 0.253281, acc: 82.03%, op_acc: 55.47%] [G loss: 1.226237]\n",
      "775 [D loss: 0.243705, acc: 90.62%, op_acc: 60.16%] [G loss: 1.293118]\n",
      "776 [D loss: 0.241500, acc: 87.50%, op_acc: 60.94%] [G loss: 1.269608]\n",
      "777 [D loss: 0.241258, acc: 84.38%, op_acc: 53.91%] [G loss: 1.212721]\n",
      "778 [D loss: 0.232534, acc: 86.72%, op_acc: 56.25%] [G loss: 1.301904]\n",
      "779 [D loss: 0.251345, acc: 90.62%, op_acc: 59.38%] [G loss: 1.224175]\n",
      "780 [D loss: 0.235292, acc: 87.50%, op_acc: 60.16%] [G loss: 1.266767]\n",
      "Epoch: 780, F1: 0.58065, F1P: 78\n",
      "[[28393    39]\n",
      " [   13    36]]\n",
      "86.71875\n",
      "781 [D loss: 0.236517, acc: 86.72%, op_acc: 56.25%] [G loss: 1.228128]\n",
      "782 [D loss: 0.243159, acc: 86.72%, op_acc: 54.69%] [G loss: 1.274190]\n",
      "783 [D loss: 0.244795, acc: 87.50%, op_acc: 61.72%] [G loss: 1.245612]\n",
      "784 [D loss: 0.247326, acc: 85.16%, op_acc: 53.91%] [G loss: 1.294668]\n",
      "785 [D loss: 0.223775, acc: 89.06%, op_acc: 57.81%] [G loss: 1.344745]\n",
      "786 [D loss: 0.240062, acc: 87.50%, op_acc: 59.38%] [G loss: 1.237080]\n",
      "787 [D loss: 0.226959, acc: 92.19%, op_acc: 64.06%] [G loss: 1.297883]\n",
      "788 [D loss: 0.232091, acc: 91.41%, op_acc: 63.28%] [G loss: 1.240821]\n",
      "789 [D loss: 0.234298, acc: 88.28%, op_acc: 63.28%] [G loss: 1.184325]\n",
      "790 [D loss: 0.231783, acc: 86.72%, op_acc: 59.38%] [G loss: 1.208733]\n",
      "Epoch: 790, F1: 0.59504, F1P: 79\n",
      "[[28396    36]\n",
      " [   13    36]]\n",
      "88.125\n",
      "791 [D loss: 0.243398, acc: 82.03%, op_acc: 57.81%] [G loss: 1.204140]\n",
      "792 [D loss: 0.252466, acc: 89.84%, op_acc: 60.16%] [G loss: 1.232426]\n",
      "793 [D loss: 0.239228, acc: 88.28%, op_acc: 60.94%] [G loss: 1.276458]\n",
      "794 [D loss: 0.248185, acc: 82.81%, op_acc: 60.16%] [G loss: 1.241838]\n",
      "795 [D loss: 0.241135, acc: 85.94%, op_acc: 57.81%] [G loss: 1.237363]\n",
      "796 [D loss: 0.237449, acc: 88.28%, op_acc: 53.91%] [G loss: 1.212730]\n",
      "797 [D loss: 0.242711, acc: 84.38%, op_acc: 54.69%] [G loss: 1.298135]\n",
      "798 [D loss: 0.255938, acc: 82.81%, op_acc: 57.81%] [G loss: 1.318467]\n",
      "799 [D loss: 0.239906, acc: 87.50%, op_acc: 58.59%] [G loss: 1.295518]\n",
      "800 [D loss: 0.231086, acc: 86.72%, op_acc: 58.59%] [G loss: 1.294033]\n",
      "Epoch: 800, F1: 0.52482, F1P: 80\n",
      "[[28377    55]\n",
      " [   12    37]]\n",
      "85.859375\n",
      "801 [D loss: 0.240321, acc: 86.72%, op_acc: 62.50%] [G loss: 1.324274]\n",
      "802 [D loss: 0.234567, acc: 89.84%, op_acc: 60.94%] [G loss: 1.275925]\n",
      "803 [D loss: 0.251374, acc: 82.81%, op_acc: 58.59%] [G loss: 1.304593]\n",
      "804 [D loss: 0.239719, acc: 86.72%, op_acc: 60.16%] [G loss: 1.201009]\n",
      "805 [D loss: 0.241567, acc: 86.72%, op_acc: 58.59%] [G loss: 1.282604]\n",
      "806 [D loss: 0.230766, acc: 87.50%, op_acc: 64.06%] [G loss: 1.302426]\n",
      "807 [D loss: 0.229459, acc: 86.72%, op_acc: 60.16%] [G loss: 1.355114]\n",
      "808 [D loss: 0.231352, acc: 84.38%, op_acc: 60.94%] [G loss: 1.271387]\n",
      "809 [D loss: 0.240905, acc: 86.72%, op_acc: 62.50%] [G loss: 1.309447]\n",
      "810 [D loss: 0.241302, acc: 89.06%, op_acc: 60.16%] [G loss: 1.302022]\n",
      "Epoch: 810, F1: 0.54545, F1P: 81\n",
      "[[28385    47]\n",
      " [   13    36]]\n",
      "86.71875\n",
      "811 [D loss: 0.244890, acc: 88.28%, op_acc: 59.38%] [G loss: 1.293293]\n",
      "812 [D loss: 0.240907, acc: 89.06%, op_acc: 60.16%] [G loss: 1.340821]\n",
      "813 [D loss: 0.241390, acc: 85.94%, op_acc: 57.81%] [G loss: 1.256170]\n",
      "814 [D loss: 0.245520, acc: 92.97%, op_acc: 62.50%] [G loss: 1.274431]\n",
      "815 [D loss: 0.230342, acc: 88.28%, op_acc: 63.28%] [G loss: 1.328439]\n",
      "816 [D loss: 0.229975, acc: 90.62%, op_acc: 58.59%] [G loss: 1.283664]\n",
      "817 [D loss: 0.228520, acc: 88.28%, op_acc: 59.38%] [G loss: 1.346863]\n",
      "818 [D loss: 0.234109, acc: 85.94%, op_acc: 54.69%] [G loss: 1.229831]\n",
      "819 [D loss: 0.222496, acc: 92.19%, op_acc: 67.97%] [G loss: 1.313075]\n",
      "820 [D loss: 0.226634, acc: 90.62%, op_acc: 68.75%] [G loss: 1.312365]\n",
      "Epoch: 820, F1: 0.60000, F1P: 82\n",
      "[[28397    35]\n",
      " [   13    36]]\n",
      "89.21875\n",
      "821 [D loss: 0.246712, acc: 87.50%, op_acc: 55.47%] [G loss: 1.309673]\n",
      "822 [D loss: 0.232405, acc: 85.94%, op_acc: 57.81%] [G loss: 1.237012]\n",
      "823 [D loss: 0.235301, acc: 85.16%, op_acc: 67.19%] [G loss: 1.259342]\n",
      "824 [D loss: 0.246320, acc: 87.50%, op_acc: 64.06%] [G loss: 1.319578]\n",
      "825 [D loss: 0.243525, acc: 84.38%, op_acc: 55.47%] [G loss: 1.337190]\n",
      "826 [D loss: 0.218085, acc: 90.62%, op_acc: 60.16%] [G loss: 1.277893]\n",
      "827 [D loss: 0.239767, acc: 89.84%, op_acc: 60.16%] [G loss: 1.303375]\n",
      "828 [D loss: 0.238595, acc: 85.94%, op_acc: 64.06%] [G loss: 1.281006]\n",
      "829 [D loss: 0.226534, acc: 92.19%, op_acc: 63.28%] [G loss: 1.300332]\n",
      "830 [D loss: 0.231279, acc: 87.50%, op_acc: 65.62%] [G loss: 1.332158]\n",
      "Epoch: 830, F1: 0.62069, F1P: 83\n",
      "[[28401    31]\n",
      " [   13    36]]\n",
      "87.65625\n",
      "831 [D loss: 0.247302, acc: 84.38%, op_acc: 53.91%] [G loss: 1.364260]\n",
      "832 [D loss: 0.239642, acc: 87.50%, op_acc: 60.94%] [G loss: 1.340372]\n",
      "833 [D loss: 0.239199, acc: 85.16%, op_acc: 57.81%] [G loss: 1.307113]\n",
      "834 [D loss: 0.225823, acc: 92.19%, op_acc: 62.50%] [G loss: 1.254439]\n",
      "835 [D loss: 0.243915, acc: 82.03%, op_acc: 67.97%] [G loss: 1.254018]\n",
      "836 [D loss: 0.238807, acc: 89.84%, op_acc: 55.47%] [G loss: 1.276751]\n",
      "837 [D loss: 0.241187, acc: 83.59%, op_acc: 63.28%] [G loss: 1.282219]\n",
      "838 [D loss: 0.223891, acc: 87.50%, op_acc: 62.50%] [G loss: 1.253913]\n",
      "839 [D loss: 0.240923, acc: 82.03%, op_acc: 65.62%] [G loss: 1.283299]\n",
      "840 [D loss: 0.235338, acc: 86.72%, op_acc: 57.03%] [G loss: 1.274035]\n",
      "Epoch: 840, F1: 0.62609, F1P: 84\n",
      "[[28402    30]\n",
      " [   13    36]]\n",
      "86.09375\n",
      "841 [D loss: 0.243359, acc: 85.16%, op_acc: 64.06%] [G loss: 1.316684]\n",
      "842 [D loss: 0.242914, acc: 89.06%, op_acc: 68.75%] [G loss: 1.278220]\n",
      "843 [D loss: 0.239336, acc: 86.72%, op_acc: 61.72%] [G loss: 1.318293]\n",
      "844 [D loss: 0.232944, acc: 87.50%, op_acc: 67.19%] [G loss: 1.346355]\n",
      "845 [D loss: 0.227609, acc: 89.06%, op_acc: 63.28%] [G loss: 1.282230]\n",
      "846 [D loss: 0.239867, acc: 85.94%, op_acc: 57.03%] [G loss: 1.217512]\n",
      "847 [D loss: 0.243848, acc: 84.38%, op_acc: 57.03%] [G loss: 1.280121]\n",
      "848 [D loss: 0.235081, acc: 91.41%, op_acc: 66.41%] [G loss: 1.239378]\n",
      "849 [D loss: 0.240976, acc: 82.81%, op_acc: 62.50%] [G loss: 1.285753]\n",
      "850 [D loss: 0.239720, acc: 84.38%, op_acc: 64.06%] [G loss: 1.256350]\n",
      "Epoch: 850, F1: 0.62069, F1P: 85\n",
      "[[28401    31]\n",
      " [   13    36]]\n",
      "86.640625\n",
      "851 [D loss: 0.236378, acc: 86.72%, op_acc: 67.97%] [G loss: 1.272310]\n",
      "852 [D loss: 0.238041, acc: 90.62%, op_acc: 65.62%] [G loss: 1.341153]\n",
      "853 [D loss: 0.240056, acc: 85.94%, op_acc: 60.16%] [G loss: 1.343830]\n",
      "854 [D loss: 0.230032, acc: 90.62%, op_acc: 65.62%] [G loss: 1.308401]\n",
      "855 [D loss: 0.238146, acc: 85.94%, op_acc: 56.25%] [G loss: 1.276463]\n",
      "856 [D loss: 0.248223, acc: 87.50%, op_acc: 63.28%] [G loss: 1.346257]\n",
      "857 [D loss: 0.226730, acc: 90.62%, op_acc: 64.84%] [G loss: 1.354482]\n",
      "858 [D loss: 0.234128, acc: 86.72%, op_acc: 63.28%] [G loss: 1.285666]\n",
      "859 [D loss: 0.239232, acc: 85.94%, op_acc: 61.72%] [G loss: 1.267845]\n",
      "860 [D loss: 0.227524, acc: 93.75%, op_acc: 64.06%] [G loss: 1.272122]\n",
      "Epoch: 860, F1: 0.63717, F1P: 86\n",
      "[[28404    28]\n",
      " [   13    36]]\n",
      "88.4375\n",
      "861 [D loss: 0.246333, acc: 88.28%, op_acc: 59.38%] [G loss: 1.234353]\n",
      "862 [D loss: 0.247736, acc: 84.38%, op_acc: 64.06%] [G loss: 1.265814]\n",
      "863 [D loss: 0.262041, acc: 79.69%, op_acc: 57.03%] [G loss: 1.340411]\n",
      "864 [D loss: 0.267834, acc: 82.81%, op_acc: 64.06%] [G loss: 1.346719]\n",
      "865 [D loss: 0.233750, acc: 85.94%, op_acc: 58.59%] [G loss: 1.296216]\n",
      "866 [D loss: 0.243395, acc: 88.28%, op_acc: 67.97%] [G loss: 1.323098]\n",
      "867 [D loss: 0.240871, acc: 88.28%, op_acc: 61.72%] [G loss: 1.262489]\n",
      "868 [D loss: 0.231095, acc: 88.28%, op_acc: 67.19%] [G loss: 1.322355]\n",
      "869 [D loss: 0.227203, acc: 90.62%, op_acc: 64.06%] [G loss: 1.320792]\n",
      "870 [D loss: 0.233271, acc: 85.94%, op_acc: 68.75%] [G loss: 1.280149]\n",
      "Epoch: 870, F1: 0.66055, F1P: 87\n",
      "[[28408    24]\n",
      " [   13    36]]\n",
      "86.25\n",
      "871 [D loss: 0.237957, acc: 88.28%, op_acc: 71.09%] [G loss: 1.375213]\n",
      "872 [D loss: 0.244271, acc: 86.72%, op_acc: 62.50%] [G loss: 1.382677]\n",
      "873 [D loss: 0.223001, acc: 86.72%, op_acc: 63.28%] [G loss: 1.252214]\n",
      "874 [D loss: 0.239593, acc: 85.16%, op_acc: 64.06%] [G loss: 1.281308]\n",
      "875 [D loss: 0.244057, acc: 83.59%, op_acc: 62.50%] [G loss: 1.361961]\n",
      "876 [D loss: 0.238594, acc: 85.94%, op_acc: 66.41%] [G loss: 1.346875]\n",
      "877 [D loss: 0.233064, acc: 86.72%, op_acc: 59.38%] [G loss: 1.349279]\n",
      "878 [D loss: 0.231121, acc: 87.50%, op_acc: 64.84%] [G loss: 1.300558]\n",
      "879 [D loss: 0.229543, acc: 89.84%, op_acc: 60.16%] [G loss: 1.279577]\n",
      "880 [D loss: 0.235496, acc: 85.94%, op_acc: 70.31%] [G loss: 1.313090]\n",
      "Epoch: 880, F1: 0.66038, F1P: 88\n",
      "[[28410    22]\n",
      " [   14    35]]\n",
      "86.640625\n",
      "881 [D loss: 0.239557, acc: 87.50%, op_acc: 67.19%] [G loss: 1.256486]\n",
      "882 [D loss: 0.239488, acc: 85.94%, op_acc: 64.84%] [G loss: 1.359734]\n",
      "883 [D loss: 0.233864, acc: 88.28%, op_acc: 62.50%] [G loss: 1.331327]\n",
      "884 [D loss: 0.245715, acc: 87.50%, op_acc: 60.94%] [G loss: 1.349223]\n",
      "885 [D loss: 0.240354, acc: 86.72%, op_acc: 60.16%] [G loss: 1.351374]\n",
      "886 [D loss: 0.236123, acc: 86.72%, op_acc: 62.50%] [G loss: 1.306272]\n",
      "887 [D loss: 0.228535, acc: 89.06%, op_acc: 65.62%] [G loss: 1.281971]\n",
      "888 [D loss: 0.223581, acc: 90.62%, op_acc: 68.75%] [G loss: 1.362320]\n",
      "889 [D loss: 0.237053, acc: 85.94%, op_acc: 67.19%] [G loss: 1.360809]\n",
      "890 [D loss: 0.233252, acc: 85.94%, op_acc: 67.19%] [G loss: 1.283625]\n",
      "Epoch: 890, F1: 0.70000, F1P: 89\n",
      "[[28416    16]\n",
      " [   14    35]]\n",
      "87.421875\n",
      "891 [D loss: 0.230019, acc: 91.41%, op_acc: 63.28%] [G loss: 1.271211]\n",
      "892 [D loss: 0.217010, acc: 93.75%, op_acc: 67.19%] [G loss: 1.332278]\n",
      "893 [D loss: 0.234748, acc: 88.28%, op_acc: 62.50%] [G loss: 1.361328]\n",
      "894 [D loss: 0.231845, acc: 88.28%, op_acc: 61.72%] [G loss: 1.312655]\n",
      "895 [D loss: 0.243948, acc: 85.94%, op_acc: 65.62%] [G loss: 1.301806]\n",
      "896 [D loss: 0.232084, acc: 93.75%, op_acc: 67.19%] [G loss: 1.372533]\n",
      "897 [D loss: 0.239103, acc: 91.41%, op_acc: 71.09%] [G loss: 1.308402]\n",
      "898 [D loss: 0.233582, acc: 88.28%, op_acc: 64.84%] [G loss: 1.388351]\n",
      "899 [D loss: 0.223122, acc: 89.84%, op_acc: 68.75%] [G loss: 1.366543]\n",
      "900 [D loss: 0.229185, acc: 91.41%, op_acc: 64.84%] [G loss: 1.411567]\n",
      "Epoch: 900, F1: 0.71579, F1P: 90\n",
      "[[28420    12]\n",
      " [   15    34]]\n",
      "90.234375\n",
      "901 [D loss: 0.240041, acc: 90.62%, op_acc: 67.97%] [G loss: 1.292084]\n",
      "902 [D loss: 0.235793, acc: 90.62%, op_acc: 67.19%] [G loss: 1.326113]\n",
      "903 [D loss: 0.230143, acc: 89.84%, op_acc: 60.94%] [G loss: 1.384125]\n",
      "904 [D loss: 0.221971, acc: 88.28%, op_acc: 57.03%] [G loss: 1.353001]\n",
      "905 [D loss: 0.228823, acc: 88.28%, op_acc: 64.06%] [G loss: 1.273128]\n",
      "906 [D loss: 0.221965, acc: 88.28%, op_acc: 60.94%] [G loss: 1.327661]\n",
      "907 [D loss: 0.233097, acc: 89.06%, op_acc: 59.38%] [G loss: 1.333853]\n",
      "908 [D loss: 0.229611, acc: 90.62%, op_acc: 64.06%] [G loss: 1.391673]\n",
      "909 [D loss: 0.235161, acc: 89.06%, op_acc: 63.28%] [G loss: 1.321036]\n",
      "910 [D loss: 0.227609, acc: 89.84%, op_acc: 71.88%] [G loss: 1.329697]\n",
      "Epoch: 910, F1: 0.68132, F1P: 91\n",
      "[[28421    11]\n",
      " [   18    31]]\n",
      "89.453125\n",
      "911 [D loss: 0.233337, acc: 89.84%, op_acc: 59.38%] [G loss: 1.272760]\n",
      "912 [D loss: 0.248920, acc: 84.38%, op_acc: 60.16%] [G loss: 1.385647]\n",
      "913 [D loss: 0.240632, acc: 86.72%, op_acc: 71.09%] [G loss: 1.353294]\n",
      "914 [D loss: 0.225595, acc: 89.84%, op_acc: 68.75%] [G loss: 1.383195]\n",
      "915 [D loss: 0.221020, acc: 93.75%, op_acc: 65.62%] [G loss: 1.343335]\n",
      "916 [D loss: 0.232042, acc: 89.06%, op_acc: 64.06%] [G loss: 1.379547]\n",
      "917 [D loss: 0.226453, acc: 88.28%, op_acc: 62.50%] [G loss: 1.379072]\n",
      "918 [D loss: 0.252176, acc: 87.50%, op_acc: 63.28%] [G loss: 1.358696]\n",
      "919 [D loss: 0.234806, acc: 89.84%, op_acc: 71.88%] [G loss: 1.380860]\n",
      "920 [D loss: 0.234547, acc: 87.50%, op_acc: 57.03%] [G loss: 1.391745]\n",
      "Epoch: 920, F1: 0.68132, F1P: 92\n",
      "[[28421    11]\n",
      " [   18    31]]\n",
      "88.671875\n",
      "921 [D loss: 0.236304, acc: 90.62%, op_acc: 66.41%] [G loss: 1.326988]\n",
      "922 [D loss: 0.232322, acc: 87.50%, op_acc: 65.62%] [G loss: 1.412720]\n",
      "923 [D loss: 0.224238, acc: 92.19%, op_acc: 60.94%] [G loss: 1.364554]\n",
      "924 [D loss: 0.217508, acc: 92.19%, op_acc: 68.75%] [G loss: 1.387990]\n",
      "925 [D loss: 0.224085, acc: 89.06%, op_acc: 71.09%] [G loss: 1.366266]\n",
      "926 [D loss: 0.230300, acc: 89.06%, op_acc: 71.09%] [G loss: 1.370627]\n",
      "927 [D loss: 0.221124, acc: 92.97%, op_acc: 67.19%] [G loss: 1.362346]\n",
      "928 [D loss: 0.216740, acc: 92.19%, op_acc: 69.53%] [G loss: 1.353914]\n",
      "929 [D loss: 0.209735, acc: 89.84%, op_acc: 72.66%] [G loss: 1.324514]\n",
      "930 [D loss: 0.237444, acc: 88.28%, op_acc: 63.28%] [G loss: 1.416929]\n",
      "Epoch: 930, F1: 0.68889, F1P: 93\n",
      "[[28422    10]\n",
      " [   18    31]]\n",
      "90.390625\n",
      "931 [D loss: 0.223371, acc: 87.50%, op_acc: 64.84%] [G loss: 1.375844]\n",
      "932 [D loss: 0.246922, acc: 84.38%, op_acc: 64.84%] [G loss: 1.373747]\n",
      "933 [D loss: 0.219252, acc: 89.06%, op_acc: 64.06%] [G loss: 1.433107]\n",
      "934 [D loss: 0.244726, acc: 83.59%, op_acc: 67.97%] [G loss: 1.450959]\n",
      "935 [D loss: 0.217216, acc: 90.62%, op_acc: 71.88%] [G loss: 1.337494]\n",
      "936 [D loss: 0.246254, acc: 85.94%, op_acc: 65.62%] [G loss: 1.403609]\n",
      "937 [D loss: 0.236831, acc: 86.72%, op_acc: 67.19%] [G loss: 1.396589]\n",
      "938 [D loss: 0.228223, acc: 85.16%, op_acc: 62.50%] [G loss: 1.290612]\n",
      "939 [D loss: 0.225724, acc: 88.28%, op_acc: 65.62%] [G loss: 1.440939]\n",
      "940 [D loss: 0.232054, acc: 89.84%, op_acc: 66.41%] [G loss: 1.385569]\n",
      "Epoch: 940, F1: 0.68889, F1P: 94\n",
      "[[28422    10]\n",
      " [   18    31]]\n",
      "87.109375\n",
      "941 [D loss: 0.224129, acc: 89.84%, op_acc: 63.28%] [G loss: 1.341714]\n",
      "942 [D loss: 0.221368, acc: 88.28%, op_acc: 65.62%] [G loss: 1.356996]\n",
      "943 [D loss: 0.218891, acc: 87.50%, op_acc: 68.75%] [G loss: 1.366499]\n",
      "944 [D loss: 0.231505, acc: 89.06%, op_acc: 69.53%] [G loss: 1.347096]\n",
      "945 [D loss: 0.215702, acc: 92.97%, op_acc: 67.97%] [G loss: 1.318410]\n",
      "946 [D loss: 0.237238, acc: 82.03%, op_acc: 69.53%] [G loss: 1.425612]\n",
      "947 [D loss: 0.239265, acc: 86.72%, op_acc: 64.06%] [G loss: 1.389229]\n",
      "948 [D loss: 0.223563, acc: 91.41%, op_acc: 69.53%] [G loss: 1.423368]\n",
      "949 [D loss: 0.220911, acc: 91.41%, op_acc: 61.72%] [G loss: 1.403414]\n",
      "950 [D loss: 0.228281, acc: 86.72%, op_acc: 64.84%] [G loss: 1.478118]\n",
      "Epoch: 950, F1: 0.68889, F1P: 95\n",
      "[[28422    10]\n",
      " [   18    31]]\n",
      "88.59375\n",
      "951 [D loss: 0.217958, acc: 92.19%, op_acc: 69.53%] [G loss: 1.318163]\n",
      "952 [D loss: 0.211646, acc: 92.97%, op_acc: 71.88%] [G loss: 1.400178]\n",
      "953 [D loss: 0.231018, acc: 87.50%, op_acc: 59.38%] [G loss: 1.346346]\n",
      "954 [D loss: 0.221201, acc: 90.62%, op_acc: 64.06%] [G loss: 1.388912]\n",
      "955 [D loss: 0.232966, acc: 85.94%, op_acc: 68.75%] [G loss: 1.372087]\n",
      "956 [D loss: 0.225805, acc: 89.06%, op_acc: 57.81%] [G loss: 1.416347]\n",
      "957 [D loss: 0.209739, acc: 92.97%, op_acc: 70.31%] [G loss: 1.485772]\n",
      "958 [D loss: 0.223401, acc: 91.41%, op_acc: 66.41%] [G loss: 1.317214]\n",
      "959 [D loss: 0.220118, acc: 91.41%, op_acc: 68.75%] [G loss: 1.425643]\n",
      "960 [D loss: 0.231044, acc: 90.62%, op_acc: 61.72%] [G loss: 1.392425]\n",
      "Epoch: 960, F1: 0.65909, F1P: 96\n",
      "[[28422    10]\n",
      " [   20    29]]\n",
      "90.46875\n",
      "961 [D loss: 0.229928, acc: 90.62%, op_acc: 61.72%] [G loss: 1.295720]\n",
      "962 [D loss: 0.230245, acc: 85.16%, op_acc: 67.97%] [G loss: 1.424073]\n",
      "963 [D loss: 0.224260, acc: 89.06%, op_acc: 67.19%] [G loss: 1.405186]\n",
      "964 [D loss: 0.220565, acc: 90.62%, op_acc: 64.06%] [G loss: 1.403183]\n",
      "965 [D loss: 0.224888, acc: 89.06%, op_acc: 66.41%] [G loss: 1.418053]\n",
      "966 [D loss: 0.220200, acc: 92.19%, op_acc: 64.84%] [G loss: 1.412552]\n",
      "967 [D loss: 0.222390, acc: 89.06%, op_acc: 67.19%] [G loss: 1.337890]\n",
      "968 [D loss: 0.235734, acc: 85.94%, op_acc: 57.81%] [G loss: 1.393674]\n",
      "969 [D loss: 0.204206, acc: 96.09%, op_acc: 68.75%] [G loss: 1.374689]\n",
      "970 [D loss: 0.217360, acc: 92.19%, op_acc: 72.66%] [G loss: 1.365067]\n",
      "Epoch: 970, F1: 0.65909, F1P: 97\n",
      "[[28422    10]\n",
      " [   20    29]]\n",
      "90.0\n",
      "971 [D loss: 0.227884, acc: 86.72%, op_acc: 61.72%] [G loss: 1.415199]\n",
      "972 [D loss: 0.225235, acc: 88.28%, op_acc: 67.19%] [G loss: 1.469804]\n",
      "973 [D loss: 0.222605, acc: 91.41%, op_acc: 67.97%] [G loss: 1.418517]\n",
      "974 [D loss: 0.221155, acc: 89.84%, op_acc: 65.62%] [G loss: 1.504226]\n",
      "975 [D loss: 0.241090, acc: 85.16%, op_acc: 67.97%] [G loss: 1.369987]\n",
      "976 [D loss: 0.219558, acc: 88.28%, op_acc: 63.28%] [G loss: 1.445456]\n",
      "977 [D loss: 0.228074, acc: 91.41%, op_acc: 60.94%] [G loss: 1.420561]\n",
      "978 [D loss: 0.220636, acc: 85.16%, op_acc: 66.41%] [G loss: 1.371775]\n",
      "979 [D loss: 0.210602, acc: 92.97%, op_acc: 60.16%] [G loss: 1.385579]\n",
      "980 [D loss: 0.235460, acc: 87.50%, op_acc: 67.97%] [G loss: 1.418336]\n",
      "Epoch: 980, F1: 0.65882, F1P: 98\n",
      "[[28424     8]\n",
      " [   21    28]]\n",
      "88.671875\n",
      "981 [D loss: 0.221217, acc: 89.84%, op_acc: 66.41%] [G loss: 1.316110]\n",
      "982 [D loss: 0.221414, acc: 89.84%, op_acc: 70.31%] [G loss: 1.388903]\n",
      "983 [D loss: 0.214854, acc: 92.97%, op_acc: 72.66%] [G loss: 1.444789]\n",
      "984 [D loss: 0.214905, acc: 95.31%, op_acc: 65.62%] [G loss: 1.354168]\n",
      "985 [D loss: 0.218523, acc: 91.41%, op_acc: 67.97%] [G loss: 1.325890]\n",
      "986 [D loss: 0.218813, acc: 90.62%, op_acc: 71.09%] [G loss: 1.440936]\n",
      "987 [D loss: 0.227096, acc: 85.94%, op_acc: 66.41%] [G loss: 1.344770]\n",
      "988 [D loss: 0.223335, acc: 89.84%, op_acc: 67.19%] [G loss: 1.388527]\n",
      "989 [D loss: 0.231190, acc: 85.94%, op_acc: 60.16%] [G loss: 1.422547]\n",
      "990 [D loss: 0.245868, acc: 80.47%, op_acc: 63.28%] [G loss: 1.407459]\n",
      "Epoch: 990, F1: 0.67470, F1P: 99\n",
      "[[28426     6]\n",
      " [   21    28]]\n",
      "89.21875\n",
      "991 [D loss: 0.218888, acc: 88.28%, op_acc: 63.28%] [G loss: 1.399023]\n",
      "992 [D loss: 0.222249, acc: 87.50%, op_acc: 67.97%] [G loss: 1.445203]\n",
      "993 [D loss: 0.223173, acc: 91.41%, op_acc: 69.53%] [G loss: 1.392290]\n",
      "994 [D loss: 0.217115, acc: 92.19%, op_acc: 69.53%] [G loss: 1.340987]\n",
      "995 [D loss: 0.232607, acc: 85.16%, op_acc: 67.97%] [G loss: 1.348044]\n",
      "996 [D loss: 0.218051, acc: 92.97%, op_acc: 69.53%] [G loss: 1.474010]\n",
      "997 [D loss: 0.223010, acc: 89.84%, op_acc: 73.44%] [G loss: 1.296771]\n",
      "998 [D loss: 0.219806, acc: 89.84%, op_acc: 69.53%] [G loss: 1.386740]\n",
      "999 [D loss: 0.215362, acc: 89.84%, op_acc: 64.84%] [G loss: 1.361448]\n",
      "1000 [D loss: 0.207000, acc: 91.41%, op_acc: 62.50%] [G loss: 1.396876]\n",
      "Epoch: 1000, F1: 0.67470, F1P: 100\n",
      "[[28426     6]\n",
      " [   21    28]]\n",
      "89.84375\n",
      "1001 [D loss: 0.222836, acc: 87.50%, op_acc: 67.19%] [G loss: 1.378460]\n",
      "1002 [D loss: 0.231449, acc: 88.28%, op_acc: 57.03%] [G loss: 1.407775]\n",
      "1003 [D loss: 0.233039, acc: 88.28%, op_acc: 65.62%] [G loss: 1.332067]\n",
      "1004 [D loss: 0.229325, acc: 87.50%, op_acc: 70.31%] [G loss: 1.321601]\n",
      "1005 [D loss: 0.226758, acc: 85.94%, op_acc: 64.06%] [G loss: 1.382058]\n",
      "1006 [D loss: 0.233103, acc: 85.94%, op_acc: 63.28%] [G loss: 1.409774]\n",
      "1007 [D loss: 0.210784, acc: 87.50%, op_acc: 65.62%] [G loss: 1.365377]\n",
      "1008 [D loss: 0.229796, acc: 89.06%, op_acc: 59.38%] [G loss: 1.376141]\n",
      "1009 [D loss: 0.239876, acc: 86.72%, op_acc: 60.16%] [G loss: 1.303957]\n",
      "1010 [D loss: 0.244311, acc: 82.81%, op_acc: 58.59%] [G loss: 1.384158]\n",
      "Epoch: 1010, F1: 0.67470, F1P: 101\n",
      "[[28426     6]\n",
      " [   21    28]]\n",
      "86.953125\n",
      "1011 [D loss: 0.223204, acc: 88.28%, op_acc: 62.50%] [G loss: 1.411034]\n",
      "1012 [D loss: 0.219703, acc: 90.62%, op_acc: 66.41%] [G loss: 1.398859]\n",
      "1013 [D loss: 0.219467, acc: 89.06%, op_acc: 71.88%] [G loss: 1.385926]\n",
      "1014 [D loss: 0.229292, acc: 89.84%, op_acc: 67.97%] [G loss: 1.431843]\n",
      "1015 [D loss: 0.229802, acc: 89.06%, op_acc: 65.62%] [G loss: 1.471249]\n",
      "1016 [D loss: 0.217922, acc: 89.84%, op_acc: 67.19%] [G loss: 1.459802]\n",
      "1017 [D loss: 0.228726, acc: 91.41%, op_acc: 63.28%] [G loss: 1.411976]\n",
      "1018 [D loss: 0.237867, acc: 89.84%, op_acc: 66.41%] [G loss: 1.399641]\n",
      "1019 [D loss: 0.215272, acc: 88.28%, op_acc: 68.75%] [G loss: 1.331875]\n",
      "1020 [D loss: 0.218755, acc: 90.62%, op_acc: 67.97%] [G loss: 1.376132]\n",
      "Epoch: 1020, F1: 0.67470, F1P: 102\n",
      "[[28426     6]\n",
      " [   21    28]]\n",
      "89.6875\n",
      "1021 [D loss: 0.215450, acc: 89.84%, op_acc: 62.50%] [G loss: 1.337266]\n",
      "1022 [D loss: 0.213857, acc: 92.97%, op_acc: 62.50%] [G loss: 1.441452]\n",
      "1023 [D loss: 0.221721, acc: 89.06%, op_acc: 67.19%] [G loss: 1.416406]\n",
      "1024 [D loss: 0.234421, acc: 85.94%, op_acc: 66.41%] [G loss: 1.449577]\n",
      "1025 [D loss: 0.212060, acc: 89.84%, op_acc: 71.88%] [G loss: 1.371343]\n",
      "1026 [D loss: 0.225087, acc: 88.28%, op_acc: 63.28%] [G loss: 1.453569]\n",
      "1027 [D loss: 0.223892, acc: 85.16%, op_acc: 67.97%] [G loss: 1.438901]\n",
      "1028 [D loss: 0.224496, acc: 91.41%, op_acc: 62.50%] [G loss: 1.484691]\n",
      "1029 [D loss: 0.210781, acc: 93.75%, op_acc: 73.44%] [G loss: 1.419903]\n",
      "1030 [D loss: 0.220930, acc: 90.62%, op_acc: 64.84%] [G loss: 1.365792]\n",
      "Epoch: 1030, F1: 0.67470, F1P: 103\n",
      "[[28426     6]\n",
      " [   21    28]]\n",
      "89.6875\n",
      "1031 [D loss: 0.213500, acc: 92.19%, op_acc: 73.44%] [G loss: 1.377933]\n",
      "1032 [D loss: 0.236642, acc: 87.50%, op_acc: 66.41%] [G loss: 1.431883]\n",
      "1033 [D loss: 0.217657, acc: 92.19%, op_acc: 65.62%] [G loss: 1.348275]\n",
      "1034 [D loss: 0.221462, acc: 89.06%, op_acc: 71.09%] [G loss: 1.346644]\n",
      "1035 [D loss: 0.212450, acc: 88.28%, op_acc: 65.62%] [G loss: 1.422560]\n",
      "1036 [D loss: 0.227470, acc: 88.28%, op_acc: 64.84%] [G loss: 1.402357]\n",
      "1037 [D loss: 0.225240, acc: 85.94%, op_acc: 67.19%] [G loss: 1.420456]\n",
      "1038 [D loss: 0.224695, acc: 90.62%, op_acc: 64.84%] [G loss: 1.374819]\n",
      "1039 [D loss: 0.227843, acc: 92.19%, op_acc: 71.88%] [G loss: 1.397817]\n",
      "1040 [D loss: 0.224275, acc: 88.28%, op_acc: 75.00%] [G loss: 1.422259]\n",
      "Epoch: 1040, F1: 0.67470, F1P: 104\n",
      "[[28426     6]\n",
      " [   21    28]]\n",
      "89.453125\n",
      "1041 [D loss: 0.215982, acc: 92.97%, op_acc: 72.66%] [G loss: 1.438984]\n",
      "1042 [D loss: 0.229297, acc: 87.50%, op_acc: 63.28%] [G loss: 1.393861]\n",
      "1043 [D loss: 0.227171, acc: 88.28%, op_acc: 71.88%] [G loss: 1.389667]\n",
      "1044 [D loss: 0.214476, acc: 92.19%, op_acc: 67.97%] [G loss: 1.430766]\n",
      "1045 [D loss: 0.197563, acc: 93.75%, op_acc: 75.00%] [G loss: 1.420614]\n",
      "1046 [D loss: 0.213250, acc: 92.97%, op_acc: 67.97%] [G loss: 1.469918]\n",
      "1047 [D loss: 0.214162, acc: 92.97%, op_acc: 69.53%] [G loss: 1.356603]\n",
      "1048 [D loss: 0.209188, acc: 93.75%, op_acc: 69.53%] [G loss: 1.386612]\n",
      "1049 [D loss: 0.215111, acc: 94.53%, op_acc: 71.09%] [G loss: 1.372090]\n",
      "1050 [D loss: 0.208985, acc: 90.62%, op_acc: 70.31%] [G loss: 1.368856]\n",
      "Epoch: 1050, F1: 0.67470, F1P: 105\n",
      "[[28426     6]\n",
      " [   21    28]]\n",
      "91.953125\n",
      "1051 [D loss: 0.220144, acc: 89.84%, op_acc: 68.75%] [G loss: 1.437312]\n",
      "1052 [D loss: 0.214939, acc: 89.84%, op_acc: 71.88%] [G loss: 1.372497]\n",
      "1053 [D loss: 0.221944, acc: 85.94%, op_acc: 72.66%] [G loss: 1.493490]\n",
      "1054 [D loss: 0.230358, acc: 86.72%, op_acc: 66.41%] [G loss: 1.463307]\n",
      "1055 [D loss: 0.219885, acc: 89.06%, op_acc: 68.75%] [G loss: 1.362240]\n",
      "1056 [D loss: 0.197631, acc: 96.09%, op_acc: 73.44%] [G loss: 1.472367]\n",
      "1057 [D loss: 0.217480, acc: 92.97%, op_acc: 67.97%] [G loss: 1.395705]\n",
      "1058 [D loss: 0.221789, acc: 89.06%, op_acc: 64.84%] [G loss: 1.423590]\n",
      "1059 [D loss: 0.220350, acc: 88.28%, op_acc: 67.19%] [G loss: 1.454997]\n",
      "1060 [D loss: 0.221546, acc: 89.06%, op_acc: 67.19%] [G loss: 1.337825]\n",
      "Epoch: 1060, F1: 0.67470, F1P: 106\n",
      "[[28426     6]\n",
      " [   21    28]]\n",
      "89.6875\n",
      "1061 [D loss: 0.219163, acc: 89.06%, op_acc: 70.31%] [G loss: 1.434575]\n",
      "1062 [D loss: 0.219203, acc: 87.50%, op_acc: 65.62%] [G loss: 1.456757]\n",
      "1063 [D loss: 0.202836, acc: 92.97%, op_acc: 66.41%] [G loss: 1.468271]\n",
      "1064 [D loss: 0.217723, acc: 88.28%, op_acc: 65.62%] [G loss: 1.515124]\n",
      "1065 [D loss: 0.216789, acc: 89.84%, op_acc: 73.44%] [G loss: 1.459556]\n",
      "1066 [D loss: 0.215537, acc: 88.28%, op_acc: 65.62%] [G loss: 1.460809]\n",
      "1067 [D loss: 0.218143, acc: 86.72%, op_acc: 68.75%] [G loss: 1.408714]\n",
      "1068 [D loss: 0.199744, acc: 92.97%, op_acc: 68.75%] [G loss: 1.481712]\n",
      "1069 [D loss: 0.214820, acc: 89.06%, op_acc: 79.69%] [G loss: 1.368819]\n",
      "1070 [D loss: 0.216339, acc: 90.62%, op_acc: 73.44%] [G loss: 1.362315]\n",
      "Epoch: 1070, F1: 0.67470, F1P: 107\n",
      "[[28426     6]\n",
      " [   21    28]]\n",
      "89.53125\n",
      "1071 [D loss: 0.209918, acc: 94.53%, op_acc: 71.09%] [G loss: 1.417988]\n",
      "1072 [D loss: 0.215075, acc: 89.06%, op_acc: 65.62%] [G loss: 1.425209]\n",
      "1073 [D loss: 0.211916, acc: 89.84%, op_acc: 74.22%] [G loss: 1.409271]\n",
      "1074 [D loss: 0.214178, acc: 92.19%, op_acc: 66.41%] [G loss: 1.400282]\n",
      "1075 [D loss: 0.207935, acc: 91.41%, op_acc: 67.19%] [G loss: 1.536351]\n",
      "1076 [D loss: 0.216163, acc: 89.84%, op_acc: 64.84%] [G loss: 1.472597]\n",
      "1077 [D loss: 0.206149, acc: 92.97%, op_acc: 67.97%] [G loss: 1.389519]\n",
      "1078 [D loss: 0.208361, acc: 91.41%, op_acc: 73.44%] [G loss: 1.513222]\n",
      "1079 [D loss: 0.212989, acc: 89.84%, op_acc: 73.44%] [G loss: 1.441240]\n",
      "1080 [D loss: 0.220281, acc: 89.84%, op_acc: 68.75%] [G loss: 1.408273]\n",
      "Epoch: 1080, F1: 0.67470, F1P: 108\n",
      "[[28426     6]\n",
      " [   21    28]]\n",
      "91.09375\n",
      "1081 [D loss: 0.210277, acc: 92.19%, op_acc: 63.28%] [G loss: 1.456361]\n",
      "1082 [D loss: 0.218463, acc: 88.28%, op_acc: 67.97%] [G loss: 1.434957]\n",
      "1083 [D loss: 0.219449, acc: 89.84%, op_acc: 64.84%] [G loss: 1.384314]\n",
      "1084 [D loss: 0.243944, acc: 82.81%, op_acc: 62.50%] [G loss: 1.460799]\n",
      "1085 [D loss: 0.197171, acc: 89.06%, op_acc: 68.75%] [G loss: 1.448701]\n",
      "1086 [D loss: 0.205276, acc: 92.19%, op_acc: 73.44%] [G loss: 1.447018]\n",
      "1087 [D loss: 0.214379, acc: 85.94%, op_acc: 68.75%] [G loss: 1.450181]\n",
      "1088 [D loss: 0.212089, acc: 93.75%, op_acc: 69.53%] [G loss: 1.435680]\n",
      "1089 [D loss: 0.209297, acc: 92.19%, op_acc: 69.53%] [G loss: 1.475669]\n",
      "1090 [D loss: 0.204145, acc: 92.97%, op_acc: 71.88%] [G loss: 1.421600]\n",
      "Epoch: 1090, F1: 0.65854, F1P: 109\n",
      "[[28426     6]\n",
      " [   22    27]]\n",
      "89.921875\n",
      "1091 [D loss: 0.214227, acc: 87.50%, op_acc: 67.97%] [G loss: 1.450896]\n",
      "1092 [D loss: 0.220117, acc: 86.72%, op_acc: 64.06%] [G loss: 1.528990]\n",
      "1093 [D loss: 0.199586, acc: 93.75%, op_acc: 68.75%] [G loss: 1.521281]\n",
      "1094 [D loss: 0.207165, acc: 92.19%, op_acc: 73.44%] [G loss: 1.522040]\n",
      "1095 [D loss: 0.205534, acc: 94.53%, op_acc: 73.44%] [G loss: 1.370471]\n",
      "1096 [D loss: 0.195820, acc: 92.97%, op_acc: 67.19%] [G loss: 1.450962]\n",
      "1097 [D loss: 0.216514, acc: 90.62%, op_acc: 70.31%] [G loss: 1.465852]\n",
      "1098 [D loss: 0.215909, acc: 89.06%, op_acc: 62.50%] [G loss: 1.395697]\n",
      "1099 [D loss: 0.217385, acc: 92.19%, op_acc: 67.19%] [G loss: 1.413423]\n",
      "1100 [D loss: 0.210495, acc: 92.19%, op_acc: 66.41%] [G loss: 1.471619]\n",
      "Epoch: 1100, F1: 0.67470, F1P: 110\n",
      "[[28426     6]\n",
      " [   21    28]]\n",
      "91.171875\n",
      "1101 [D loss: 0.212832, acc: 91.41%, op_acc: 62.50%] [G loss: 1.429934]\n",
      "1102 [D loss: 0.217156, acc: 90.62%, op_acc: 59.38%] [G loss: 1.452660]\n",
      "1103 [D loss: 0.217238, acc: 89.84%, op_acc: 67.97%] [G loss: 1.485642]\n",
      "1104 [D loss: 0.224150, acc: 91.41%, op_acc: 69.53%] [G loss: 1.510863]\n",
      "1105 [D loss: 0.206487, acc: 92.97%, op_acc: 70.31%] [G loss: 1.404596]\n",
      "1106 [D loss: 0.203139, acc: 94.53%, op_acc: 77.34%] [G loss: 1.510955]\n",
      "1107 [D loss: 0.201946, acc: 92.19%, op_acc: 70.31%] [G loss: 1.468639]\n",
      "1108 [D loss: 0.198666, acc: 92.19%, op_acc: 67.97%] [G loss: 1.470271]\n",
      "1109 [D loss: 0.211376, acc: 89.06%, op_acc: 70.31%] [G loss: 1.488365]\n",
      "1110 [D loss: 0.212602, acc: 92.97%, op_acc: 68.75%] [G loss: 1.557022]\n",
      "Epoch: 1110, F1: 0.67470, F1P: 111\n",
      "[[28426     6]\n",
      " [   21    28]]\n",
      "91.71875\n",
      "1111 [D loss: 0.208745, acc: 92.19%, op_acc: 71.88%] [G loss: 1.547071]\n",
      "1112 [D loss: 0.200601, acc: 92.97%, op_acc: 66.41%] [G loss: 1.477205]\n",
      "1113 [D loss: 0.196702, acc: 89.84%, op_acc: 69.53%] [G loss: 1.522997]\n",
      "1114 [D loss: 0.203223, acc: 91.41%, op_acc: 69.53%] [G loss: 1.590712]\n",
      "1115 [D loss: 0.210813, acc: 92.19%, op_acc: 66.41%] [G loss: 1.477207]\n",
      "1116 [D loss: 0.192731, acc: 93.75%, op_acc: 71.88%] [G loss: 1.542256]\n",
      "1117 [D loss: 0.204474, acc: 92.97%, op_acc: 67.19%] [G loss: 1.526577]\n",
      "1118 [D loss: 0.208007, acc: 91.41%, op_acc: 71.88%] [G loss: 1.545707]\n",
      "1119 [D loss: 0.210535, acc: 94.53%, op_acc: 66.41%] [G loss: 1.557445]\n",
      "1120 [D loss: 0.207024, acc: 86.72%, op_acc: 64.84%] [G loss: 1.486720]\n",
      "Epoch: 1120, F1: 0.67470, F1P: 112\n",
      "[[28426     6]\n",
      " [   21    28]]\n",
      "91.796875\n",
      "1121 [D loss: 0.201312, acc: 92.19%, op_acc: 72.66%] [G loss: 1.582115]\n",
      "1122 [D loss: 0.203140, acc: 89.84%, op_acc: 70.31%] [G loss: 1.469739]\n",
      "1123 [D loss: 0.200302, acc: 93.75%, op_acc: 66.41%] [G loss: 1.484544]\n",
      "1124 [D loss: 0.224486, acc: 88.28%, op_acc: 68.75%] [G loss: 1.416547]\n",
      "1125 [D loss: 0.212888, acc: 89.84%, op_acc: 68.75%] [G loss: 1.470178]\n",
      "1126 [D loss: 0.207101, acc: 93.75%, op_acc: 71.88%] [G loss: 1.498334]\n",
      "1127 [D loss: 0.195033, acc: 91.41%, op_acc: 68.75%] [G loss: 1.568742]\n",
      "1128 [D loss: 0.197111, acc: 94.53%, op_acc: 58.59%] [G loss: 1.565899]\n",
      "1129 [D loss: 0.192919, acc: 91.41%, op_acc: 69.53%] [G loss: 1.487858]\n",
      "1130 [D loss: 0.206152, acc: 90.62%, op_acc: 75.78%] [G loss: 1.538650]\n",
      "Epoch: 1130, F1: 0.67470, F1P: 113\n",
      "[[28426     6]\n",
      " [   21    28]]\n",
      "91.5625\n",
      "1131 [D loss: 0.207534, acc: 92.19%, op_acc: 71.09%] [G loss: 1.541938]\n",
      "1132 [D loss: 0.220462, acc: 85.94%, op_acc: 67.19%] [G loss: 1.552789]\n",
      "1133 [D loss: 0.212057, acc: 93.75%, op_acc: 64.06%] [G loss: 1.468003]\n",
      "1134 [D loss: 0.204784, acc: 89.84%, op_acc: 65.62%] [G loss: 1.570449]\n",
      "1135 [D loss: 0.214287, acc: 87.50%, op_acc: 73.44%] [G loss: 1.446879]\n",
      "1136 [D loss: 0.214707, acc: 92.19%, op_acc: 68.75%] [G loss: 1.527909]\n",
      "1137 [D loss: 0.204680, acc: 94.53%, op_acc: 71.88%] [G loss: 1.424974]\n",
      "1138 [D loss: 0.204461, acc: 96.88%, op_acc: 59.38%] [G loss: 1.480691]\n",
      "1139 [D loss: 0.215692, acc: 91.41%, op_acc: 65.62%] [G loss: 1.488708]\n",
      "1140 [D loss: 0.191581, acc: 92.97%, op_acc: 73.44%] [G loss: 1.457147]\n",
      "Epoch: 1140, F1: 0.66667, F1P: 114\n",
      "[[28425     7]\n",
      " [   21    28]]\n",
      "91.71875\n",
      "1141 [D loss: 0.203230, acc: 89.84%, op_acc: 68.75%] [G loss: 1.546255]\n",
      "1142 [D loss: 0.219325, acc: 89.06%, op_acc: 71.88%] [G loss: 1.595948]\n",
      "1143 [D loss: 0.219693, acc: 89.06%, op_acc: 65.62%] [G loss: 1.598421]\n",
      "1144 [D loss: 0.204652, acc: 89.84%, op_acc: 62.50%] [G loss: 1.535607]\n",
      "1145 [D loss: 0.204302, acc: 94.53%, op_acc: 64.06%] [G loss: 1.590042]\n",
      "1146 [D loss: 0.189169, acc: 92.97%, op_acc: 71.09%] [G loss: 1.603035]\n",
      "1147 [D loss: 0.195419, acc: 96.09%, op_acc: 67.97%] [G loss: 1.494496]\n",
      "1148 [D loss: 0.198549, acc: 91.41%, op_acc: 74.22%] [G loss: 1.546400]\n",
      "1149 [D loss: 0.210849, acc: 89.06%, op_acc: 67.19%] [G loss: 1.613109]\n",
      "1150 [D loss: 0.206442, acc: 92.19%, op_acc: 72.66%] [G loss: 1.475062]\n",
      "Epoch: 1150, F1: 0.65060, F1P: 115\n",
      "[[28425     7]\n",
      " [   22    27]]\n",
      "91.40625\n",
      "1151 [D loss: 0.197968, acc: 90.62%, op_acc: 66.41%] [G loss: 1.590477]\n",
      "1152 [D loss: 0.209267, acc: 87.50%, op_acc: 67.19%] [G loss: 1.563581]\n",
      "1153 [D loss: 0.194595, acc: 91.41%, op_acc: 72.66%] [G loss: 1.589271]\n",
      "1154 [D loss: 0.194721, acc: 95.31%, op_acc: 76.56%] [G loss: 1.518257]\n",
      "1155 [D loss: 0.206993, acc: 89.06%, op_acc: 75.00%] [G loss: 1.550747]\n",
      "1156 [D loss: 0.187012, acc: 95.31%, op_acc: 67.97%] [G loss: 1.506857]\n",
      "1157 [D loss: 0.185024, acc: 96.09%, op_acc: 73.44%] [G loss: 1.512147]\n",
      "1158 [D loss: 0.200550, acc: 91.41%, op_acc: 71.88%] [G loss: 1.575201]\n",
      "1159 [D loss: 0.190152, acc: 94.53%, op_acc: 68.75%] [G loss: 1.511882]\n",
      "1160 [D loss: 0.189862, acc: 93.75%, op_acc: 63.28%] [G loss: 1.541909]\n",
      "Epoch: 1160, F1: 0.65060, F1P: 116\n",
      "[[28425     7]\n",
      " [   22    27]]\n",
      "92.5\n",
      "1161 [D loss: 0.195101, acc: 93.75%, op_acc: 71.09%] [G loss: 1.556230]\n",
      "1162 [D loss: 0.193185, acc: 93.75%, op_acc: 68.75%] [G loss: 1.537904]\n",
      "1163 [D loss: 0.183208, acc: 95.31%, op_acc: 73.44%] [G loss: 1.649582]\n",
      "1164 [D loss: 0.189451, acc: 92.19%, op_acc: 67.19%] [G loss: 1.595926]\n",
      "1165 [D loss: 0.183744, acc: 94.53%, op_acc: 75.00%] [G loss: 1.703652]\n",
      "1166 [D loss: 0.206295, acc: 93.75%, op_acc: 65.62%] [G loss: 1.633987]\n",
      "1167 [D loss: 0.196938, acc: 92.19%, op_acc: 70.31%] [G loss: 1.653154]\n",
      "1168 [D loss: 0.194224, acc: 92.19%, op_acc: 66.41%] [G loss: 1.619238]\n",
      "1169 [D loss: 0.191009, acc: 92.19%, op_acc: 72.66%] [G loss: 1.613911]\n",
      "1170 [D loss: 0.187312, acc: 92.19%, op_acc: 70.31%] [G loss: 1.615975]\n",
      "Epoch: 1170, F1: 0.65060, F1P: 117\n",
      "[[28425     7]\n",
      " [   22    27]]\n",
      "93.203125\n",
      "1171 [D loss: 0.196989, acc: 90.62%, op_acc: 71.88%] [G loss: 1.537694]\n",
      "1172 [D loss: 0.190350, acc: 94.53%, op_acc: 75.00%] [G loss: 1.626698]\n",
      "1173 [D loss: 0.193140, acc: 92.97%, op_acc: 71.09%] [G loss: 1.679728]\n",
      "1174 [D loss: 0.196065, acc: 92.19%, op_acc: 71.88%] [G loss: 1.640712]\n",
      "1175 [D loss: 0.182204, acc: 94.53%, op_acc: 71.88%] [G loss: 1.615753]\n",
      "1176 [D loss: 0.181428, acc: 93.75%, op_acc: 78.91%] [G loss: 1.668250]\n",
      "1177 [D loss: 0.189585, acc: 92.19%, op_acc: 74.22%] [G loss: 1.534463]\n",
      "1178 [D loss: 0.196620, acc: 92.19%, op_acc: 72.66%] [G loss: 1.584457]\n",
      "1179 [D loss: 0.211765, acc: 91.41%, op_acc: 67.19%] [G loss: 1.618228]\n",
      "1180 [D loss: 0.184907, acc: 92.97%, op_acc: 71.09%] [G loss: 1.586368]\n",
      "Epoch: 1180, F1: 0.65060, F1P: 118\n",
      "[[28425     7]\n",
      " [   22    27]]\n",
      "92.734375\n",
      "1181 [D loss: 0.182151, acc: 94.53%, op_acc: 74.22%] [G loss: 1.681698]\n",
      "1182 [D loss: 0.183075, acc: 91.41%, op_acc: 67.97%] [G loss: 1.588149]\n",
      "1183 [D loss: 0.201662, acc: 89.84%, op_acc: 64.84%] [G loss: 1.546899]\n",
      "1184 [D loss: 0.182647, acc: 92.97%, op_acc: 74.22%] [G loss: 1.582886]\n",
      "1185 [D loss: 0.184185, acc: 95.31%, op_acc: 65.62%] [G loss: 1.588758]\n",
      "1186 [D loss: 0.176178, acc: 98.44%, op_acc: 67.97%] [G loss: 1.629652]\n",
      "1187 [D loss: 0.189348, acc: 94.53%, op_acc: 65.62%] [G loss: 1.628341]\n",
      "1188 [D loss: 0.194469, acc: 90.62%, op_acc: 70.31%] [G loss: 1.525760]\n",
      "1189 [D loss: 0.200173, acc: 89.84%, op_acc: 74.22%] [G loss: 1.617202]\n",
      "1190 [D loss: 0.199940, acc: 89.84%, op_acc: 67.97%] [G loss: 1.653184]\n",
      "Epoch: 1190, F1: 0.65060, F1P: 119\n",
      "[[28425     7]\n",
      " [   22    27]]\n",
      "92.734375\n",
      "1191 [D loss: 0.182037, acc: 94.53%, op_acc: 66.41%] [G loss: 1.679456]\n",
      "1192 [D loss: 0.205709, acc: 88.28%, op_acc: 67.97%] [G loss: 1.677344]\n",
      "1193 [D loss: 0.183976, acc: 92.19%, op_acc: 71.88%] [G loss: 1.692873]\n",
      "1194 [D loss: 0.197421, acc: 92.97%, op_acc: 70.31%] [G loss: 1.664953]\n",
      "1195 [D loss: 0.188987, acc: 93.75%, op_acc: 64.84%] [G loss: 1.653149]\n",
      "1196 [D loss: 0.187335, acc: 95.31%, op_acc: 72.66%] [G loss: 1.617230]\n",
      "1197 [D loss: 0.187559, acc: 95.31%, op_acc: 68.75%] [G loss: 1.641257]\n",
      "1198 [D loss: 0.181580, acc: 92.19%, op_acc: 75.00%] [G loss: 1.598502]\n",
      "1199 [D loss: 0.192458, acc: 91.41%, op_acc: 70.31%] [G loss: 1.655412]\n",
      "1200 [D loss: 0.202065, acc: 91.41%, op_acc: 72.66%] [G loss: 1.670776]\n",
      "Epoch: 1200, F1: 0.65060, F1P: 120\n",
      "[[28425     7]\n",
      " [   22    27]]\n",
      "92.734375\n",
      "1201 [D loss: 0.181720, acc: 96.09%, op_acc: 74.22%] [G loss: 1.727647]\n",
      "1202 [D loss: 0.198518, acc: 90.62%, op_acc: 71.09%] [G loss: 1.727685]\n",
      "1203 [D loss: 0.195781, acc: 93.75%, op_acc: 70.31%] [G loss: 1.671700]\n",
      "1204 [D loss: 0.173389, acc: 95.31%, op_acc: 79.69%] [G loss: 1.600467]\n",
      "1205 [D loss: 0.191117, acc: 93.75%, op_acc: 78.12%] [G loss: 1.655419]\n",
      "1206 [D loss: 0.188892, acc: 92.19%, op_acc: 67.97%] [G loss: 1.630738]\n",
      "1207 [D loss: 0.199047, acc: 90.62%, op_acc: 78.91%] [G loss: 1.663209]\n",
      "1208 [D loss: 0.169202, acc: 96.09%, op_acc: 76.56%] [G loss: 1.655747]\n",
      "1209 [D loss: 0.186280, acc: 95.31%, op_acc: 74.22%] [G loss: 1.665040]\n",
      "1210 [D loss: 0.179196, acc: 93.75%, op_acc: 75.00%] [G loss: 1.620502]\n",
      "Epoch: 1210, F1: 0.65060, F1P: 121\n",
      "[[28425     7]\n",
      " [   22    27]]\n",
      "93.75\n",
      "1211 [D loss: 0.197758, acc: 88.28%, op_acc: 75.00%] [G loss: 1.585896]\n",
      "1212 [D loss: 0.196408, acc: 92.19%, op_acc: 67.97%] [G loss: 1.666650]\n",
      "1213 [D loss: 0.188492, acc: 90.62%, op_acc: 70.31%] [G loss: 1.691570]\n",
      "1214 [D loss: 0.196410, acc: 90.62%, op_acc: 72.66%] [G loss: 1.646328]\n",
      "1215 [D loss: 0.177168, acc: 92.19%, op_acc: 73.44%] [G loss: 1.645596]\n",
      "1216 [D loss: 0.181201, acc: 97.66%, op_acc: 75.78%] [G loss: 1.654033]\n",
      "1217 [D loss: 0.190045, acc: 91.41%, op_acc: 75.78%] [G loss: 1.726887]\n",
      "1218 [D loss: 0.188189, acc: 93.75%, op_acc: 75.00%] [G loss: 1.678881]\n",
      "1219 [D loss: 0.182283, acc: 96.88%, op_acc: 81.25%] [G loss: 1.701155]\n",
      "1220 [D loss: 0.190854, acc: 92.97%, op_acc: 69.53%] [G loss: 1.614681]\n",
      "Epoch: 1220, F1: 0.65060, F1P: 122\n",
      "[[28425     7]\n",
      " [   22    27]]\n",
      "92.65625\n",
      "1221 [D loss: 0.205688, acc: 90.62%, op_acc: 69.53%] [G loss: 1.566881]\n",
      "1222 [D loss: 0.183325, acc: 95.31%, op_acc: 71.88%] [G loss: 1.623115]\n",
      "1223 [D loss: 0.192273, acc: 93.75%, op_acc: 74.22%] [G loss: 1.542037]\n",
      "1224 [D loss: 0.192623, acc: 90.62%, op_acc: 67.97%] [G loss: 1.638765]\n",
      "1225 [D loss: 0.193201, acc: 91.41%, op_acc: 71.88%] [G loss: 1.775957]\n",
      "1226 [D loss: 0.186162, acc: 95.31%, op_acc: 74.22%] [G loss: 1.621021]\n",
      "1227 [D loss: 0.184594, acc: 96.09%, op_acc: 71.88%] [G loss: 1.615820]\n",
      "1228 [D loss: 0.176405, acc: 92.19%, op_acc: 76.56%] [G loss: 1.676452]\n",
      "1229 [D loss: 0.184389, acc: 96.09%, op_acc: 70.31%] [G loss: 1.582022]\n",
      "1230 [D loss: 0.191295, acc: 96.09%, op_acc: 75.78%] [G loss: 1.653664]\n",
      "Epoch: 1230, F1: 0.65060, F1P: 123\n",
      "[[28425     7]\n",
      " [   22    27]]\n",
      "93.75\n",
      "1231 [D loss: 0.197138, acc: 90.62%, op_acc: 71.09%] [G loss: 1.722289]\n",
      "1232 [D loss: 0.196994, acc: 88.28%, op_acc: 74.22%] [G loss: 1.626317]\n",
      "1233 [D loss: 0.183507, acc: 90.62%, op_acc: 75.00%] [G loss: 1.583453]\n",
      "1234 [D loss: 0.176763, acc: 95.31%, op_acc: 69.53%] [G loss: 1.652443]\n",
      "1235 [D loss: 0.192715, acc: 91.41%, op_acc: 73.44%] [G loss: 1.590261]\n",
      "1236 [D loss: 0.186771, acc: 94.53%, op_acc: 71.09%] [G loss: 1.664070]\n",
      "1237 [D loss: 0.174703, acc: 95.31%, op_acc: 76.56%] [G loss: 1.616044]\n",
      "1238 [D loss: 0.184674, acc: 93.75%, op_acc: 74.22%] [G loss: 1.624186]\n",
      "1239 [D loss: 0.187860, acc: 95.31%, op_acc: 73.44%] [G loss: 1.638266]\n",
      "1240 [D loss: 0.198122, acc: 89.06%, op_acc: 75.00%] [G loss: 1.697304]\n",
      "Epoch: 1240, F1: 0.65060, F1P: 124\n",
      "[[28425     7]\n",
      " [   22    27]]\n",
      "92.421875\n",
      "1241 [D loss: 0.192763, acc: 89.06%, op_acc: 74.22%] [G loss: 1.653726]\n",
      "1242 [D loss: 0.178123, acc: 96.88%, op_acc: 73.44%] [G loss: 1.668526]\n",
      "1243 [D loss: 0.191536, acc: 91.41%, op_acc: 75.78%] [G loss: 1.654703]\n",
      "1244 [D loss: 0.203861, acc: 90.62%, op_acc: 71.09%] [G loss: 1.683512]\n",
      "1245 [D loss: 0.182102, acc: 96.09%, op_acc: 81.25%] [G loss: 1.668674]\n",
      "1246 [D loss: 0.181701, acc: 95.31%, op_acc: 74.22%] [G loss: 1.677863]\n",
      "1247 [D loss: 0.185722, acc: 94.53%, op_acc: 72.66%] [G loss: 1.660642]\n",
      "1248 [D loss: 0.189271, acc: 92.97%, op_acc: 71.88%] [G loss: 1.618789]\n",
      "1249 [D loss: 0.198640, acc: 87.50%, op_acc: 73.44%] [G loss: 1.567327]\n",
      "1250 [D loss: 0.187069, acc: 91.41%, op_acc: 71.88%] [G loss: 1.689659]\n",
      "Epoch: 1250, F1: 0.65060, F1P: 125\n",
      "[[28425     7]\n",
      " [   22    27]]\n",
      "92.578125\n",
      "1251 [D loss: 0.195810, acc: 88.28%, op_acc: 74.22%] [G loss: 1.714872]\n",
      "1252 [D loss: 0.181198, acc: 92.19%, op_acc: 75.00%] [G loss: 1.626322]\n",
      "1253 [D loss: 0.194454, acc: 94.53%, op_acc: 74.22%] [G loss: 1.685044]\n",
      "1254 [D loss: 0.197749, acc: 92.97%, op_acc: 73.44%] [G loss: 1.598542]\n",
      "1255 [D loss: 0.188643, acc: 92.97%, op_acc: 76.56%] [G loss: 1.663086]\n",
      "1256 [D loss: 0.181376, acc: 96.88%, op_acc: 82.81%] [G loss: 1.574180]\n",
      "1257 [D loss: 0.179440, acc: 92.97%, op_acc: 77.34%] [G loss: 1.670726]\n",
      "1258 [D loss: 0.186254, acc: 89.06%, op_acc: 80.47%] [G loss: 1.700785]\n",
      "1259 [D loss: 0.195474, acc: 91.41%, op_acc: 72.66%] [G loss: 1.560102]\n",
      "1260 [D loss: 0.188069, acc: 91.41%, op_acc: 73.44%] [G loss: 1.637435]\n",
      "Epoch: 1260, F1: 0.60000, F1P: 126\n",
      "[[28425     7]\n",
      " [   25    24]]\n",
      "92.265625\n",
      "1261 [D loss: 0.183697, acc: 91.41%, op_acc: 75.00%] [G loss: 1.610430]\n",
      "1262 [D loss: 0.196766, acc: 92.19%, op_acc: 74.22%] [G loss: 1.686074]\n",
      "1263 [D loss: 0.188081, acc: 94.53%, op_acc: 66.41%] [G loss: 1.658326]\n",
      "1264 [D loss: 0.168576, acc: 96.09%, op_acc: 82.03%] [G loss: 1.685428]\n",
      "1265 [D loss: 0.168528, acc: 97.66%, op_acc: 75.00%] [G loss: 1.596703]\n",
      "1266 [D loss: 0.188789, acc: 95.31%, op_acc: 71.88%] [G loss: 1.779732]\n",
      "1267 [D loss: 0.178082, acc: 94.53%, op_acc: 74.22%] [G loss: 1.652158]\n",
      "1268 [D loss: 0.163615, acc: 97.66%, op_acc: 81.25%] [G loss: 1.665546]\n",
      "1269 [D loss: 0.171724, acc: 94.53%, op_acc: 83.59%] [G loss: 1.688284]\n",
      "1270 [D loss: 0.187218, acc: 93.75%, op_acc: 76.56%] [G loss: 1.588592]\n",
      "Epoch: 1270, F1: 0.63415, F1P: 127\n",
      "[[28425     7]\n",
      " [   23    26]]\n",
      "94.765625\n",
      "1271 [D loss: 0.201417, acc: 90.62%, op_acc: 69.53%] [G loss: 1.639314]\n",
      "1272 [D loss: 0.192815, acc: 92.97%, op_acc: 82.03%] [G loss: 1.740271]\n",
      "1273 [D loss: 0.186211, acc: 95.31%, op_acc: 79.69%] [G loss: 1.676162]\n",
      "1274 [D loss: 0.174153, acc: 96.09%, op_acc: 75.78%] [G loss: 1.681365]\n",
      "1275 [D loss: 0.183742, acc: 95.31%, op_acc: 74.22%] [G loss: 1.660365]\n",
      "1276 [D loss: 0.188483, acc: 92.19%, op_acc: 75.78%] [G loss: 1.638474]\n",
      "1277 [D loss: 0.189471, acc: 90.62%, op_acc: 79.69%] [G loss: 1.769720]\n",
      "1278 [D loss: 0.170327, acc: 95.31%, op_acc: 74.22%] [G loss: 1.683371]\n",
      "1279 [D loss: 0.183304, acc: 96.09%, op_acc: 78.12%] [G loss: 1.657718]\n",
      "1280 [D loss: 0.184553, acc: 92.97%, op_acc: 77.34%] [G loss: 1.703213]\n",
      "Epoch: 1280, F1: 0.61728, F1P: 128\n",
      "[[28425     7]\n",
      " [   24    25]]\n",
      "93.75\n",
      "1281 [D loss: 0.179888, acc: 94.53%, op_acc: 74.22%] [G loss: 1.644325]\n",
      "1282 [D loss: 0.186903, acc: 91.41%, op_acc: 76.56%] [G loss: 1.631308]\n",
      "1283 [D loss: 0.176233, acc: 92.19%, op_acc: 81.25%] [G loss: 1.639164]\n",
      "1284 [D loss: 0.179329, acc: 92.97%, op_acc: 78.12%] [G loss: 1.685823]\n",
      "1285 [D loss: 0.172582, acc: 94.53%, op_acc: 75.00%] [G loss: 1.661071]\n",
      "1286 [D loss: 0.168006, acc: 95.31%, op_acc: 81.25%] [G loss: 1.664986]\n",
      "1287 [D loss: 0.199488, acc: 93.75%, op_acc: 75.78%] [G loss: 1.601099]\n",
      "1288 [D loss: 0.184309, acc: 93.75%, op_acc: 78.12%] [G loss: 1.583348]\n",
      "1289 [D loss: 0.174608, acc: 93.75%, op_acc: 78.12%] [G loss: 1.635134]\n",
      "1290 [D loss: 0.191056, acc: 93.75%, op_acc: 73.44%] [G loss: 1.745172]\n",
      "Epoch: 1290, F1: 0.60000, F1P: 129\n",
      "[[28425     7]\n",
      " [   25    24]]\n",
      "93.59375\n",
      "1291 [D loss: 0.173142, acc: 96.88%, op_acc: 78.91%] [G loss: 1.637268]\n",
      "1292 [D loss: 0.190034, acc: 92.19%, op_acc: 78.12%] [G loss: 1.660020]\n",
      "1293 [D loss: 0.180988, acc: 92.19%, op_acc: 77.34%] [G loss: 1.652307]\n",
      "1294 [D loss: 0.169844, acc: 95.31%, op_acc: 80.47%] [G loss: 1.712842]\n",
      "1295 [D loss: 0.193228, acc: 88.28%, op_acc: 74.22%] [G loss: 1.706573]\n",
      "1296 [D loss: 0.191507, acc: 92.19%, op_acc: 81.25%] [G loss: 1.756993]\n",
      "1297 [D loss: 0.180932, acc: 92.19%, op_acc: 79.69%] [G loss: 1.677567]\n",
      "1298 [D loss: 0.183449, acc: 96.09%, op_acc: 75.78%] [G loss: 1.628787]\n",
      "1299 [D loss: 0.179955, acc: 96.09%, op_acc: 79.69%] [G loss: 1.624906]\n",
      "1300 [D loss: 0.193995, acc: 89.84%, op_acc: 75.78%] [G loss: 1.681832]\n",
      "Epoch: 1300, F1: 0.60000, F1P: 130\n",
      "[[28425     7]\n",
      " [   25    24]]\n",
      "93.125\n",
      "1301 [D loss: 0.174699, acc: 95.31%, op_acc: 79.69%] [G loss: 1.664499]\n",
      "1302 [D loss: 0.177906, acc: 94.53%, op_acc: 76.56%] [G loss: 1.733610]\n",
      "1303 [D loss: 0.180044, acc: 93.75%, op_acc: 79.69%] [G loss: 1.709856]\n",
      "1304 [D loss: 0.185132, acc: 93.75%, op_acc: 76.56%] [G loss: 1.679228]\n",
      "1305 [D loss: 0.186479, acc: 92.19%, op_acc: 85.16%] [G loss: 1.658962]\n",
      "1306 [D loss: 0.199571, acc: 89.84%, op_acc: 77.34%] [G loss: 1.733879]\n",
      "1307 [D loss: 0.189474, acc: 92.19%, op_acc: 75.78%] [G loss: 1.836392]\n",
      "1308 [D loss: 0.177962, acc: 93.75%, op_acc: 78.91%] [G loss: 1.661428]\n",
      "1309 [D loss: 0.200219, acc: 89.84%, op_acc: 71.09%] [G loss: 1.691304]\n",
      "1310 [D loss: 0.165518, acc: 97.66%, op_acc: 80.47%] [G loss: 1.599237]\n",
      "Epoch: 1310, F1: 0.60000, F1P: 131\n",
      "[[28425     7]\n",
      " [   25    24]]\n",
      "93.28125\n",
      "1311 [D loss: 0.173338, acc: 96.88%, op_acc: 80.47%] [G loss: 1.715691]\n",
      "1312 [D loss: 0.181046, acc: 95.31%, op_acc: 79.69%] [G loss: 1.894212]\n",
      "1313 [D loss: 0.168851, acc: 92.97%, op_acc: 78.12%] [G loss: 1.696099]\n",
      "1314 [D loss: 0.171707, acc: 96.88%, op_acc: 81.25%] [G loss: 1.794178]\n",
      "1315 [D loss: 0.185736, acc: 90.62%, op_acc: 79.69%] [G loss: 1.662359]\n",
      "1316 [D loss: 0.179015, acc: 90.62%, op_acc: 77.34%] [G loss: 1.817084]\n",
      "1317 [D loss: 0.169585, acc: 93.75%, op_acc: 78.12%] [G loss: 1.825073]\n",
      "1318 [D loss: 0.173511, acc: 92.97%, op_acc: 81.25%] [G loss: 1.653027]\n",
      "1319 [D loss: 0.174585, acc: 93.75%, op_acc: 80.47%] [G loss: 1.677017]\n",
      "1320 [D loss: 0.183867, acc: 89.84%, op_acc: 78.91%] [G loss: 1.736989]\n",
      "Epoch: 1320, F1: 0.60000, F1P: 132\n",
      "[[28425     7]\n",
      " [   25    24]]\n",
      "93.359375\n",
      "1321 [D loss: 0.188621, acc: 89.84%, op_acc: 75.78%] [G loss: 1.676361]\n",
      "1322 [D loss: 0.181012, acc: 92.97%, op_acc: 79.69%] [G loss: 1.774768]\n",
      "1323 [D loss: 0.185601, acc: 94.53%, op_acc: 78.12%] [G loss: 1.693423]\n",
      "1324 [D loss: 0.189775, acc: 92.97%, op_acc: 79.69%] [G loss: 1.652456]\n",
      "1325 [D loss: 0.177124, acc: 93.75%, op_acc: 80.47%] [G loss: 1.592094]\n",
      "1326 [D loss: 0.179637, acc: 92.97%, op_acc: 81.25%] [G loss: 1.722025]\n",
      "1327 [D loss: 0.184701, acc: 92.97%, op_acc: 77.34%] [G loss: 1.795928]\n",
      "1328 [D loss: 0.163918, acc: 95.31%, op_acc: 82.03%] [G loss: 1.754330]\n",
      "1329 [D loss: 0.179288, acc: 96.88%, op_acc: 79.69%] [G loss: 1.660758]\n",
      "1330 [D loss: 0.165500, acc: 96.88%, op_acc: 82.81%] [G loss: 1.780871]\n",
      "Epoch: 1330, F1: 0.60000, F1P: 133\n",
      "[[28425     7]\n",
      " [   25    24]]\n",
      "93.90625\n",
      "1331 [D loss: 0.151513, acc: 96.09%, op_acc: 85.16%] [G loss: 1.775829]\n",
      "1332 [D loss: 0.193100, acc: 96.88%, op_acc: 71.09%] [G loss: 1.662793]\n",
      "1333 [D loss: 0.170357, acc: 96.88%, op_acc: 77.34%] [G loss: 1.729312]\n",
      "1334 [D loss: 0.174550, acc: 94.53%, op_acc: 83.59%] [G loss: 1.761592]\n",
      "1335 [D loss: 0.187502, acc: 90.62%, op_acc: 77.34%] [G loss: 1.889653]\n",
      "1336 [D loss: 0.177966, acc: 92.19%, op_acc: 78.91%] [G loss: 1.817056]\n",
      "1337 [D loss: 0.171651, acc: 92.97%, op_acc: 81.25%] [G loss: 1.797994]\n",
      "1338 [D loss: 0.175455, acc: 96.88%, op_acc: 80.47%] [G loss: 1.764370]\n",
      "1339 [D loss: 0.171812, acc: 96.88%, op_acc: 82.03%] [G loss: 1.851052]\n",
      "1340 [D loss: 0.173204, acc: 94.53%, op_acc: 80.47%] [G loss: 1.885672]\n",
      "Epoch: 1340, F1: 0.58228, F1P: 134\n",
      "[[28425     7]\n",
      " [   26    23]]\n",
      "94.84375\n",
      "1341 [D loss: 0.192723, acc: 92.19%, op_acc: 73.44%] [G loss: 1.708715]\n",
      "1342 [D loss: 0.171421, acc: 96.09%, op_acc: 80.47%] [G loss: 1.685861]\n",
      "1343 [D loss: 0.191023, acc: 90.62%, op_acc: 76.56%] [G loss: 1.685952]\n",
      "1344 [D loss: 0.192216, acc: 92.19%, op_acc: 76.56%] [G loss: 1.747192]\n",
      "1345 [D loss: 0.177279, acc: 95.31%, op_acc: 82.81%] [G loss: 1.755158]\n",
      "1346 [D loss: 0.163332, acc: 95.31%, op_acc: 85.94%] [G loss: 1.801172]\n",
      "1347 [D loss: 0.180499, acc: 93.75%, op_acc: 78.91%] [G loss: 1.778476]\n",
      "1348 [D loss: 0.175694, acc: 93.75%, op_acc: 75.00%] [G loss: 1.875741]\n",
      "1349 [D loss: 0.176967, acc: 94.53%, op_acc: 82.81%] [G loss: 1.699819]\n",
      "1350 [D loss: 0.170168, acc: 96.09%, op_acc: 81.25%] [G loss: 1.770910]\n",
      "Epoch: 1350, F1: 0.60000, F1P: 135\n",
      "[[28425     7]\n",
      " [   25    24]]\n",
      "93.984375\n",
      "1351 [D loss: 0.167166, acc: 97.66%, op_acc: 84.38%] [G loss: 1.736120]\n",
      "1352 [D loss: 0.163940, acc: 96.09%, op_acc: 87.50%] [G loss: 1.835206]\n",
      "1353 [D loss: 0.167718, acc: 97.66%, op_acc: 85.94%] [G loss: 1.693424]\n",
      "1354 [D loss: 0.168123, acc: 92.97%, op_acc: 82.81%] [G loss: 1.868619]\n",
      "1355 [D loss: 0.173324, acc: 96.09%, op_acc: 85.94%] [G loss: 1.883690]\n",
      "1356 [D loss: 0.168526, acc: 94.53%, op_acc: 78.91%] [G loss: 1.791734]\n",
      "1357 [D loss: 0.172868, acc: 96.09%, op_acc: 74.22%] [G loss: 1.735151]\n",
      "1358 [D loss: 0.183243, acc: 91.41%, op_acc: 75.78%] [G loss: 1.761655]\n",
      "1359 [D loss: 0.168445, acc: 93.75%, op_acc: 78.91%] [G loss: 1.725129]\n",
      "1360 [D loss: 0.169902, acc: 94.53%, op_acc: 86.72%] [G loss: 1.815030]\n",
      "Epoch: 1360, F1: 0.60000, F1P: 136\n",
      "[[28425     7]\n",
      " [   25    24]]\n",
      "95.078125\n",
      "1361 [D loss: 0.173842, acc: 92.19%, op_acc: 78.12%] [G loss: 1.829682]\n",
      "1362 [D loss: 0.176187, acc: 93.75%, op_acc: 81.25%] [G loss: 1.758332]\n",
      "1363 [D loss: 0.168827, acc: 94.53%, op_acc: 88.28%] [G loss: 1.848718]\n",
      "1364 [D loss: 0.177230, acc: 92.19%, op_acc: 82.03%] [G loss: 1.724598]\n",
      "1365 [D loss: 0.170700, acc: 94.53%, op_acc: 79.69%] [G loss: 1.944445]\n",
      "1366 [D loss: 0.163351, acc: 96.09%, op_acc: 85.16%] [G loss: 1.786259]\n",
      "1367 [D loss: 0.179254, acc: 94.53%, op_acc: 78.91%] [G loss: 1.825197]\n",
      "1368 [D loss: 0.161996, acc: 96.09%, op_acc: 82.81%] [G loss: 1.907198]\n",
      "1369 [D loss: 0.180751, acc: 92.19%, op_acc: 82.03%] [G loss: 1.758552]\n",
      "1370 [D loss: 0.178179, acc: 92.19%, op_acc: 84.38%] [G loss: 1.727350]\n",
      "Epoch: 1370, F1: 0.60000, F1P: 137\n",
      "[[28425     7]\n",
      " [   25    24]]\n",
      "93.828125\n",
      "1371 [D loss: 0.178737, acc: 92.19%, op_acc: 85.16%] [G loss: 1.751226]\n",
      "1372 [D loss: 0.163454, acc: 96.09%, op_acc: 82.03%] [G loss: 1.832301]\n",
      "1373 [D loss: 0.168698, acc: 95.31%, op_acc: 82.81%] [G loss: 1.745448]\n",
      "1374 [D loss: 0.174251, acc: 96.88%, op_acc: 82.81%] [G loss: 1.798909]\n",
      "1375 [D loss: 0.168145, acc: 97.66%, op_acc: 82.81%] [G loss: 1.792151]\n",
      "1376 [D loss: 0.178022, acc: 90.62%, op_acc: 80.47%] [G loss: 1.786597]\n",
      "1377 [D loss: 0.164296, acc: 92.97%, op_acc: 87.50%] [G loss: 1.878789]\n",
      "1378 [D loss: 0.169670, acc: 98.44%, op_acc: 80.47%] [G loss: 1.825992]\n",
      "1379 [D loss: 0.163926, acc: 95.31%, op_acc: 84.38%] [G loss: 1.757658]\n",
      "1380 [D loss: 0.160286, acc: 96.88%, op_acc: 80.47%] [G loss: 1.882587]\n",
      "Epoch: 1380, F1: 0.61728, F1P: 138\n",
      "[[28425     7]\n",
      " [   24    25]]\n",
      "95.234375\n",
      "1381 [D loss: 0.159382, acc: 95.31%, op_acc: 85.16%] [G loss: 1.831235]\n",
      "1382 [D loss: 0.177067, acc: 92.19%, op_acc: 73.44%] [G loss: 1.825089]\n",
      "1383 [D loss: 0.175550, acc: 92.97%, op_acc: 81.25%] [G loss: 1.722928]\n",
      "1384 [D loss: 0.168526, acc: 95.31%, op_acc: 85.16%] [G loss: 1.888252]\n",
      "1385 [D loss: 0.180400, acc: 92.19%, op_acc: 78.12%] [G loss: 1.941910]\n",
      "1386 [D loss: 0.173632, acc: 94.53%, op_acc: 82.81%] [G loss: 1.911936]\n",
      "1387 [D loss: 0.183796, acc: 92.97%, op_acc: 73.44%] [G loss: 1.878370]\n",
      "1388 [D loss: 0.187782, acc: 92.97%, op_acc: 79.69%] [G loss: 1.715656]\n",
      "1389 [D loss: 0.176224, acc: 93.75%, op_acc: 86.72%] [G loss: 1.783302]\n",
      "1390 [D loss: 0.169235, acc: 96.09%, op_acc: 80.47%] [G loss: 1.760219]\n",
      "Epoch: 1390, F1: 0.60000, F1P: 139\n",
      "[[28425     7]\n",
      " [   25    24]]\n",
      "93.828125\n",
      "1391 [D loss: 0.175197, acc: 94.53%, op_acc: 80.47%] [G loss: 1.909043]\n",
      "1392 [D loss: 0.166755, acc: 96.09%, op_acc: 81.25%] [G loss: 1.847667]\n",
      "1393 [D loss: 0.192015, acc: 92.97%, op_acc: 85.94%] [G loss: 1.860321]\n",
      "1394 [D loss: 0.177738, acc: 94.53%, op_acc: 79.69%] [G loss: 1.706982]\n",
      "1395 [D loss: 0.177514, acc: 93.75%, op_acc: 82.03%] [G loss: 1.797395]\n",
      "1396 [D loss: 0.167975, acc: 96.09%, op_acc: 82.03%] [G loss: 1.915045]\n",
      "1397 [D loss: 0.175184, acc: 92.97%, op_acc: 78.12%] [G loss: 1.790804]\n",
      "1398 [D loss: 0.171783, acc: 94.53%, op_acc: 76.56%] [G loss: 1.646536]\n",
      "1399 [D loss: 0.167624, acc: 95.31%, op_acc: 83.59%] [G loss: 1.813639]\n",
      "1400 [D loss: 0.170345, acc: 94.53%, op_acc: 84.38%] [G loss: 1.783339]\n",
      "Epoch: 1400, F1: 0.60000, F1P: 140\n",
      "[[28425     7]\n",
      " [   25    24]]\n",
      "94.53125\n",
      "1401 [D loss: 0.184510, acc: 93.75%, op_acc: 73.44%] [G loss: 1.910651]\n",
      "1402 [D loss: 0.184461, acc: 92.19%, op_acc: 72.66%] [G loss: 1.736586]\n",
      "1403 [D loss: 0.173125, acc: 92.97%, op_acc: 84.38%] [G loss: 1.857627]\n",
      "1404 [D loss: 0.182423, acc: 95.31%, op_acc: 80.47%] [G loss: 1.729414]\n",
      "1405 [D loss: 0.168638, acc: 93.75%, op_acc: 83.59%] [G loss: 1.821247]\n",
      "1406 [D loss: 0.169485, acc: 93.75%, op_acc: 84.38%] [G loss: 1.803554]\n",
      "1407 [D loss: 0.179076, acc: 92.19%, op_acc: 82.81%] [G loss: 1.854420]\n",
      "1408 [D loss: 0.179723, acc: 93.75%, op_acc: 82.81%] [G loss: 1.685183]\n",
      "1409 [D loss: 0.171686, acc: 95.31%, op_acc: 85.94%] [G loss: 1.724530]\n",
      "1410 [D loss: 0.173331, acc: 96.09%, op_acc: 82.81%] [G loss: 1.764961]\n",
      "Epoch: 1410, F1: 0.60000, F1P: 141\n",
      "[[28425     7]\n",
      " [   25    24]]\n",
      "93.90625\n",
      "1411 [D loss: 0.163556, acc: 93.75%, op_acc: 83.59%] [G loss: 1.869099]\n",
      "1412 [D loss: 0.164739, acc: 94.53%, op_acc: 82.03%] [G loss: 1.766305]\n",
      "1413 [D loss: 0.193271, acc: 89.84%, op_acc: 76.56%] [G loss: 1.752475]\n",
      "1414 [D loss: 0.176109, acc: 95.31%, op_acc: 79.69%] [G loss: 1.758594]\n",
      "1415 [D loss: 0.175766, acc: 92.97%, op_acc: 73.44%] [G loss: 1.850366]\n",
      "1416 [D loss: 0.182336, acc: 94.53%, op_acc: 79.69%] [G loss: 1.782917]\n",
      "1417 [D loss: 0.168334, acc: 96.09%, op_acc: 83.59%] [G loss: 1.812541]\n",
      "1418 [D loss: 0.168381, acc: 96.09%, op_acc: 77.34%] [G loss: 1.811164]\n",
      "1419 [D loss: 0.172776, acc: 94.53%, op_acc: 78.91%] [G loss: 1.773307]\n",
      "1420 [D loss: 0.167741, acc: 96.09%, op_acc: 78.91%] [G loss: 1.752355]\n",
      "Epoch: 1420, F1: 0.60000, F1P: 142\n",
      "[[28425     7]\n",
      " [   25    24]]\n",
      "94.375\n",
      "1421 [D loss: 0.177018, acc: 92.97%, op_acc: 81.25%] [G loss: 1.731380]\n",
      "1422 [D loss: 0.194031, acc: 91.41%, op_acc: 79.69%] [G loss: 1.690886]\n",
      "1423 [D loss: 0.183825, acc: 92.97%, op_acc: 78.91%] [G loss: 1.694720]\n",
      "1424 [D loss: 0.162801, acc: 97.66%, op_acc: 84.38%] [G loss: 1.746355]\n",
      "1425 [D loss: 0.196939, acc: 87.50%, op_acc: 73.44%] [G loss: 1.698208]\n",
      "1426 [D loss: 0.169933, acc: 93.75%, op_acc: 77.34%] [G loss: 1.780039]\n",
      "1427 [D loss: 0.171568, acc: 95.31%, op_acc: 82.03%] [G loss: 1.739020]\n",
      "1428 [D loss: 0.161827, acc: 96.88%, op_acc: 85.16%] [G loss: 1.701880]\n",
      "1429 [D loss: 0.173241, acc: 96.09%, op_acc: 85.16%] [G loss: 1.735062]\n",
      "1430 [D loss: 0.190850, acc: 93.75%, op_acc: 76.56%] [G loss: 1.885480]\n",
      "Epoch: 1430, F1: 0.60000, F1P: 143\n",
      "[[28425     7]\n",
      " [   25    24]]\n",
      "93.828125\n",
      "1431 [D loss: 0.178640, acc: 96.09%, op_acc: 80.47%] [G loss: 1.842423]\n",
      "1432 [D loss: 0.191012, acc: 89.84%, op_acc: 78.91%] [G loss: 1.725936]\n",
      "1433 [D loss: 0.168614, acc: 96.88%, op_acc: 78.91%] [G loss: 1.745235]\n",
      "1434 [D loss: 0.187062, acc: 88.28%, op_acc: 76.56%] [G loss: 1.732728]\n",
      "1435 [D loss: 0.171869, acc: 95.31%, op_acc: 78.91%] [G loss: 1.858418]\n",
      "1436 [D loss: 0.178268, acc: 91.41%, op_acc: 84.38%] [G loss: 1.640609]\n",
      "1437 [D loss: 0.182519, acc: 92.97%, op_acc: 78.91%] [G loss: 1.730865]\n",
      "1438 [D loss: 0.165035, acc: 95.31%, op_acc: 80.47%] [G loss: 1.679540]\n",
      "1439 [D loss: 0.163991, acc: 95.31%, op_acc: 83.59%] [G loss: 1.602691]\n",
      "1440 [D loss: 0.167778, acc: 96.88%, op_acc: 80.47%] [G loss: 1.671242]\n",
      "Epoch: 1440, F1: 0.61728, F1P: 144\n",
      "[[28425     7]\n",
      " [   24    25]]\n",
      "93.828125\n",
      "1441 [D loss: 0.169479, acc: 96.09%, op_acc: 84.38%] [G loss: 1.764233]\n",
      "1442 [D loss: 0.187181, acc: 91.41%, op_acc: 78.12%] [G loss: 1.676420]\n",
      "1443 [D loss: 0.171834, acc: 94.53%, op_acc: 79.69%] [G loss: 1.692812]\n",
      "1444 [D loss: 0.177608, acc: 94.53%, op_acc: 80.47%] [G loss: 1.612717]\n",
      "1445 [D loss: 0.176185, acc: 93.75%, op_acc: 78.91%] [G loss: 1.735567]\n",
      "1446 [D loss: 0.171876, acc: 95.31%, op_acc: 75.00%] [G loss: 1.863121]\n",
      "1447 [D loss: 0.173652, acc: 95.31%, op_acc: 85.16%] [G loss: 1.818580]\n",
      "1448 [D loss: 0.187295, acc: 91.41%, op_acc: 79.69%] [G loss: 1.826287]\n",
      "1449 [D loss: 0.163762, acc: 97.66%, op_acc: 79.69%] [G loss: 1.773179]\n",
      "1450 [D loss: 0.180877, acc: 93.75%, op_acc: 83.59%] [G loss: 1.721802]\n",
      "Epoch: 1450, F1: 0.60000, F1P: 145\n",
      "[[28425     7]\n",
      " [   25    24]]\n",
      "94.375\n",
      "1451 [D loss: 0.164021, acc: 92.97%, op_acc: 82.03%] [G loss: 1.691098]\n",
      "1452 [D loss: 0.164168, acc: 96.88%, op_acc: 78.12%] [G loss: 1.616082]\n",
      "1453 [D loss: 0.180145, acc: 92.19%, op_acc: 76.56%] [G loss: 1.665114]\n",
      "1454 [D loss: 0.178879, acc: 93.75%, op_acc: 82.81%] [G loss: 1.782972]\n",
      "1455 [D loss: 0.181611, acc: 92.97%, op_acc: 80.47%] [G loss: 1.805552]\n",
      "1456 [D loss: 0.162814, acc: 97.66%, op_acc: 81.25%] [G loss: 1.763671]\n",
      "1457 [D loss: 0.174758, acc: 96.88%, op_acc: 75.00%] [G loss: 1.703740]\n",
      "1458 [D loss: 0.182527, acc: 92.97%, op_acc: 75.78%] [G loss: 1.820001]\n",
      "1459 [D loss: 0.177659, acc: 96.09%, op_acc: 75.78%] [G loss: 1.733110]\n",
      "1460 [D loss: 0.176368, acc: 94.53%, op_acc: 81.25%] [G loss: 1.787956]\n",
      "Epoch: 1460, F1: 0.59259, F1P: 146\n",
      "[[28424     8]\n",
      " [   25    24]]\n",
      "94.6875\n",
      "1461 [D loss: 0.186942, acc: 91.41%, op_acc: 76.56%] [G loss: 1.709605]\n",
      "1462 [D loss: 0.165802, acc: 96.88%, op_acc: 82.81%] [G loss: 1.758824]\n",
      "1463 [D loss: 0.169165, acc: 97.66%, op_acc: 76.56%] [G loss: 1.768302]\n",
      "1464 [D loss: 0.167851, acc: 95.31%, op_acc: 84.38%] [G loss: 1.859879]\n",
      "1465 [D loss: 0.172369, acc: 93.75%, op_acc: 78.12%] [G loss: 1.769392]\n",
      "1466 [D loss: 0.167158, acc: 96.09%, op_acc: 84.38%] [G loss: 1.651242]\n",
      "1467 [D loss: 0.168656, acc: 96.09%, op_acc: 78.91%] [G loss: 1.779034]\n",
      "1468 [D loss: 0.182363, acc: 94.53%, op_acc: 79.69%] [G loss: 1.624686]\n",
      "1469 [D loss: 0.172954, acc: 96.88%, op_acc: 80.47%] [G loss: 1.781847]\n",
      "1470 [D loss: 0.169666, acc: 96.88%, op_acc: 81.25%] [G loss: 1.832458]\n",
      "Epoch: 1470, F1: 0.60976, F1P: 147\n",
      "[[28424     8]\n",
      " [   24    25]]\n",
      "95.546875\n",
      "1471 [D loss: 0.172804, acc: 94.53%, op_acc: 76.56%] [G loss: 1.863388]\n",
      "1472 [D loss: 0.179700, acc: 91.41%, op_acc: 75.78%] [G loss: 1.734449]\n",
      "1473 [D loss: 0.181968, acc: 89.84%, op_acc: 77.34%] [G loss: 1.800581]\n",
      "1474 [D loss: 0.166517, acc: 95.31%, op_acc: 78.91%] [G loss: 1.700001]\n",
      "1475 [D loss: 0.176105, acc: 93.75%, op_acc: 78.91%] [G loss: 1.837641]\n",
      "1476 [D loss: 0.160244, acc: 96.09%, op_acc: 86.72%] [G loss: 1.879560]\n",
      "1477 [D loss: 0.169496, acc: 96.09%, op_acc: 78.12%] [G loss: 1.674989]\n",
      "1478 [D loss: 0.163645, acc: 96.88%, op_acc: 82.81%] [G loss: 1.704101]\n",
      "1479 [D loss: 0.181572, acc: 92.97%, op_acc: 75.00%] [G loss: 1.743984]\n",
      "1480 [D loss: 0.176742, acc: 95.31%, op_acc: 82.03%] [G loss: 1.748205]\n",
      "Epoch: 1480, F1: 0.64286, F1P: 148\n",
      "[[28424     8]\n",
      " [   22    27]]\n",
      "94.21875\n",
      "1481 [D loss: 0.178323, acc: 95.31%, op_acc: 78.12%] [G loss: 1.806411]\n",
      "1482 [D loss: 0.162857, acc: 97.66%, op_acc: 79.69%] [G loss: 1.871190]\n",
      "1483 [D loss: 0.182819, acc: 92.97%, op_acc: 77.34%] [G loss: 1.789225]\n",
      "1484 [D loss: 0.186942, acc: 92.97%, op_acc: 77.34%] [G loss: 1.776896]\n",
      "1485 [D loss: 0.185993, acc: 92.97%, op_acc: 76.56%] [G loss: 1.724548]\n",
      "1486 [D loss: 0.168559, acc: 93.75%, op_acc: 76.56%] [G loss: 1.879731]\n",
      "1487 [D loss: 0.180210, acc: 96.09%, op_acc: 78.91%] [G loss: 1.802386]\n",
      "1488 [D loss: 0.161114, acc: 96.09%, op_acc: 84.38%] [G loss: 1.811608]\n",
      "1489 [D loss: 0.164616, acc: 94.53%, op_acc: 83.59%] [G loss: 1.869279]\n",
      "1490 [D loss: 0.189988, acc: 94.53%, op_acc: 78.12%] [G loss: 1.906951]\n",
      "Epoch: 1490, F1: 0.64286, F1P: 149\n",
      "[[28424     8]\n",
      " [   22    27]]\n",
      "94.6875\n",
      "1491 [D loss: 0.171688, acc: 96.09%, op_acc: 82.03%] [G loss: 1.770420]\n",
      "1492 [D loss: 0.170187, acc: 95.31%, op_acc: 80.47%] [G loss: 1.771211]\n",
      "1493 [D loss: 0.176472, acc: 92.97%, op_acc: 78.91%] [G loss: 1.739064]\n",
      "1494 [D loss: 0.176508, acc: 96.09%, op_acc: 76.56%] [G loss: 1.771538]\n",
      "1495 [D loss: 0.171937, acc: 94.53%, op_acc: 85.16%] [G loss: 1.810663]\n",
      "1496 [D loss: 0.179204, acc: 89.84%, op_acc: 71.88%] [G loss: 1.819034]\n",
      "1497 [D loss: 0.170592, acc: 96.09%, op_acc: 79.69%] [G loss: 1.818041]\n",
      "1498 [D loss: 0.180632, acc: 93.75%, op_acc: 81.25%] [G loss: 1.813430]\n",
      "1499 [D loss: 0.166826, acc: 93.75%, op_acc: 77.34%] [G loss: 1.872367]\n",
      "1500 [D loss: 0.187316, acc: 92.19%, op_acc: 75.00%] [G loss: 1.665905]\n",
      "Epoch: 1500, F1: 0.60976, F1P: 150\n",
      "[[28424     8]\n",
      " [   24    25]]\n",
      "94.0625\n",
      "1501 [D loss: 0.168241, acc: 93.75%, op_acc: 75.78%] [G loss: 1.803279]\n",
      "1502 [D loss: 0.179019, acc: 92.19%, op_acc: 78.91%] [G loss: 1.855985]\n",
      "1503 [D loss: 0.177927, acc: 93.75%, op_acc: 75.00%] [G loss: 1.865262]\n",
      "1504 [D loss: 0.170547, acc: 89.84%, op_acc: 82.81%] [G loss: 1.697726]\n",
      "1505 [D loss: 0.170858, acc: 91.41%, op_acc: 79.69%] [G loss: 1.851505]\n",
      "1506 [D loss: 0.170829, acc: 95.31%, op_acc: 75.00%] [G loss: 1.840153]\n",
      "1507 [D loss: 0.173452, acc: 95.31%, op_acc: 78.12%] [G loss: 1.753134]\n",
      "1508 [D loss: 0.167331, acc: 94.53%, op_acc: 76.56%] [G loss: 1.876335]\n",
      "1509 [D loss: 0.175414, acc: 93.75%, op_acc: 79.69%] [G loss: 1.822488]\n",
      "1510 [D loss: 0.162834, acc: 96.09%, op_acc: 84.38%] [G loss: 1.688684]\n",
      "Epoch: 1510, F1: 0.60976, F1P: 151\n",
      "[[28424     8]\n",
      " [   24    25]]\n",
      "93.59375\n",
      "1511 [D loss: 0.179114, acc: 96.09%, op_acc: 79.69%] [G loss: 1.892926]\n",
      "1512 [D loss: 0.166739, acc: 94.53%, op_acc: 76.56%] [G loss: 1.849116]\n",
      "1513 [D loss: 0.155955, acc: 93.75%, op_acc: 82.03%] [G loss: 1.825361]\n",
      "1514 [D loss: 0.189375, acc: 89.84%, op_acc: 75.78%] [G loss: 1.853337]\n",
      "1515 [D loss: 0.168079, acc: 93.75%, op_acc: 80.47%] [G loss: 1.879238]\n",
      "1516 [D loss: 0.173657, acc: 94.53%, op_acc: 75.78%] [G loss: 1.824250]\n",
      "1517 [D loss: 0.183667, acc: 92.97%, op_acc: 81.25%] [G loss: 1.803506]\n",
      "1518 [D loss: 0.161695, acc: 96.09%, op_acc: 84.38%] [G loss: 1.846873]\n",
      "1519 [D loss: 0.168869, acc: 94.53%, op_acc: 83.59%] [G loss: 1.865551]\n",
      "1520 [D loss: 0.170878, acc: 95.31%, op_acc: 78.12%] [G loss: 1.744498]\n",
      "Epoch: 1520, F1: 0.64286, F1P: 152\n",
      "[[28424     8]\n",
      " [   22    27]]\n",
      "94.140625\n",
      "1521 [D loss: 0.186355, acc: 90.62%, op_acc: 75.00%] [G loss: 1.932830]\n",
      "1522 [D loss: 0.160996, acc: 96.09%, op_acc: 79.69%] [G loss: 1.814325]\n",
      "1523 [D loss: 0.174472, acc: 92.19%, op_acc: 72.66%] [G loss: 1.888425]\n",
      "1524 [D loss: 0.159299, acc: 94.53%, op_acc: 82.81%] [G loss: 1.882727]\n",
      "1525 [D loss: 0.169578, acc: 93.75%, op_acc: 83.59%] [G loss: 1.901862]\n",
      "1526 [D loss: 0.171553, acc: 96.88%, op_acc: 78.91%] [G loss: 1.769829]\n",
      "1527 [D loss: 0.183723, acc: 92.19%, op_acc: 74.22%] [G loss: 1.959338]\n",
      "1528 [D loss: 0.164339, acc: 97.66%, op_acc: 75.78%] [G loss: 1.814588]\n",
      "1529 [D loss: 0.155418, acc: 94.53%, op_acc: 82.81%] [G loss: 1.974993]\n",
      "1530 [D loss: 0.187238, acc: 90.62%, op_acc: 78.91%] [G loss: 1.935157]\n",
      "Epoch: 1530, F1: 0.63529, F1P: 153\n",
      "[[28423     9]\n",
      " [   22    27]]\n",
      "93.90625\n",
      "1531 [D loss: 0.163911, acc: 95.31%, op_acc: 78.91%] [G loss: 1.702007]\n",
      "1532 [D loss: 0.156683, acc: 97.66%, op_acc: 79.69%] [G loss: 1.921449]\n",
      "1533 [D loss: 0.171107, acc: 91.41%, op_acc: 79.69%] [G loss: 1.907987]\n",
      "1534 [D loss: 0.173362, acc: 92.97%, op_acc: 81.25%] [G loss: 1.814300]\n",
      "1535 [D loss: 0.162018, acc: 96.09%, op_acc: 79.69%] [G loss: 1.887646]\n",
      "1536 [D loss: 0.161860, acc: 93.75%, op_acc: 84.38%] [G loss: 1.902359]\n",
      "1537 [D loss: 0.159269, acc: 96.09%, op_acc: 82.03%] [G loss: 1.877129]\n",
      "1538 [D loss: 0.179807, acc: 89.06%, op_acc: 75.00%] [G loss: 1.785657]\n",
      "1539 [D loss: 0.170195, acc: 92.19%, op_acc: 82.81%] [G loss: 1.672172]\n",
      "1540 [D loss: 0.176435, acc: 94.53%, op_acc: 78.91%] [G loss: 1.742767]\n",
      "Epoch: 1540, F1: 0.60976, F1P: 154\n",
      "[[28424     8]\n",
      " [   24    25]]\n",
      "93.90625\n",
      "1541 [D loss: 0.168869, acc: 96.09%, op_acc: 79.69%] [G loss: 1.852097]\n",
      "1542 [D loss: 0.174534, acc: 93.75%, op_acc: 86.72%] [G loss: 1.817820]\n",
      "1543 [D loss: 0.162345, acc: 92.19%, op_acc: 78.12%] [G loss: 1.908575]\n",
      "1544 [D loss: 0.168157, acc: 95.31%, op_acc: 84.38%] [G loss: 1.852108]\n",
      "1545 [D loss: 0.182213, acc: 93.75%, op_acc: 80.47%] [G loss: 1.824883]\n",
      "1546 [D loss: 0.176725, acc: 91.41%, op_acc: 83.59%] [G loss: 1.865773]\n",
      "1547 [D loss: 0.159736, acc: 96.88%, op_acc: 83.59%] [G loss: 1.761264]\n",
      "1548 [D loss: 0.167752, acc: 92.19%, op_acc: 78.12%] [G loss: 1.740133]\n",
      "1549 [D loss: 0.164279, acc: 94.53%, op_acc: 83.59%] [G loss: 1.869807]\n",
      "1550 [D loss: 0.168708, acc: 92.97%, op_acc: 81.25%] [G loss: 1.773174]\n",
      "Epoch: 1550, F1: 0.63529, F1P: 155\n",
      "[[28423     9]\n",
      " [   22    27]]\n",
      "93.90625\n",
      "1551 [D loss: 0.164019, acc: 95.31%, op_acc: 85.16%] [G loss: 1.993456]\n",
      "1552 [D loss: 0.177546, acc: 93.75%, op_acc: 82.03%] [G loss: 1.903494]\n",
      "1553 [D loss: 0.160362, acc: 95.31%, op_acc: 82.81%] [G loss: 1.864440]\n",
      "1554 [D loss: 0.170922, acc: 93.75%, op_acc: 82.03%] [G loss: 1.975017]\n",
      "1555 [D loss: 0.164662, acc: 95.31%, op_acc: 80.47%] [G loss: 1.761896]\n",
      "1556 [D loss: 0.178717, acc: 93.75%, op_acc: 79.69%] [G loss: 1.791126]\n",
      "1557 [D loss: 0.162944, acc: 93.75%, op_acc: 78.91%] [G loss: 1.831315]\n",
      "1558 [D loss: 0.166818, acc: 95.31%, op_acc: 78.91%] [G loss: 1.813637]\n",
      "1559 [D loss: 0.169908, acc: 95.31%, op_acc: 77.34%] [G loss: 1.795166]\n",
      "1560 [D loss: 0.175428, acc: 90.62%, op_acc: 78.91%] [G loss: 1.771497]\n",
      "Epoch: 1560, F1: 0.63529, F1P: 156\n",
      "[[28423     9]\n",
      " [   22    27]]\n",
      "94.21875\n",
      "1561 [D loss: 0.165363, acc: 98.44%, op_acc: 78.91%] [G loss: 1.796280]\n",
      "1562 [D loss: 0.160695, acc: 96.88%, op_acc: 78.12%] [G loss: 1.872642]\n",
      "1563 [D loss: 0.170251, acc: 92.97%, op_acc: 82.03%] [G loss: 1.881580]\n",
      "1564 [D loss: 0.169873, acc: 95.31%, op_acc: 83.59%] [G loss: 1.780013]\n",
      "1565 [D loss: 0.160906, acc: 94.53%, op_acc: 82.81%] [G loss: 1.781482]\n",
      "1566 [D loss: 0.158637, acc: 93.75%, op_acc: 79.69%] [G loss: 1.849087]\n",
      "1567 [D loss: 0.155971, acc: 94.53%, op_acc: 82.03%] [G loss: 1.934045]\n",
      "1568 [D loss: 0.160830, acc: 92.97%, op_acc: 83.59%] [G loss: 2.052287]\n",
      "1569 [D loss: 0.162037, acc: 93.75%, op_acc: 85.16%] [G loss: 1.890355]\n",
      "1570 [D loss: 0.178414, acc: 91.41%, op_acc: 75.00%] [G loss: 1.834086]\n",
      "Epoch: 1570, F1: 0.63529, F1P: 157\n",
      "[[28423     9]\n",
      " [   22    27]]\n",
      "94.453125\n",
      "1571 [D loss: 0.164091, acc: 93.75%, op_acc: 86.72%] [G loss: 1.809956]\n",
      "1572 [D loss: 0.174790, acc: 92.97%, op_acc: 77.34%] [G loss: 1.885186]\n",
      "1573 [D loss: 0.182513, acc: 93.75%, op_acc: 77.34%] [G loss: 1.982631]\n",
      "1574 [D loss: 0.166273, acc: 94.53%, op_acc: 72.66%] [G loss: 1.837906]\n",
      "1575 [D loss: 0.153337, acc: 92.19%, op_acc: 85.16%] [G loss: 1.780089]\n",
      "1576 [D loss: 0.174368, acc: 92.19%, op_acc: 79.69%] [G loss: 1.828031]\n",
      "1577 [D loss: 0.181180, acc: 92.19%, op_acc: 73.44%] [G loss: 1.864032]\n",
      "1578 [D loss: 0.150378, acc: 93.75%, op_acc: 84.38%] [G loss: 1.988634]\n",
      "1579 [D loss: 0.164240, acc: 93.75%, op_acc: 80.47%] [G loss: 2.018497]\n",
      "1580 [D loss: 0.160817, acc: 96.09%, op_acc: 77.34%] [G loss: 1.929190]\n",
      "Epoch: 1580, F1: 0.64286, F1P: 158\n",
      "[[28424     8]\n",
      " [   22    27]]\n",
      "93.515625\n",
      "1581 [D loss: 0.176890, acc: 92.97%, op_acc: 78.91%] [G loss: 1.879432]\n",
      "1582 [D loss: 0.167116, acc: 95.31%, op_acc: 80.47%] [G loss: 1.813580]\n",
      "1583 [D loss: 0.185467, acc: 93.75%, op_acc: 78.12%] [G loss: 1.871572]\n",
      "1584 [D loss: 0.151229, acc: 96.88%, op_acc: 83.59%] [G loss: 1.822428]\n",
      "1585 [D loss: 0.148555, acc: 97.66%, op_acc: 82.03%] [G loss: 1.795806]\n",
      "1586 [D loss: 0.152961, acc: 94.53%, op_acc: 85.16%] [G loss: 1.904798]\n",
      "1587 [D loss: 0.159011, acc: 93.75%, op_acc: 85.16%] [G loss: 1.883098]\n",
      "1588 [D loss: 0.180693, acc: 92.19%, op_acc: 81.25%] [G loss: 1.823858]\n",
      "1589 [D loss: 0.179583, acc: 89.84%, op_acc: 82.81%] [G loss: 1.841178]\n",
      "1590 [D loss: 0.172992, acc: 94.53%, op_acc: 78.91%] [G loss: 1.840440]\n",
      "Epoch: 1590, F1: 0.62069, F1P: 159\n",
      "[[28421    11]\n",
      " [   22    27]]\n",
      "94.140625\n",
      "1591 [D loss: 0.172856, acc: 92.97%, op_acc: 79.69%] [G loss: 1.942920]\n",
      "1592 [D loss: 0.160467, acc: 95.31%, op_acc: 75.78%] [G loss: 1.927372]\n",
      "1593 [D loss: 0.155792, acc: 95.31%, op_acc: 76.56%] [G loss: 1.771889]\n",
      "1594 [D loss: 0.153130, acc: 96.88%, op_acc: 78.12%] [G loss: 1.863924]\n",
      "1595 [D loss: 0.171854, acc: 90.62%, op_acc: 77.34%] [G loss: 1.787988]\n",
      "1596 [D loss: 0.158001, acc: 94.53%, op_acc: 82.03%] [G loss: 1.809269]\n",
      "1597 [D loss: 0.158701, acc: 96.09%, op_acc: 82.81%] [G loss: 1.908020]\n",
      "1598 [D loss: 0.163390, acc: 94.53%, op_acc: 85.94%] [G loss: 1.770888]\n",
      "1599 [D loss: 0.163102, acc: 93.75%, op_acc: 82.81%] [G loss: 1.976204]\n",
      "1600 [D loss: 0.170503, acc: 92.97%, op_acc: 80.47%] [G loss: 1.977377]\n",
      "Epoch: 1600, F1: 0.63529, F1P: 160\n",
      "[[28423     9]\n",
      " [   22    27]]\n",
      "94.296875\n",
      "1601 [D loss: 0.153161, acc: 97.66%, op_acc: 81.25%] [G loss: 1.881812]\n",
      "1602 [D loss: 0.158189, acc: 95.31%, op_acc: 78.91%] [G loss: 1.846044]\n",
      "1603 [D loss: 0.163859, acc: 94.53%, op_acc: 82.81%] [G loss: 1.731720]\n",
      "1604 [D loss: 0.156189, acc: 95.31%, op_acc: 81.25%] [G loss: 1.736568]\n",
      "1605 [D loss: 0.167797, acc: 92.97%, op_acc: 84.38%] [G loss: 1.908905]\n",
      "1606 [D loss: 0.146931, acc: 94.53%, op_acc: 82.03%] [G loss: 1.809864]\n",
      "1607 [D loss: 0.163070, acc: 92.97%, op_acc: 81.25%] [G loss: 1.805592]\n",
      "1608 [D loss: 0.156348, acc: 95.31%, op_acc: 85.16%] [G loss: 1.866585]\n",
      "1609 [D loss: 0.167397, acc: 93.75%, op_acc: 83.59%] [G loss: 1.931437]\n",
      "1610 [D loss: 0.182087, acc: 92.97%, op_acc: 77.34%] [G loss: 1.904905]\n",
      "Epoch: 1610, F1: 0.63636, F1P: 161\n",
      "[[28421    11]\n",
      " [   21    28]]\n",
      "94.53125\n",
      "1611 [D loss: 0.162411, acc: 94.53%, op_acc: 78.12%] [G loss: 1.865837]\n",
      "1612 [D loss: 0.151157, acc: 97.66%, op_acc: 82.03%] [G loss: 1.858641]\n",
      "1613 [D loss: 0.158155, acc: 95.31%, op_acc: 74.22%] [G loss: 1.855329]\n",
      "1614 [D loss: 0.167300, acc: 91.41%, op_acc: 79.69%] [G loss: 1.749414]\n",
      "1615 [D loss: 0.159504, acc: 95.31%, op_acc: 83.59%] [G loss: 1.898441]\n",
      "1616 [D loss: 0.170172, acc: 96.88%, op_acc: 79.69%] [G loss: 1.838313]\n",
      "1617 [D loss: 0.158262, acc: 94.53%, op_acc: 83.59%] [G loss: 1.920351]\n",
      "1618 [D loss: 0.160162, acc: 94.53%, op_acc: 81.25%] [G loss: 1.794663]\n",
      "1619 [D loss: 0.168793, acc: 92.97%, op_acc: 75.78%] [G loss: 1.918952]\n",
      "1620 [D loss: 0.148708, acc: 96.09%, op_acc: 81.25%] [G loss: 1.819530]\n",
      "Epoch: 1620, F1: 0.63736, F1P: 162\n",
      "[[28419    13]\n",
      " [   20    29]]\n",
      "94.921875\n",
      "1621 [D loss: 0.160169, acc: 96.09%, op_acc: 79.69%] [G loss: 1.837408]\n",
      "1622 [D loss: 0.162798, acc: 92.97%, op_acc: 82.03%] [G loss: 1.918308]\n",
      "1623 [D loss: 0.158853, acc: 95.31%, op_acc: 78.12%] [G loss: 1.805101]\n",
      "1624 [D loss: 0.158916, acc: 96.88%, op_acc: 80.47%] [G loss: 1.912634]\n",
      "1625 [D loss: 0.155940, acc: 96.09%, op_acc: 76.56%] [G loss: 1.904631]\n",
      "1626 [D loss: 0.146275, acc: 99.22%, op_acc: 85.94%] [G loss: 1.784903]\n",
      "1627 [D loss: 0.152426, acc: 95.31%, op_acc: 75.00%] [G loss: 1.783276]\n",
      "1628 [D loss: 0.157677, acc: 94.53%, op_acc: 80.47%] [G loss: 1.777160]\n",
      "1629 [D loss: 0.163895, acc: 92.97%, op_acc: 82.81%] [G loss: 1.974991]\n",
      "1630 [D loss: 0.154400, acc: 97.66%, op_acc: 77.34%] [G loss: 1.853774]\n",
      "Epoch: 1630, F1: 0.65217, F1P: 163\n",
      "[[28419    13]\n",
      " [   19    30]]\n",
      "95.703125\n",
      "1631 [D loss: 0.159834, acc: 96.88%, op_acc: 84.38%] [G loss: 1.854439]\n",
      "1632 [D loss: 0.154839, acc: 93.75%, op_acc: 82.81%] [G loss: 1.877056]\n",
      "1633 [D loss: 0.148734, acc: 96.88%, op_acc: 86.72%] [G loss: 2.028886]\n",
      "1634 [D loss: 0.166266, acc: 92.19%, op_acc: 80.47%] [G loss: 1.997564]\n",
      "1635 [D loss: 0.162441, acc: 93.75%, op_acc: 86.72%] [G loss: 1.835145]\n",
      "1636 [D loss: 0.146893, acc: 96.88%, op_acc: 89.84%] [G loss: 1.885858]\n",
      "1637 [D loss: 0.162456, acc: 96.09%, op_acc: 83.59%] [G loss: 1.868811]\n",
      "1638 [D loss: 0.143018, acc: 98.44%, op_acc: 88.28%] [G loss: 1.843862]\n",
      "1639 [D loss: 0.167144, acc: 91.41%, op_acc: 82.81%] [G loss: 1.949462]\n",
      "1640 [D loss: 0.157568, acc: 97.66%, op_acc: 84.38%] [G loss: 1.827225]\n",
      "Epoch: 1640, F1: 0.65957, F1P: 164\n",
      "[[28418    14]\n",
      " [   18    31]]\n",
      "95.390625\n",
      "1641 [D loss: 0.150920, acc: 97.66%, op_acc: 79.69%] [G loss: 1.901843]\n",
      "1642 [D loss: 0.162879, acc: 95.31%, op_acc: 84.38%] [G loss: 1.742678]\n",
      "1643 [D loss: 0.153406, acc: 94.53%, op_acc: 81.25%] [G loss: 1.879240]\n",
      "1644 [D loss: 0.178593, acc: 90.62%, op_acc: 74.22%] [G loss: 1.809967]\n",
      "1645 [D loss: 0.153000, acc: 97.66%, op_acc: 85.16%] [G loss: 1.829070]\n",
      "1646 [D loss: 0.169284, acc: 91.41%, op_acc: 85.16%] [G loss: 1.813876]\n",
      "1647 [D loss: 0.159047, acc: 94.53%, op_acc: 82.03%] [G loss: 1.762278]\n",
      "1648 [D loss: 0.171246, acc: 96.09%, op_acc: 82.03%] [G loss: 1.887471]\n",
      "1649 [D loss: 0.163685, acc: 94.53%, op_acc: 83.59%] [G loss: 1.897414]\n",
      "1650 [D loss: 0.166415, acc: 94.53%, op_acc: 75.78%] [G loss: 1.945680]\n",
      "Epoch: 1650, F1: 0.68750, F1P: 165\n",
      "[[28418    14]\n",
      " [   16    33]]\n",
      "94.6875\n",
      "1651 [D loss: 0.162614, acc: 95.31%, op_acc: 84.38%] [G loss: 1.867881]\n",
      "1652 [D loss: 0.176037, acc: 94.53%, op_acc: 76.56%] [G loss: 1.845444]\n",
      "1653 [D loss: 0.172451, acc: 94.53%, op_acc: 83.59%] [G loss: 1.943230]\n",
      "1654 [D loss: 0.160080, acc: 94.53%, op_acc: 78.12%] [G loss: 1.821952]\n",
      "1655 [D loss: 0.164299, acc: 93.75%, op_acc: 81.25%] [G loss: 1.749167]\n",
      "1656 [D loss: 0.164565, acc: 96.09%, op_acc: 81.25%] [G loss: 1.868407]\n",
      "1657 [D loss: 0.165318, acc: 96.88%, op_acc: 82.03%] [G loss: 1.837664]\n",
      "1658 [D loss: 0.157315, acc: 96.09%, op_acc: 83.59%] [G loss: 1.909893]\n",
      "1659 [D loss: 0.149125, acc: 97.66%, op_acc: 88.28%] [G loss: 1.920684]\n",
      "1660 [D loss: 0.174298, acc: 90.62%, op_acc: 81.25%] [G loss: 1.958812]\n",
      "Epoch: 1660, F1: 0.67961, F1P: 166\n",
      "[[28413    19]\n",
      " [   14    35]]\n",
      "95.0\n",
      "1661 [D loss: 0.159532, acc: 93.75%, op_acc: 78.91%] [G loss: 1.775491]\n",
      "1662 [D loss: 0.135134, acc: 96.09%, op_acc: 84.38%] [G loss: 1.699010]\n",
      "1663 [D loss: 0.167573, acc: 95.31%, op_acc: 82.81%] [G loss: 1.850088]\n",
      "1664 [D loss: 0.161022, acc: 93.75%, op_acc: 82.03%] [G loss: 1.657060]\n",
      "1665 [D loss: 0.164700, acc: 92.19%, op_acc: 82.03%] [G loss: 1.806848]\n",
      "1666 [D loss: 0.150293, acc: 94.53%, op_acc: 76.56%] [G loss: 1.703083]\n",
      "1667 [D loss: 0.151950, acc: 95.31%, op_acc: 80.47%] [G loss: 1.822130]\n",
      "1668 [D loss: 0.169036, acc: 93.75%, op_acc: 77.34%] [G loss: 1.712029]\n",
      "1669 [D loss: 0.162792, acc: 94.53%, op_acc: 85.16%] [G loss: 1.784369]\n",
      "1670 [D loss: 0.151882, acc: 96.09%, op_acc: 78.91%] [G loss: 1.848191]\n",
      "Epoch: 1670, F1: 0.67327, F1P: 167\n",
      "[[28414    18]\n",
      " [   15    34]]\n",
      "94.53125\n",
      "1671 [D loss: 0.169085, acc: 93.75%, op_acc: 78.12%] [G loss: 1.806187]\n",
      "1672 [D loss: 0.150003, acc: 94.53%, op_acc: 84.38%] [G loss: 1.871850]\n",
      "1673 [D loss: 0.157377, acc: 96.09%, op_acc: 82.81%] [G loss: 1.773138]\n",
      "1674 [D loss: 0.163514, acc: 96.09%, op_acc: 81.25%] [G loss: 1.686791]\n",
      "1675 [D loss: 0.160970, acc: 92.97%, op_acc: 84.38%] [G loss: 1.696431]\n",
      "1676 [D loss: 0.156124, acc: 95.31%, op_acc: 79.69%] [G loss: 1.788338]\n",
      "1677 [D loss: 0.160166, acc: 93.75%, op_acc: 82.03%] [G loss: 1.686274]\n",
      "1678 [D loss: 0.143256, acc: 96.88%, op_acc: 79.69%] [G loss: 1.722666]\n",
      "1679 [D loss: 0.157265, acc: 94.53%, op_acc: 83.59%] [G loss: 1.877349]\n",
      "1680 [D loss: 0.155371, acc: 97.66%, op_acc: 74.22%] [G loss: 1.634829]\n",
      "Epoch: 1680, F1: 0.66667, F1P: 168\n",
      "[[28411    21]\n",
      " [   14    35]]\n",
      "95.15625\n",
      "1681 [D loss: 0.167628, acc: 95.31%, op_acc: 78.12%] [G loss: 1.771873]\n",
      "1682 [D loss: 0.163818, acc: 93.75%, op_acc: 78.12%] [G loss: 1.735929]\n",
      "1683 [D loss: 0.151941, acc: 94.53%, op_acc: 79.69%] [G loss: 1.973333]\n",
      "1684 [D loss: 0.160316, acc: 94.53%, op_acc: 82.81%] [G loss: 1.962291]\n",
      "1685 [D loss: 0.156799, acc: 96.09%, op_acc: 79.69%] [G loss: 1.834279]\n",
      "1686 [D loss: 0.151145, acc: 97.66%, op_acc: 79.69%] [G loss: 1.771424]\n",
      "1687 [D loss: 0.150296, acc: 99.22%, op_acc: 78.91%] [G loss: 1.824112]\n",
      "1688 [D loss: 0.163233, acc: 95.31%, op_acc: 78.91%] [G loss: 1.868325]\n",
      "1689 [D loss: 0.164281, acc: 98.44%, op_acc: 79.69%] [G loss: 1.818202]\n",
      "1690 [D loss: 0.166013, acc: 92.97%, op_acc: 72.66%] [G loss: 1.749838]\n",
      "Epoch: 1690, F1: 0.66055, F1P: 169\n",
      "[[28408    24]\n",
      " [   13    36]]\n",
      "95.78125\n",
      "1691 [D loss: 0.147292, acc: 97.66%, op_acc: 85.94%] [G loss: 1.812530]\n",
      "1692 [D loss: 0.162383, acc: 94.53%, op_acc: 75.00%] [G loss: 1.746221]\n",
      "1693 [D loss: 0.161448, acc: 93.75%, op_acc: 85.94%] [G loss: 1.748179]\n",
      "1694 [D loss: 0.154292, acc: 96.09%, op_acc: 79.69%] [G loss: 1.737431]\n",
      "1695 [D loss: 0.172372, acc: 92.19%, op_acc: 77.34%] [G loss: 1.642148]\n",
      "1696 [D loss: 0.156298, acc: 96.09%, op_acc: 79.69%] [G loss: 1.771775]\n",
      "1697 [D loss: 0.155745, acc: 96.88%, op_acc: 73.44%] [G loss: 1.799558]\n",
      "1698 [D loss: 0.166538, acc: 93.75%, op_acc: 68.75%] [G loss: 1.783348]\n",
      "1699 [D loss: 0.144993, acc: 98.44%, op_acc: 79.69%] [G loss: 1.795323]\n",
      "1700 [D loss: 0.142099, acc: 95.31%, op_acc: 83.59%] [G loss: 1.687374]\n",
      "Epoch: 1700, F1: 0.67290, F1P: 170\n",
      "[[28410    22]\n",
      " [   13    36]]\n",
      "95.46875\n",
      "1701 [D loss: 0.163707, acc: 94.53%, op_acc: 73.44%] [G loss: 1.781435]\n",
      "1702 [D loss: 0.168648, acc: 95.31%, op_acc: 84.38%] [G loss: 1.683408]\n",
      "1703 [D loss: 0.158198, acc: 94.53%, op_acc: 80.47%] [G loss: 1.732259]\n",
      "1704 [D loss: 0.157661, acc: 96.09%, op_acc: 82.03%] [G loss: 1.745108]\n",
      "1705 [D loss: 0.156362, acc: 94.53%, op_acc: 76.56%] [G loss: 1.764100]\n",
      "1706 [D loss: 0.175026, acc: 89.06%, op_acc: 76.56%] [G loss: 1.737111]\n",
      "1707 [D loss: 0.160147, acc: 94.53%, op_acc: 79.69%] [G loss: 1.734269]\n",
      "1708 [D loss: 0.144005, acc: 96.09%, op_acc: 85.16%] [G loss: 1.714626]\n",
      "1709 [D loss: 0.152262, acc: 93.75%, op_acc: 85.16%] [G loss: 1.885442]\n",
      "1710 [D loss: 0.161120, acc: 96.09%, op_acc: 80.47%] [G loss: 1.845480]\n",
      "Epoch: 1710, F1: 0.64865, F1P: 171\n",
      "[[28406    26]\n",
      " [   13    36]]\n",
      "94.453125\n",
      "1711 [D loss: 0.147006, acc: 92.19%, op_acc: 85.16%] [G loss: 1.725166]\n",
      "1712 [D loss: 0.152621, acc: 94.53%, op_acc: 78.91%] [G loss: 1.715616]\n",
      "1713 [D loss: 0.168693, acc: 93.75%, op_acc: 82.03%] [G loss: 1.749247]\n",
      "1714 [D loss: 0.156351, acc: 93.75%, op_acc: 80.47%] [G loss: 1.757648]\n",
      "1715 [D loss: 0.173981, acc: 96.09%, op_acc: 82.81%] [G loss: 1.757704]\n",
      "1716 [D loss: 0.164751, acc: 96.09%, op_acc: 79.69%] [G loss: 1.784965]\n",
      "1717 [D loss: 0.160981, acc: 95.31%, op_acc: 82.03%] [G loss: 1.882900]\n",
      "1718 [D loss: 0.156647, acc: 95.31%, op_acc: 79.69%] [G loss: 1.948250]\n",
      "1719 [D loss: 0.162398, acc: 92.19%, op_acc: 80.47%] [G loss: 1.764337]\n",
      "1720 [D loss: 0.150553, acc: 99.22%, op_acc: 78.12%] [G loss: 1.751918]\n",
      "Epoch: 1720, F1: 0.56489, F1P: 172\n",
      "[[28387    45]\n",
      " [   12    37]]\n",
      "94.84375\n",
      "1721 [D loss: 0.166198, acc: 92.97%, op_acc: 77.34%] [G loss: 1.765627]\n",
      "1722 [D loss: 0.163825, acc: 92.19%, op_acc: 78.91%] [G loss: 1.865979]\n",
      "1723 [D loss: 0.160793, acc: 95.31%, op_acc: 79.69%] [G loss: 1.861822]\n",
      "1724 [D loss: 0.154010, acc: 94.53%, op_acc: 78.12%] [G loss: 1.731859]\n",
      "1725 [D loss: 0.155265, acc: 97.66%, op_acc: 82.81%] [G loss: 1.815291]\n",
      "1726 [D loss: 0.158401, acc: 92.97%, op_acc: 76.56%] [G loss: 1.851668]\n",
      "1727 [D loss: 0.142058, acc: 96.88%, op_acc: 79.69%] [G loss: 1.811148]\n",
      "1728 [D loss: 0.146822, acc: 95.31%, op_acc: 77.34%] [G loss: 1.878504]\n",
      "1729 [D loss: 0.157433, acc: 93.75%, op_acc: 79.69%] [G loss: 1.774533]\n",
      "1730 [D loss: 0.168895, acc: 94.53%, op_acc: 78.12%] [G loss: 1.828370]\n",
      "Epoch: 1730, F1: 0.50340, F1P: 173\n",
      "[[28371    61]\n",
      " [   12    37]]\n",
      "94.609375\n",
      "1731 [D loss: 0.141854, acc: 96.09%, op_acc: 83.59%] [G loss: 1.748847]\n",
      "1732 [D loss: 0.156878, acc: 96.88%, op_acc: 82.03%] [G loss: 1.881859]\n",
      "1733 [D loss: 0.140305, acc: 98.44%, op_acc: 84.38%] [G loss: 1.735572]\n",
      "1734 [D loss: 0.156918, acc: 95.31%, op_acc: 80.47%] [G loss: 1.953531]\n",
      "1735 [D loss: 0.142471, acc: 96.88%, op_acc: 80.47%] [G loss: 1.796517]\n",
      "1736 [D loss: 0.155583, acc: 95.31%, op_acc: 82.81%] [G loss: 1.861093]\n",
      "1737 [D loss: 0.140879, acc: 93.75%, op_acc: 78.12%] [G loss: 1.681627]\n",
      "1738 [D loss: 0.152728, acc: 96.88%, op_acc: 84.38%] [G loss: 1.896349]\n",
      "1739 [D loss: 0.158358, acc: 96.88%, op_acc: 79.69%] [G loss: 1.939039]\n",
      "1740 [D loss: 0.154069, acc: 95.31%, op_acc: 83.59%] [G loss: 1.910790]\n",
      "Epoch: 1740, F1: 0.47134, F1P: 174\n",
      "[[28361    71]\n",
      " [   12    37]]\n",
      "96.171875\n",
      "1741 [D loss: 0.164875, acc: 94.53%, op_acc: 78.12%] [G loss: 1.807881]\n",
      "1742 [D loss: 0.158061, acc: 96.09%, op_acc: 78.91%] [G loss: 1.783689]\n",
      "1743 [D loss: 0.152484, acc: 97.66%, op_acc: 78.12%] [G loss: 1.867498]\n",
      "1744 [D loss: 0.151862, acc: 93.75%, op_acc: 82.81%] [G loss: 1.828937]\n",
      "1745 [D loss: 0.150616, acc: 96.09%, op_acc: 85.94%] [G loss: 1.847102]\n",
      "1746 [D loss: 0.158793, acc: 93.75%, op_acc: 83.59%] [G loss: 1.855483]\n",
      "1747 [D loss: 0.165445, acc: 95.31%, op_acc: 79.69%] [G loss: 1.816016]\n",
      "1748 [D loss: 0.148850, acc: 96.88%, op_acc: 85.16%] [G loss: 1.960242]\n",
      "1749 [D loss: 0.167136, acc: 91.41%, op_acc: 80.47%] [G loss: 1.785789]\n",
      "1750 [D loss: 0.161853, acc: 96.09%, op_acc: 78.91%] [G loss: 1.627260]\n",
      "Epoch: 1750, F1: 0.36275, F1P: 175\n",
      "[[28314   118]\n",
      " [   12    37]]\n",
      "95.15625\n",
      "1751 [D loss: 0.156581, acc: 94.53%, op_acc: 84.38%] [G loss: 1.842207]\n",
      "1752 [D loss: 0.147274, acc: 94.53%, op_acc: 79.69%] [G loss: 1.769257]\n",
      "1753 [D loss: 0.144871, acc: 94.53%, op_acc: 86.72%] [G loss: 1.820716]\n",
      "1754 [D loss: 0.144144, acc: 96.88%, op_acc: 79.69%] [G loss: 1.768641]\n",
      "1755 [D loss: 0.174349, acc: 92.19%, op_acc: 80.47%] [G loss: 1.828087]\n",
      "1756 [D loss: 0.150993, acc: 98.44%, op_acc: 80.47%] [G loss: 1.901964]\n",
      "1757 [D loss: 0.142001, acc: 95.31%, op_acc: 78.12%] [G loss: 1.924877]\n",
      "1758 [D loss: 0.157379, acc: 98.44%, op_acc: 84.38%] [G loss: 1.724029]\n",
      "1759 [D loss: 0.163332, acc: 96.88%, op_acc: 81.25%] [G loss: 1.746962]\n",
      "1760 [D loss: 0.151793, acc: 95.31%, op_acc: 82.03%] [G loss: 1.707944]\n",
      "Epoch: 1760, F1: 0.40217, F1P: 176\n",
      "[[28334    98]\n",
      " [   12    37]]\n",
      "95.703125\n",
      "1761 [D loss: 0.145650, acc: 92.97%, op_acc: 82.81%] [G loss: 1.821003]\n",
      "1762 [D loss: 0.169723, acc: 94.53%, op_acc: 82.81%] [G loss: 1.790187]\n",
      "1763 [D loss: 0.139940, acc: 97.66%, op_acc: 84.38%] [G loss: 1.881413]\n",
      "1764 [D loss: 0.162372, acc: 94.53%, op_acc: 80.47%] [G loss: 1.805745]\n",
      "1765 [D loss: 0.158097, acc: 92.97%, op_acc: 81.25%] [G loss: 1.887540]\n",
      "1766 [D loss: 0.165045, acc: 93.75%, op_acc: 78.12%] [G loss: 1.844926]\n",
      "1767 [D loss: 0.158864, acc: 92.97%, op_acc: 80.47%] [G loss: 1.875549]\n",
      "1768 [D loss: 0.154688, acc: 96.09%, op_acc: 78.91%] [G loss: 1.777861]\n",
      "1769 [D loss: 0.136332, acc: 98.44%, op_acc: 83.59%] [G loss: 1.816227]\n",
      "1770 [D loss: 0.160890, acc: 95.31%, op_acc: 79.69%] [G loss: 1.819800]\n",
      "Epoch: 1770, F1: 0.32922, F1P: 177\n",
      "[[28278   154]\n",
      " [    9    40]]\n",
      "94.921875\n",
      "1771 [D loss: 0.140945, acc: 96.09%, op_acc: 75.00%] [G loss: 1.831801]\n",
      "1772 [D loss: 0.153344, acc: 97.66%, op_acc: 82.81%] [G loss: 1.764138]\n",
      "1773 [D loss: 0.150930, acc: 94.53%, op_acc: 75.00%] [G loss: 1.793938]\n",
      "1774 [D loss: 0.150693, acc: 92.97%, op_acc: 78.12%] [G loss: 1.664485]\n",
      "1775 [D loss: 0.157144, acc: 92.97%, op_acc: 78.91%] [G loss: 1.749871]\n",
      "1776 [D loss: 0.157014, acc: 96.88%, op_acc: 79.69%] [G loss: 1.662992]\n",
      "1777 [D loss: 0.149687, acc: 94.53%, op_acc: 84.38%] [G loss: 1.869992]\n",
      "1778 [D loss: 0.157144, acc: 96.09%, op_acc: 81.25%] [G loss: 1.821427]\n",
      "1779 [D loss: 0.165481, acc: 92.97%, op_acc: 74.22%] [G loss: 1.805611]\n",
      "1780 [D loss: 0.148368, acc: 96.09%, op_acc: 87.50%] [G loss: 1.879747]\n",
      "Epoch: 1780, F1: 0.29391, F1P: 178\n",
      "[[28243   189]\n",
      " [    8    41]]\n",
      "95.078125\n",
      "1781 [D loss: 0.136423, acc: 96.09%, op_acc: 85.94%] [G loss: 1.785826]\n",
      "1782 [D loss: 0.152548, acc: 95.31%, op_acc: 80.47%] [G loss: 1.898833]\n",
      "1783 [D loss: 0.157586, acc: 93.75%, op_acc: 78.91%] [G loss: 1.754701]\n",
      "1784 [D loss: 0.156751, acc: 96.09%, op_acc: 81.25%] [G loss: 1.884587]\n",
      "1785 [D loss: 0.155622, acc: 96.09%, op_acc: 84.38%] [G loss: 1.733960]\n",
      "1786 [D loss: 0.146475, acc: 97.66%, op_acc: 82.03%] [G loss: 1.823971]\n",
      "1787 [D loss: 0.159132, acc: 95.31%, op_acc: 81.25%] [G loss: 1.786723]\n",
      "1788 [D loss: 0.146464, acc: 96.88%, op_acc: 80.47%] [G loss: 1.763560]\n",
      "1789 [D loss: 0.147084, acc: 94.53%, op_acc: 80.47%] [G loss: 1.786760]\n",
      "1790 [D loss: 0.155494, acc: 96.09%, op_acc: 77.34%] [G loss: 1.892695]\n",
      "Epoch: 1790, F1: 0.31418, F1P: 179\n",
      "[[28261   171]\n",
      " [    8    41]]\n",
      "95.78125\n",
      "1791 [D loss: 0.150625, acc: 93.75%, op_acc: 80.47%] [G loss: 1.797133]\n",
      "1792 [D loss: 0.156783, acc: 96.09%, op_acc: 84.38%] [G loss: 1.728233]\n",
      "1793 [D loss: 0.147951, acc: 96.88%, op_acc: 81.25%] [G loss: 1.820937]\n",
      "1794 [D loss: 0.148798, acc: 98.44%, op_acc: 83.59%] [G loss: 1.805177]\n",
      "1795 [D loss: 0.156565, acc: 92.97%, op_acc: 84.38%] [G loss: 1.776887]\n",
      "1796 [D loss: 0.138563, acc: 98.44%, op_acc: 86.72%] [G loss: 1.880646]\n",
      "1797 [D loss: 0.157708, acc: 94.53%, op_acc: 79.69%] [G loss: 1.837798]\n",
      "1798 [D loss: 0.139402, acc: 96.09%, op_acc: 79.69%] [G loss: 1.754940]\n",
      "1799 [D loss: 0.138489, acc: 97.66%, op_acc: 88.28%] [G loss: 1.791843]\n",
      "1800 [D loss: 0.150068, acc: 94.53%, op_acc: 86.72%] [G loss: 1.786002]\n",
      "Epoch: 1800, F1: 0.25153, F1P: 180\n",
      "[[28196   236]\n",
      " [    8    41]]\n",
      "95.9375\n",
      "1801 [D loss: 0.164363, acc: 96.09%, op_acc: 77.34%] [G loss: 1.688072]\n",
      "1802 [D loss: 0.140381, acc: 98.44%, op_acc: 85.16%] [G loss: 1.801425]\n",
      "1803 [D loss: 0.152437, acc: 96.09%, op_acc: 87.50%] [G loss: 1.810078]\n",
      "1804 [D loss: 0.152169, acc: 95.31%, op_acc: 82.03%] [G loss: 1.762391]\n",
      "1805 [D loss: 0.138990, acc: 97.66%, op_acc: 87.50%] [G loss: 1.769511]\n",
      "1806 [D loss: 0.147200, acc: 97.66%, op_acc: 85.16%] [G loss: 1.810122]\n",
      "1807 [D loss: 0.142551, acc: 98.44%, op_acc: 84.38%] [G loss: 1.820398]\n",
      "1808 [D loss: 0.149361, acc: 96.88%, op_acc: 84.38%] [G loss: 1.745064]\n",
      "1809 [D loss: 0.143316, acc: 96.88%, op_acc: 82.81%] [G loss: 1.828153]\n",
      "1810 [D loss: 0.142343, acc: 98.44%, op_acc: 89.06%] [G loss: 1.731230]\n",
      "Epoch: 1810, F1: 0.29603, F1P: 181\n",
      "[[28245   187]\n",
      " [    8    41]]\n",
      "97.1875\n",
      "1811 [D loss: 0.148594, acc: 97.66%, op_acc: 82.03%] [G loss: 1.717879]\n",
      "1812 [D loss: 0.154203, acc: 95.31%, op_acc: 82.81%] [G loss: 1.848136]\n",
      "1813 [D loss: 0.158937, acc: 94.53%, op_acc: 81.25%] [G loss: 1.775013]\n",
      "1814 [D loss: 0.146087, acc: 96.09%, op_acc: 79.69%] [G loss: 1.820232]\n",
      "1815 [D loss: 0.158416, acc: 93.75%, op_acc: 82.81%] [G loss: 1.903120]\n",
      "1816 [D loss: 0.153172, acc: 94.53%, op_acc: 79.69%] [G loss: 1.809336]\n",
      "1817 [D loss: 0.158645, acc: 94.53%, op_acc: 83.59%] [G loss: 1.898222]\n",
      "1818 [D loss: 0.170295, acc: 96.88%, op_acc: 78.12%] [G loss: 1.731220]\n",
      "1819 [D loss: 0.139603, acc: 98.44%, op_acc: 82.81%] [G loss: 1.787010]\n",
      "1820 [D loss: 0.151910, acc: 94.53%, op_acc: 80.47%] [G loss: 1.937405]\n",
      "Epoch: 1820, F1: 0.24551, F1P: 182\n",
      "[[28188   244]\n",
      " [    8    41]]\n",
      "95.625\n",
      "1821 [D loss: 0.144215, acc: 96.09%, op_acc: 80.47%] [G loss: 1.854334]\n",
      "1822 [D loss: 0.142099, acc: 97.66%, op_acc: 86.72%] [G loss: 1.782190]\n",
      "1823 [D loss: 0.151966, acc: 98.44%, op_acc: 86.72%] [G loss: 1.753468]\n",
      "1824 [D loss: 0.151670, acc: 95.31%, op_acc: 82.81%] [G loss: 1.797369]\n",
      "1825 [D loss: 0.166739, acc: 94.53%, op_acc: 82.81%] [G loss: 1.762567]\n",
      "1826 [D loss: 0.143237, acc: 100.00%, op_acc: 85.16%] [G loss: 1.742959]\n",
      "1827 [D loss: 0.154252, acc: 94.53%, op_acc: 80.47%] [G loss: 1.798242]\n",
      "1828 [D loss: 0.147810, acc: 96.09%, op_acc: 78.91%] [G loss: 1.856346]\n",
      "1829 [D loss: 0.156652, acc: 98.44%, op_acc: 89.06%] [G loss: 1.957958]\n",
      "1830 [D loss: 0.141653, acc: 94.53%, op_acc: 81.25%] [G loss: 1.807128]\n",
      "Epoch: 1830, F1: 0.16466, F1P: 183\n",
      "[[28024   408]\n",
      " [    8    41]]\n",
      "96.5625\n",
      "1831 [D loss: 0.145013, acc: 97.66%, op_acc: 86.72%] [G loss: 1.751198]\n",
      "1832 [D loss: 0.144307, acc: 97.66%, op_acc: 85.16%] [G loss: 1.802727]\n",
      "1833 [D loss: 0.131935, acc: 98.44%, op_acc: 85.16%] [G loss: 1.839276]\n",
      "1834 [D loss: 0.169173, acc: 95.31%, op_acc: 78.12%] [G loss: 1.881322]\n",
      "1835 [D loss: 0.140919, acc: 95.31%, op_acc: 84.38%] [G loss: 1.813381]\n",
      "1836 [D loss: 0.155846, acc: 95.31%, op_acc: 81.25%] [G loss: 1.847533]\n",
      "1837 [D loss: 0.142037, acc: 98.44%, op_acc: 84.38%] [G loss: 1.803892]\n",
      "1838 [D loss: 0.150712, acc: 92.97%, op_acc: 85.94%] [G loss: 1.958151]\n",
      "1839 [D loss: 0.147093, acc: 96.09%, op_acc: 83.59%] [G loss: 1.751541]\n",
      "1840 [D loss: 0.148041, acc: 93.75%, op_acc: 80.47%] [G loss: 1.782121]\n",
      "Epoch: 1840, F1: 0.07799, F1P: 184\n",
      "[[27446   986]\n",
      " [    7    42]]\n",
      "96.09375\n",
      "1841 [D loss: 0.149568, acc: 96.09%, op_acc: 84.38%] [G loss: 1.730765]\n",
      "1842 [D loss: 0.148385, acc: 95.31%, op_acc: 83.59%] [G loss: 1.858827]\n",
      "1843 [D loss: 0.151812, acc: 92.97%, op_acc: 87.50%] [G loss: 1.824912]\n",
      "1844 [D loss: 0.147519, acc: 96.88%, op_acc: 87.50%] [G loss: 1.788286]\n",
      "1845 [D loss: 0.144545, acc: 93.75%, op_acc: 83.59%] [G loss: 1.852840]\n",
      "1846 [D loss: 0.166912, acc: 92.97%, op_acc: 82.03%] [G loss: 1.899448]\n",
      "1847 [D loss: 0.140215, acc: 96.09%, op_acc: 85.94%] [G loss: 1.857634]\n",
      "1848 [D loss: 0.148062, acc: 96.09%, op_acc: 87.50%] [G loss: 1.789491]\n",
      "1849 [D loss: 0.141703, acc: 95.31%, op_acc: 85.94%] [G loss: 1.761037]\n",
      "1850 [D loss: 0.159845, acc: 96.09%, op_acc: 81.25%] [G loss: 1.717227]\n",
      "Epoch: 1850, F1: 0.07473, F1P: 185\n",
      "[[27399  1033]\n",
      " [    7    42]]\n",
      "95.15625\n",
      "1851 [D loss: 0.138587, acc: 99.22%, op_acc: 90.62%] [G loss: 1.825237]\n",
      "1852 [D loss: 0.133003, acc: 96.88%, op_acc: 85.16%] [G loss: 1.870227]\n",
      "1853 [D loss: 0.149115, acc: 97.66%, op_acc: 82.81%] [G loss: 1.785931]\n",
      "1854 [D loss: 0.140332, acc: 96.09%, op_acc: 80.47%] [G loss: 1.811672]\n",
      "1855 [D loss: 0.149842, acc: 94.53%, op_acc: 84.38%] [G loss: 1.781603]\n",
      "1856 [D loss: 0.146370, acc: 94.53%, op_acc: 88.28%] [G loss: 1.738840]\n",
      "1857 [D loss: 0.152412, acc: 94.53%, op_acc: 84.38%] [G loss: 1.825702]\n",
      "1858 [D loss: 0.149372, acc: 97.66%, op_acc: 88.28%] [G loss: 1.812600]\n",
      "1859 [D loss: 0.141484, acc: 96.09%, op_acc: 85.16%] [G loss: 1.811797]\n",
      "1860 [D loss: 0.143343, acc: 96.88%, op_acc: 85.16%] [G loss: 1.808160]\n",
      "Epoch: 1860, F1: 0.10566, F1P: 186\n",
      "[[27728   704]\n",
      " [    7    42]]\n",
      "96.40625\n",
      "1861 [D loss: 0.143037, acc: 98.44%, op_acc: 85.94%] [G loss: 1.754031]\n",
      "1862 [D loss: 0.138457, acc: 97.66%, op_acc: 84.38%] [G loss: 1.765011]\n",
      "1863 [D loss: 0.140460, acc: 95.31%, op_acc: 89.84%] [G loss: 1.775767]\n",
      "1864 [D loss: 0.147217, acc: 95.31%, op_acc: 82.81%] [G loss: 1.791112]\n",
      "1865 [D loss: 0.144055, acc: 96.09%, op_acc: 85.16%] [G loss: 1.882306]\n",
      "1866 [D loss: 0.167465, acc: 93.75%, op_acc: 82.03%] [G loss: 1.723728]\n",
      "1867 [D loss: 0.146781, acc: 96.09%, op_acc: 83.59%] [G loss: 1.813484]\n",
      "1868 [D loss: 0.136879, acc: 97.66%, op_acc: 88.28%] [G loss: 1.774882]\n",
      "1869 [D loss: 0.155898, acc: 95.31%, op_acc: 80.47%] [G loss: 1.743954]\n",
      "1870 [D loss: 0.138555, acc: 98.44%, op_acc: 88.28%] [G loss: 1.737645]\n",
      "Epoch: 1870, F1: 0.16803, F1P: 187\n",
      "[[28034   398]\n",
      " [    8    41]]\n",
      "96.40625\n",
      "1871 [D loss: 0.148413, acc: 94.53%, op_acc: 87.50%] [G loss: 1.777769]\n",
      "1872 [D loss: 0.157947, acc: 94.53%, op_acc: 86.72%] [G loss: 1.693565]\n",
      "1873 [D loss: 0.161771, acc: 96.09%, op_acc: 75.78%] [G loss: 1.860462]\n",
      "1874 [D loss: 0.146099, acc: 95.31%, op_acc: 84.38%] [G loss: 1.766924]\n",
      "1875 [D loss: 0.153498, acc: 96.88%, op_acc: 79.69%] [G loss: 1.783257]\n",
      "1876 [D loss: 0.158046, acc: 96.09%, op_acc: 80.47%] [G loss: 1.713589]\n",
      "1877 [D loss: 0.139338, acc: 94.53%, op_acc: 85.94%] [G loss: 1.816798]\n",
      "1878 [D loss: 0.152649, acc: 93.75%, op_acc: 81.25%] [G loss: 1.814814]\n",
      "1879 [D loss: 0.151443, acc: 94.53%, op_acc: 80.47%] [G loss: 1.711631]\n",
      "1880 [D loss: 0.147183, acc: 96.09%, op_acc: 80.47%] [G loss: 1.789969]\n",
      "Epoch: 1880, F1: 0.12481, F1P: 188\n",
      "[[27865   567]\n",
      " [    8    41]]\n",
      "95.234375\n",
      "1881 [D loss: 0.150882, acc: 96.88%, op_acc: 85.16%] [G loss: 1.818998]\n",
      "1882 [D loss: 0.131755, acc: 97.66%, op_acc: 87.50%] [G loss: 1.904227]\n",
      "1883 [D loss: 0.126068, acc: 97.66%, op_acc: 84.38%] [G loss: 1.747243]\n",
      "1884 [D loss: 0.141117, acc: 95.31%, op_acc: 86.72%] [G loss: 1.794714]\n",
      "1885 [D loss: 0.153931, acc: 95.31%, op_acc: 82.03%] [G loss: 1.751728]\n",
      "1886 [D loss: 0.139075, acc: 97.66%, op_acc: 89.84%] [G loss: 1.741911]\n",
      "1887 [D loss: 0.148966, acc: 96.88%, op_acc: 86.72%] [G loss: 1.868612]\n",
      "1888 [D loss: 0.152940, acc: 96.09%, op_acc: 81.25%] [G loss: 1.893160]\n",
      "1889 [D loss: 0.156822, acc: 93.75%, op_acc: 78.91%] [G loss: 1.765237]\n",
      "1890 [D loss: 0.158432, acc: 91.41%, op_acc: 85.16%] [G loss: 1.787773]\n",
      "Epoch: 1890, F1: 0.12615, F1P: 189\n",
      "[[27872   560]\n",
      " [    8    41]]\n",
      "95.859375\n",
      "1891 [D loss: 0.134554, acc: 97.66%, op_acc: 85.16%] [G loss: 1.582083]\n",
      "1892 [D loss: 0.148082, acc: 97.66%, op_acc: 85.94%] [G loss: 1.801215]\n",
      "1893 [D loss: 0.142891, acc: 98.44%, op_acc: 82.81%] [G loss: 1.807180]\n",
      "1894 [D loss: 0.162583, acc: 92.19%, op_acc: 84.38%] [G loss: 1.839005]\n",
      "1895 [D loss: 0.166906, acc: 92.19%, op_acc: 82.81%] [G loss: 1.836055]\n",
      "1896 [D loss: 0.158807, acc: 94.53%, op_acc: 85.16%] [G loss: 1.833531]\n",
      "1897 [D loss: 0.143945, acc: 95.31%, op_acc: 76.56%] [G loss: 1.795378]\n",
      "1898 [D loss: 0.157888, acc: 96.09%, op_acc: 82.03%] [G loss: 1.800563]\n",
      "1899 [D loss: 0.146479, acc: 97.66%, op_acc: 85.94%] [G loss: 1.857275]\n",
      "1900 [D loss: 0.162695, acc: 94.53%, op_acc: 82.81%] [G loss: 1.904959]\n",
      "Epoch: 1900, F1: 0.09492, F1P: 190\n",
      "[[27638   794]\n",
      " [    7    42]]\n",
      "95.625\n",
      "1901 [D loss: 0.145991, acc: 97.66%, op_acc: 85.94%] [G loss: 1.833646]\n",
      "1902 [D loss: 0.147781, acc: 96.09%, op_acc: 89.84%] [G loss: 1.793319]\n",
      "1903 [D loss: 0.157029, acc: 94.53%, op_acc: 82.03%] [G loss: 1.805298]\n",
      "1904 [D loss: 0.127558, acc: 99.22%, op_acc: 87.50%] [G loss: 1.781348]\n",
      "1905 [D loss: 0.151612, acc: 95.31%, op_acc: 85.16%] [G loss: 1.734546]\n",
      "1906 [D loss: 0.141941, acc: 96.09%, op_acc: 86.72%] [G loss: 1.755927]\n",
      "1907 [D loss: 0.137979, acc: 96.88%, op_acc: 87.50%] [G loss: 1.756424]\n",
      "1908 [D loss: 0.154196, acc: 96.09%, op_acc: 84.38%] [G loss: 1.815044]\n",
      "1909 [D loss: 0.145095, acc: 96.09%, op_acc: 82.81%] [G loss: 1.882899]\n",
      "1910 [D loss: 0.145541, acc: 97.66%, op_acc: 81.25%] [G loss: 1.860149]\n",
      "Epoch: 1910, F1: 0.06375, F1P: 191\n",
      "[[27175  1257]\n",
      " [    6    43]]\n",
      "96.5625\n",
      "1911 [D loss: 0.128012, acc: 99.22%, op_acc: 87.50%] [G loss: 1.784557]\n",
      "1912 [D loss: 0.141896, acc: 96.09%, op_acc: 81.25%] [G loss: 1.798277]\n",
      "1913 [D loss: 0.147246, acc: 96.09%, op_acc: 80.47%] [G loss: 1.734305]\n",
      "1914 [D loss: 0.142209, acc: 96.09%, op_acc: 88.28%] [G loss: 1.808984]\n",
      "1915 [D loss: 0.150227, acc: 95.31%, op_acc: 85.94%] [G loss: 1.769700]\n",
      "1916 [D loss: 0.133748, acc: 95.31%, op_acc: 85.16%] [G loss: 1.725340]\n",
      "1917 [D loss: 0.144763, acc: 95.31%, op_acc: 85.94%] [G loss: 1.793709]\n",
      "1918 [D loss: 0.146363, acc: 93.75%, op_acc: 85.94%] [G loss: 1.865118]\n",
      "1919 [D loss: 0.153735, acc: 92.97%, op_acc: 80.47%] [G loss: 1.795771]\n",
      "1920 [D loss: 0.147684, acc: 97.66%, op_acc: 85.94%] [G loss: 1.862008]\n",
      "Epoch: 1920, F1: 0.15185, F1P: 192\n",
      "[[27982   450]\n",
      " [    8    41]]\n",
      "95.78125\n",
      "1921 [D loss: 0.136630, acc: 96.88%, op_acc: 85.16%] [G loss: 1.929214]\n",
      "1922 [D loss: 0.153317, acc: 92.19%, op_acc: 80.47%] [G loss: 1.779250]\n",
      "1923 [D loss: 0.156238, acc: 97.66%, op_acc: 79.69%] [G loss: 1.814923]\n",
      "1924 [D loss: 0.143784, acc: 97.66%, op_acc: 88.28%] [G loss: 1.749894]\n",
      "1925 [D loss: 0.136976, acc: 97.66%, op_acc: 84.38%] [G loss: 1.691292]\n",
      "1926 [D loss: 0.135859, acc: 96.88%, op_acc: 92.97%] [G loss: 1.863649]\n",
      "1927 [D loss: 0.139715, acc: 97.66%, op_acc: 89.06%] [G loss: 1.775747]\n",
      "1928 [D loss: 0.141395, acc: 98.44%, op_acc: 91.41%] [G loss: 1.739357]\n",
      "1929 [D loss: 0.147811, acc: 95.31%, op_acc: 82.03%] [G loss: 1.792342]\n",
      "1930 [D loss: 0.160539, acc: 93.75%, op_acc: 82.03%] [G loss: 1.727469]\n",
      "Epoch: 1930, F1: 0.16335, F1P: 193\n",
      "[[28020   412]\n",
      " [    8    41]]\n",
      "96.40625\n",
      "1931 [D loss: 0.150560, acc: 98.44%, op_acc: 82.81%] [G loss: 1.769384]\n",
      "1932 [D loss: 0.145222, acc: 96.09%, op_acc: 88.28%] [G loss: 1.656221]\n",
      "1933 [D loss: 0.137250, acc: 97.66%, op_acc: 84.38%] [G loss: 1.759123]\n",
      "1934 [D loss: 0.145210, acc: 98.44%, op_acc: 85.94%] [G loss: 1.892050]\n",
      "1935 [D loss: 0.154147, acc: 94.53%, op_acc: 82.03%] [G loss: 1.735104]\n",
      "1936 [D loss: 0.135860, acc: 96.09%, op_acc: 83.59%] [G loss: 1.896878]\n",
      "1937 [D loss: 0.119518, acc: 100.00%, op_acc: 87.50%] [G loss: 1.825588]\n",
      "1938 [D loss: 0.142501, acc: 98.44%, op_acc: 87.50%] [G loss: 1.840779]\n",
      "1939 [D loss: 0.141448, acc: 97.66%, op_acc: 88.28%] [G loss: 1.876841]\n",
      "1940 [D loss: 0.135639, acc: 96.09%, op_acc: 89.06%] [G loss: 1.826530]\n",
      "Epoch: 1940, F1: 0.19249, F1P: 194\n",
      "[[28096   336]\n",
      " [    8    41]]\n",
      "97.34375\n",
      "1941 [D loss: 0.129496, acc: 98.44%, op_acc: 87.50%] [G loss: 1.803725]\n",
      "1942 [D loss: 0.130014, acc: 95.31%, op_acc: 89.06%] [G loss: 1.993013]\n",
      "1943 [D loss: 0.127644, acc: 97.66%, op_acc: 87.50%] [G loss: 1.801124]\n",
      "1944 [D loss: 0.137845, acc: 95.31%, op_acc: 85.94%] [G loss: 1.849976]\n",
      "1945 [D loss: 0.128727, acc: 99.22%, op_acc: 85.16%] [G loss: 1.748127]\n",
      "1946 [D loss: 0.134041, acc: 98.44%, op_acc: 89.06%] [G loss: 1.761557]\n",
      "1947 [D loss: 0.141974, acc: 94.53%, op_acc: 89.84%] [G loss: 1.789101]\n",
      "1948 [D loss: 0.131819, acc: 96.09%, op_acc: 87.50%] [G loss: 1.796432]\n",
      "1949 [D loss: 0.136634, acc: 98.44%, op_acc: 85.94%] [G loss: 1.866167]\n",
      "1950 [D loss: 0.129732, acc: 100.00%, op_acc: 87.50%] [G loss: 1.713927]\n",
      "Epoch: 1950, F1: 0.14089, F1P: 195\n",
      "[[27940   492]\n",
      " [    8    41]]\n",
      "97.34375\n",
      "1951 [D loss: 0.143693, acc: 95.31%, op_acc: 90.62%] [G loss: 1.718647]\n",
      "1952 [D loss: 0.145884, acc: 96.88%, op_acc: 85.16%] [G loss: 1.785184]\n",
      "1953 [D loss: 0.146798, acc: 96.88%, op_acc: 80.47%] [G loss: 1.865782]\n",
      "1954 [D loss: 0.132953, acc: 98.44%, op_acc: 85.94%] [G loss: 1.852158]\n",
      "1955 [D loss: 0.154667, acc: 92.97%, op_acc: 83.59%] [G loss: 1.816090]\n",
      "1956 [D loss: 0.152761, acc: 95.31%, op_acc: 82.03%] [G loss: 1.889773]\n",
      "1957 [D loss: 0.124772, acc: 99.22%, op_acc: 87.50%] [G loss: 1.916801]\n",
      "1958 [D loss: 0.135717, acc: 99.22%, op_acc: 88.28%] [G loss: 1.865031]\n",
      "1959 [D loss: 0.145176, acc: 92.97%, op_acc: 80.47%] [G loss: 1.776321]\n",
      "1960 [D loss: 0.144026, acc: 94.53%, op_acc: 84.38%] [G loss: 1.772128]\n",
      "Epoch: 1960, F1: 0.19204, F1P: 196\n",
      "[[28095   337]\n",
      " [    8    41]]\n",
      "96.171875\n",
      "1961 [D loss: 0.135730, acc: 100.00%, op_acc: 90.62%] [G loss: 1.896693]\n",
      "1962 [D loss: 0.135340, acc: 96.09%, op_acc: 85.16%] [G loss: 1.865747]\n",
      "1963 [D loss: 0.118594, acc: 97.66%, op_acc: 91.41%] [G loss: 1.700281]\n",
      "1964 [D loss: 0.136443, acc: 96.09%, op_acc: 85.94%] [G loss: 1.945286]\n",
      "1965 [D loss: 0.148077, acc: 94.53%, op_acc: 89.84%] [G loss: 1.890923]\n",
      "1966 [D loss: 0.129468, acc: 94.53%, op_acc: 88.28%] [G loss: 1.751616]\n",
      "1967 [D loss: 0.128877, acc: 97.66%, op_acc: 86.72%] [G loss: 1.854859]\n",
      "1968 [D loss: 0.122874, acc: 97.66%, op_acc: 87.50%] [G loss: 1.906142]\n",
      "1969 [D loss: 0.121364, acc: 97.66%, op_acc: 92.97%] [G loss: 1.871157]\n",
      "1970 [D loss: 0.138783, acc: 98.44%, op_acc: 90.62%] [G loss: 1.758501]\n",
      "Epoch: 1970, F1: 0.21984, F1P: 197\n",
      "[[28149   283]\n",
      " [    8    41]]\n",
      "97.03125\n",
      "1971 [D loss: 0.143220, acc: 96.09%, op_acc: 83.59%] [G loss: 1.850038]\n",
      "1972 [D loss: 0.142441, acc: 95.31%, op_acc: 89.84%] [G loss: 1.893062]\n",
      "1973 [D loss: 0.134166, acc: 96.88%, op_acc: 84.38%] [G loss: 1.851123]\n",
      "1974 [D loss: 0.128297, acc: 98.44%, op_acc: 88.28%] [G loss: 1.927712]\n",
      "1975 [D loss: 0.113231, acc: 99.22%, op_acc: 89.84%] [G loss: 1.861910]\n",
      "1976 [D loss: 0.133168, acc: 96.88%, op_acc: 85.94%] [G loss: 1.866448]\n",
      "1977 [D loss: 0.142441, acc: 94.53%, op_acc: 84.38%] [G loss: 1.823705]\n",
      "1978 [D loss: 0.134942, acc: 96.09%, op_acc: 84.38%] [G loss: 1.916213]\n",
      "1979 [D loss: 0.144606, acc: 95.31%, op_acc: 89.84%] [G loss: 1.840718]\n",
      "1980 [D loss: 0.131782, acc: 96.88%, op_acc: 90.62%] [G loss: 1.793902]\n",
      "Epoch: 1980, F1: 0.08889, F1P: 198\n",
      "[[27578   854]\n",
      " [    7    42]]\n",
      "96.5625\n",
      "1981 [D loss: 0.147156, acc: 94.53%, op_acc: 84.38%] [G loss: 1.772643]\n",
      "1982 [D loss: 0.138402, acc: 95.31%, op_acc: 83.59%] [G loss: 1.811913]\n",
      "1983 [D loss: 0.125834, acc: 95.31%, op_acc: 90.62%] [G loss: 1.891881]\n",
      "1984 [D loss: 0.145771, acc: 98.44%, op_acc: 85.94%] [G loss: 1.896325]\n",
      "1985 [D loss: 0.137219, acc: 96.09%, op_acc: 82.03%] [G loss: 1.801760]\n",
      "1986 [D loss: 0.139895, acc: 94.53%, op_acc: 88.28%] [G loss: 1.892299]\n",
      "1987 [D loss: 0.124048, acc: 97.66%, op_acc: 85.94%] [G loss: 1.806935]\n",
      "1988 [D loss: 0.142255, acc: 99.22%, op_acc: 84.38%] [G loss: 1.916399]\n",
      "1989 [D loss: 0.134013, acc: 96.88%, op_acc: 82.81%] [G loss: 1.845277]\n",
      "1990 [D loss: 0.122450, acc: 94.53%, op_acc: 89.06%] [G loss: 1.870111]\n",
      "Epoch: 1990, F1: 0.11566, F1P: 199\n",
      "[[27813   619]\n",
      " [    8    41]]\n",
      "96.25\n",
      "1991 [D loss: 0.133108, acc: 96.88%, op_acc: 85.94%] [G loss: 1.848931]\n",
      "1992 [D loss: 0.137478, acc: 93.75%, op_acc: 82.81%] [G loss: 1.826910]\n",
      "1993 [D loss: 0.147149, acc: 96.88%, op_acc: 82.81%] [G loss: 1.935345]\n",
      "1994 [D loss: 0.105160, acc: 98.44%, op_acc: 95.31%] [G loss: 1.969024]\n",
      "1995 [D loss: 0.119528, acc: 99.22%, op_acc: 92.19%] [G loss: 1.927019]\n",
      "1996 [D loss: 0.138508, acc: 96.88%, op_acc: 82.03%] [G loss: 1.936431]\n",
      "1997 [D loss: 0.118202, acc: 97.66%, op_acc: 85.16%] [G loss: 1.909529]\n",
      "1998 [D loss: 0.133663, acc: 96.88%, op_acc: 83.59%] [G loss: 1.960117]\n",
      "1999 [D loss: 0.146289, acc: 96.09%, op_acc: 85.94%] [G loss: 1.802947]\n"
     ]
    }
   ],
   "source": [
    "f1_p, d_l_p = train(X_res,y_res,\n",
    "             X_test,y_test,\n",
    "             generator,discriminator,\n",
    "             combined,\n",
    "             num_classes=2,\n",
    "             epochs=2000, \n",
    "             batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "275574636046ce8cfe041ab9776628447da970ac",
    "execution": {
     "iopub.execute_input": "2024-11-03T16:29:26.254021Z",
     "iopub.status.busy": "2024-11-03T16:29:26.253612Z",
     "iopub.status.idle": "2024-11-03T16:29:26.449684Z",
     "shell.execute_reply": "2024-11-03T16:29:26.448643Z",
     "shell.execute_reply.started": "2024-11-03T16:29:26.253955Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'F1 Score Validation')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAGtCAYAAAC4HmhdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEQmZEjIRERGRkCkhExEREQnZ/wMucwPs9FP16wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7d773e22c518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10,7))\n",
    "plt.plot(f1_p)\n",
    "plt.xlabel('10 Epochs')\n",
    "plt.ylabel('F1 Score Validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T16:29:26.451661Z",
     "iopub.status.busy": "2024-11-03T16:29:26.451270Z",
     "iopub.status.idle": "2024-11-03T16:29:26.641098Z",
     "shell.execute_reply": "2024-11-03T16:29:26.640198Z",
     "shell.execute_reply.started": "2024-11-03T16:29:26.451596Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Accuracy')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAGtCAYAAABTKdNeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wGU37DijHOZPAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7d773de87dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10,7))\n",
    "plt.plot(d_l_p)\n",
    "plt.xlabel('10 Epochs')\n",
    "plt.ylabel('Accuracy')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 310,
     "sourceId": 23498,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 594,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
